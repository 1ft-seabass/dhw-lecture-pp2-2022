# Introduction

2021年度プロダクトプロトタイピングⅡの授業で使われるドキュメントのページです。

## 注意

公開されているページですが、SNSなどに積極的な URL 公開はしないようによろしくお願いします。

## 講師紹介

<img src="https://i.gyazo.com/0116e8a74666ace1a45096ae02b54347.jpg" alt="Image from Gyazo" width="200"/>

田中正吾 タナカセイゴ

屋号ワンフットシーバスにてフリーランスエンジニアで活動。Microsoft MVP・IBM Champion。WEBフロントエンドをベースにしながらも、情報とインターフェースが合わさるアプローチという視点でIoTやMixed Realityといった技術も取り入れながら活動しています。ウォンバットが好き。

## 授業スケジュール

- 第1回　2021年09月24日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第2回　2021年10月01日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第3回　2021年10月08日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第4回　2021年10月15日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第5回　2021年10月22日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第6回　2021年10月29日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第7回　2021年11月05日（金） 8限　21:00 ～ 22:30　遠隔授業
- 第8回　2021年11月12日（金） 8限　21:00 ～ 22:30　遠隔授業
- 予 備
  - 2021年11月19日（金） 8限　21:00 ～ 22:30　遠隔授業
  - 予備日は休講があった場合に補講日として扱うものです

## 授業概要

※シラバスより

プロダクトプロトタイピングⅡでは、プロダクトプロトタイピングⅠで学んだプロトタイピングを更に発展させて、実際に私たちの生活やビジネスを良くするのプロトタイプ(モック)を作成した先の、つくるプロトタイピングから他者へ伝えるプロトタイピングをどのように行うかを解説する。

本講義では、IoT プロトタイプ(モック)を元に、フィードバックの接点を増やすプレゼンテーションの手法や、他者に伝わる外装プロトタイプの基礎、リアルタイムに伝えるデモンストレーションを習得する。

## 到達目標

※シラバスより

- IoT マイコンボード（M5Stack）を用いて実際に私たちの生活やビジネスを良くするのプロトタイプ（モック）を作成する基礎を理解する
- プレゼンテーションやデモンストレーションといったプロトタイプ（モック） を他者に伝える方法を理解し、発信自体も自身で計画しプロトタイピングできるようになる
- 他者から得たフィードバックから自身のプロダクトを磨いていくコミュニケーション手法やプロトタイピングツールの活用ができるようになる
- つくるプロトタイピングから他者へ伝えるプロトタイピングをするための手法を理解できるようになる

## 授業全体の流れ

※シラバスより

- 第1回 プロトタイピング発展概論・環境構築
- 第2回 プロトタイピング発展概論・環境構築
- 第3回 IoT開発ボード M5Stack 入門
- 第4回 IoT開発ボード M5Stack 入門
- 第5回 IoT開発ボード設置・外装入門
- 第6回 IoT開発ボード設置・外装実践
- 第7回 制作物デモ発表 ／ プレゼンテーション
- 第8回 フィードバックブラッシュアップ／ プレゼンテーション

## 各授業リンク

![image](https://i.gyazo.com/d13a3da8a09ff39274bc3f30400d83e9.png)

右側のナビゲーションから今日の授業をクリックしましょう。
# 第1回 プロトタイピング発展概論・環境構築

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第1回　2021年09月24日（金） 8限　21:00 ～ 22:30　遠隔授業
```

- [はじめに](00-introduction.md) 30分
  - 講師からの自己紹介
  - みなさんの自己紹介
- [本講義のゴールを把握する](01-understanding-the-curriculum.md) 30分
  - 授業概要
  - 到達目標
  - 授業の進め方 ほか
  - 質疑応答
- [ファーストステップ](02-firststep.md) 30分
  - 今回使う M5Stack について
  - 来週までの宿題 ほか
  - 質疑応答（機材購入の質問などもぜひ）
- [宿題](99-homework.md)

## 授業開始

![image](https://i.gyazo.com/d13a3da8a09ff39274bc3f30400d83e9.png)

右側のナビゲーションから今日の回の「はじめに」をクリックしてはじめていきましょう！

## 授業が終わるまでにアンケート入力お願いします

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

次回以降の授業の参考にします。

https://docs.google.com/forms/d/e/1FAIpQLScanK13JP3mPcBrb0WUUcLsma9AxljtfdgylEMnb8WYnJYsjA/viewform

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

# 第1回 プロトタイピング発展概論・環境構築 - イントロダクション

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

授業をはじめるにあたって、いろいろと共有していきます！

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
    - あとで、ひとりひとりウォームアップします。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

## 講師紹介

<img src="https://i.gyazo.com/0116e8a74666ace1a45096ae02b54347.jpg" alt="Image from Gyazo" width="200"/>

田中正吾 タナカセイゴ

屋号ワンフットシーバスにてフリーランスエンジニアで活動。Microsoft MVP・IBM Champion。WEBフロントエンドをベースにしながらも、情報とインターフェースが合わさるアプローチという視点でIoTやMixed Realityといった技術も取り入れながら活動しています。ウォンバットが好き。

- Webサイト https://www.1ft-seabass.jp/
  - 講師の活動の様子が分かります
- ブログ https://www.1ft-seabass.jp/memo/
  - 日々のナレッジはこちらで
- SNS
  - Twitter https://twitter.com/1ft_seabass
  - Facebook https://www.facebook.com/seigo.tanaka

## みなさんの自己紹介

それでは、自己紹介をしていきましょう～。

![image](https://i.gyazo.com/8bb6da4820529871e09aa5d80d1483c8.png)

- ひとり 30 秒 ～ 1 分くらいで話しましょう
- 内容
  - お名前
  - 簡単なプロフィール
  - この授業への思い
    - 期待すること・学びたいこと・やってみたいこと
    - 上記3つのうち、どれか1つ以上

## 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

左のナビゲーションから「本講義のゴールを把握する」にすすみましょう。# 第1回 プロトタイピング発展概論・環境構築 - 本講義のゴールを把握する

## 本講義のゴールを把握する

![image](https://i.gyazo.com/298dbb3b4b5730300528b5ca1971b1b9.png)

### 授業概要

プロダクトプロトタイピングⅡでは、プロダクトプロトタイピングⅠで学んだプロトタイピングを更に発展させて、実際に私たちの生活やビジネスを良くするのプロトタイプ(モック)を作成した先の、つくるプロトタイピングから他者へ伝えるプロトタイピングをどのように行うかを解説します。

本講義では、IoT プロトタイプ(モック)を元に、フィードバックの接点を増やすプレゼンテーションの手法や、他者に伝わる外装プロトタイプの基礎、リアルタイムに伝えるデモンストレーションを習得します。

### 到達目標

- IoT マイコンボード（M5Stack）を用いて実際に私たちの生活やビジネスを良くするのプロトタイプ（モック）を作成する基礎を理解します
- プレゼンテーションやデモンストレーションといったプロトタイプ（モック） を他者に伝える方法を理解し、発信自体も自身で計画しプロトタイピングできるようになります
- 他者から得たフィードバックから自身のプロダクトを磨いていくコミュニケーション手法やプロトタイピングツールの活用ができるようになります
- つくるプロトタイピングから他者へ伝えるプロトタイピングをするための手法を理解できるようになります

## 演習形式

オンラインの演習形式です。

コミュニケーションツールは Slack を使い、授業は Zoom で行います。

## 大まかな流れ

大まかな流れは以下の通りです。

![image](https://i.gyazo.com/af1812d8f75e22b105692e1d66c362b5.png)

## 心構え

授業が進行していく上で、最終制作発表＆フィードバックブラッシュアップ（第7回・第8回）までの、おすすめの心構えです。

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

## 課題

- 最終課題　50％
  - 発想力・創造力・アウトプット力・継続開発力 の要素で採点する予定です。
- 授業内の課題　50％
  - 機材をそろえて準備する課題 10％予定
  - 制作してアウトプットする課題 20％ * 2 予定

で採点を予定しています。

### モチベーション

- IoT、コンピューターやセンサーを組み込んだ商品開発、実験に興味のある学生
- 基板につないだプロトタイプから一歩発展させることに興味がある学生
- 作ったプロトタイプを発信することに興味のある学生

### プログラミング知識の前提

- プロダクトプロトタイピングⅠで行うプログラミングスキルを理解して制作できることが望ましいです。
- 言語としては JavaScript 言語および Arduino 言語を利用する想定です。
- プログラミングそのものや if や for などの基本構文の説明は省略する予定です。
- プロダクトプロトタイピングⅠで行う LINE BOT や  Node.js の説明は省略する予定です。

### SNSアカウントの準備

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他条件

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## プロダクトプロトタイピングⅠから発展させるポイントの共有

プロダクトプロトタイピングⅠで学んだプロトタイピングを更に発展させますが

- Ⅰでは、最終制作としてプレゼンテーションを行い終了しましたが、Ⅱではまず発表時にフィードバックを受け付け、次の回までのブラッシュアップします。
  - 他の人（今回は講師や生徒を予定）からフィードバック（他者フィードバック）を受け付けたり、自分自身が発表後にこう良くしたい（自己フィードバック）から一つ以上制作物をブラッシュアップしてもう一度発表を行い、作り続けていくサイクルを重視して学びます。
- Ⅱでは、最初の制作物デモ発表時にリアルタイムのデモを行いますし、他の人に触ってもらうために外装・インターフェースのところも意識したものをつくります。
  - obniz の場合は通常基板がむき出しなので人に触らせにくいですが、M5Stack はそれ自体はパッケージで囲まれていますし、回路で少し配線を延ばしてもプロトタイプ的な外装テクニックで手軽に追加外装できます。
- Ⅰでは、obniz と JavaScript で素早くプロトタイピングを行いましたが、より様々な IoT 制御ができる M5Stack と Arduino(C言語) を学んで技術の理解できる範囲を一層増やし、作れる幅を広げていきます。
  - Arduino(C言語) はC言語とはいえ setup , loop の中で作っていくことができ、制作の文献が豊富なので授業で学びながら、自分で調べながら作るという流れになります。
  - M5Stack については Arduino で作れる IoT 機材のなかでも、一層たくさんのTIPSや制作事例があります。つくりたい発想に似たナレッジであったり、つまづいたときも同じようなハマり方をしている人も出会いやすいので進めやすいと思います。

## プロダクトプロトタイピングⅠを受講してない人は

上記「プロダクトプロトタイピングⅠから発展させるポイントの共有」や「プログラミング知識の前提」はありますが、M5Stack と Arduino(C言語) を学ぶところ、外装について学ぶところは、今回参加するみなさん同じスタートです。

その後、最終制作物をつくるときに、フロントエンド（表示側）やバックエンド（LINE Bot やシステム）といったところが必要になるかもしれませんが、そこは講師に質問いただければアドバイスできることもあるので、どんどん Slack で聞いてください！

アウトプット・発表については、こちらからも伝えていきますし、自分に合ったやり方を模索ししながら進めましょう。こちらも気になることがあれば、どんどん Slack で聞いてください！

## 週の中で田中の動けるタイミング

2021/09/24 現在の情報です。

普段は仕事で、平日 月～金 日中 9:00-17:00 はフリーランスエンジニアとして複数のクライアントともに活動しております。休日（土日・祝日）は、家のこともあり基本お休みです。

その上で、以下を動ける予定です。

- 基本対応
  - Slack の本授業チャンネルによるテキストチャット
- 平日 月～金 
  - Slack は、なるべく見るようにするので、すぐ返せそうなときはすぐレスポンスします。
  - その他、授業準備をしているときがあるので、そのときもレスポンスできます。
  - それ以外で、みなさんから質問があるときや、こちらにまとまった時間ができたときは事前にアナウンスします。
- 休日（土日・祝日）
  - 家のこともあり日中は基本難しい、夜に少し返せるかもしれない。

あくまでベストエフォート（最善努力。もしかしたら動けないときもある。）ですが、なるべく寄りそえるようにがんばります。よろしくお願いします！

## 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

左のナビゲーションから「ファーストステップ」にすすみましょう。# 第1回 プロトタイピング発展概論・環境構築 - ファーストステップ

ファーストステップを行っていきます。

## Zoom 操作ウォームアップ

![image](https://i.gyazo.com/bc2788ab8b924263d742686389d956b1.png)

みなさんの Zoom から画面共有をしておきましょう。今後、使うことが多いと思います。

- 今後、ハンズオン（一緒に手を動かすパート）をするときに、実際にデバイスで何が起きているかや、ソースコードを見せることがあるので、はじめにチェックします。
- 画面共有するという前提で、表示するときのデスクトップが大丈夫か確認
  - 仕事のフォルダなどないですか？見られるとまずいファイルはないですか？　など
- 画面共有時にスムーズな操作ができるか大丈夫か把握しておく
  - CPU・メモリ・グラフィックカードなどの性能によって、それなりにマシンパワーを消費して負荷がかかるので体感しておく

もし、画面共有が厳しいときは、

- カメラオフで負荷をへらしてから表示してみる
- 操作はしにくいができる範囲で表示してみる
- Slack のグループチャットを通じてソースコードや状況を伝えてみる

などで対処していきましょう～。

## 授業フォルダへのアクセス

https://drive.google.com/drive/folders/1o1pZ7ityO_P78UsNKoVVC7kEXtrbK3-M

- デジタルハリウッド Google アカウントでログインすると見れます
- 今後こちらに授業を確認するデータが共有される場合があります
- 最終制作のスライドの提出などもこちらで行う予定です

## M5Stack とは

![image](https://i.gyazo.com/45ae963151d71934a8ba786c88ba9637.jpg)

[M5Stack Basic \- スイッチサイエンス](https://www.switch-science.com/catalog/3647/)

> M5Stackは、320 x 240 TFTカラーディスプレイ、microSDカードスロット、スピーカーを備えたコンパクトで便利な開発モジュールです。ESP32を搭載しているため、Wi-FiおよびBluetooth通信を扱え、Arduino環境での開発が可能です。

- 外装がしっかりある
  - メリット
    - 人にすぐに見せることができる、伝えることができる→アウトプットの迅速化
    - 「え、これ触れるの？」というユーザーの迷いや「え、感電しないの？」という恐怖心が生じにくく、すばやくつたえられる
  - 余談
    - 電子工作のボードは基板むきだしになりがち
      - [Arduino Uno R3 \- スイッチサイエンス](https://www.switch-science.com/catalog/789/)
      - プロダクトプロトタイピングⅠで使われた obniz も使い勝手は良いが基板むきだし部分が多い
    - Raspberry Pi のようにケースはあるが、ボタンやディスプレイなど人に触れるようなるまでのステップが多かったりする
      - [Raspberry Pi 4 Model B / 8GB \- スイッチサイエンス](https://www.switch-science.com/catalog/6370/)

## 購入するものと機材の説明

![image](https://i.gyazo.com/a4e22b717d8e8b84d0662bc8a98f8591.png)

まず、購入リストを見てみましょう。

購入リスト → https://docs.google.com/spreadsheets/d/1wIQr7Tai836nZ1UZrN1AgeSWpsEOh4kjj_LGNmx6O8U/edit#gid=0

- デジタルハリウッド Google アカウントでログインすると見れます

## アウトプット例

ツイート例 → https://twitter.com/1ft_seabass/status/1374889016001245200

![image](https://i.gyazo.com/3af7ed391bedccd2b68565a7d206d8b4.jpg)

## 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

お疲れ様でした！

左のナビゲーションから「宿題」にすすみましょう。# 今回の宿題 第1回

今日の宿題は以下の 2 つです

## 1. プロダクトプロトタイピング II 機材購入リストの内容を購入しましょう

https://docs.google.com/spreadsheets/d/1wIQr7Tai836nZ1UZrN1AgeSWpsEOh4kjj_LGNmx6O8U/edit#gid=0

こちらの機材購入リストにあるものを購入しましょう。

- 〆切
  - この機材購入リストは本格的に機材を触る 2 回目 10月01日（金） 21:00 開始までに用意しましょう。
  - おそらく到着までに1～2日かかるので、この土日に完了しておいたほうが安心です。
  - 授業は機材がある前提で進行します
- そのほか伝達事項
  - M5Stack 単体でも、ディスプレイ・ボタン・スピーカー（音）・加速度・ジャイロ・磁気（コンパス）が使えます。
  - シラバスでは「 7000 円程度～」としていましたが 8300 円に落ち着きました。
  - スイッチサイエンスに在庫があり手に入りやすいもので選びなおしました。
  - サーボや他のセンサーについては授業が進んでから、みなさんの必要度や進捗次第でいくつか加えるかもしれませんが、ひとまずこれですすめます。

### 買い終えた人は

> 機材買い終えた人はリアクションお願いします！

という Slack のメッセージにリアクションお願いします！

### 余談：私も最近の M5Stack セットアップしてみました

https://twitter.com/1ft_seabass/status/1439097633751003138

![image](https://i.gyazo.com/9ee0968bf2e013d118e2be34bc95e44f.jpg)

## 2. M5Stack の事前セットアップをお願いします

M5Stack 関連のインストールファイルはファイルサイズが重く（特に Arduino IDE ）、待ち時間が長くかかるので事前セットアップお願いします。

- [Getting Started: M5Stack の開発環境を準備する \| プロトタイプ向けマイコンモジュール M5Stack と 3G 拡張ボードをセットアップする \| SORACOM Users](https://users.soracom.io/ja-jp/guides/dev-boards/m5stack/development-environment/)

基本、こちらにそって進めてください。

### 大まかな手順はこちらです。

- [Arduino ダウンロードページ](https://www.arduino.cc/en/software) で最新 Arduino 1.8.16 のインストールをお願いします。
- USB シリアルドライバーをインストールする
  - Windows と Mac お使いの OS に合わせてインストールしましょう
- ESP32 ボード定義をインストールする
  - M5Stack のボードマネージャでインストールするバージョンは 1.0.7 でお願いします。
- ライブラリをインストールする
  - M5Stack のライブラリマネージャでインストールするバージョンは 0.3.0 でお願いします。
  - **TinyGSM by Volodymyr Shymanskyy はインストールしません**

### 事前セットアップが終わった人は

> 事前セットアップが終わった人はリアクションお願いします！

という Slack のメッセージにリアクションお願いします！

### 参考キャプチャ

M5Stack のボードマネージャでインストールするバージョンは 1.0.7。

![image](https://i.gyazo.com/9797d2f4483c8cd2f69a162813482dd2.png)

M5Stack のライブラリマネージャでインストールするバージョンは 0.3.0。

![image](https://i.gyazo.com/08500d83586c5ad94f31b493d1022d1f.png)

## 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

お疲れ様でした！

左のナビゲーションから今回の授業の「README」に戻りましょう。# 第2回 プロトタイピング発展概論・環境構築

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第2回　2021年10月01日（金） 8限　21:00 ～ 22:30　遠隔授業
```

- はじめに 5 分
- [IoT開発ボード M5Stack の導入](01-m5stack-firststep.md) 25 分
- [IoT開発ボード M5Stack から LINE BOT にメッセージを送る](02-line.md) 30 分
- [SNS からのアウトプットの事例や世界観を把握する](03-sns-autoput.md) 15 分
- [次回への準備](99-next-preparation.md) 15 分

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 第 2 回の心構え

第 2 回では、いよいよ M5Stack 環境構築です。

今日で、うまくいけば、M5Stack でプログラムが書き込めるようになりインターネットにもつながるようになるはず。

M5Stack の持つ機能や魅力を把握しながら、自分の最終制作で作るものをイメージしていきましょう。

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

また、第 3 回の終わりに  M5Stack で小さく作って　Twitter へアウトプットする宿題を出します。期限は第 4 回開始までの予定です。

ですので、今回の段階で、ある程度どういう風に手を動かすかのイメージをつけて、徐々に制作時間を作っていくとよいでしょう。最終制作へ「作りつづける」ウォームアップでもあります。

## 第 2 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- M5Stack が完成したソースコードを書き込む形で動かす流れを把握する
- M5Stack を少し崩して変更したり、デバッグするためのやり方を把握する
- M5Stack のボタンやディスプレイの基本的な動きやインターネットへのつなぎ方を把握する
- M5Stack と LINE サービス（LINE Notify ・ LINE BOT）がソースコードを書き加える形で連携できる
- M5Stack をとりまくアウトプットを元に自分のこれからのアウトプットに生かせる糧にする

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- 機材リストで示した機材が購入できていて揃っている状態
  - M5Stack は今日の授業で使うので必須
- Arduino IDE に M5Stack の開発環境が整っている状態
  - 前回の宿題でセットアップが済み
  - Slack で連絡した事前チェックが済んでいるとよりよい（トラブルなく始められる確率が高まります）
- プロダクトプロトタイピング I ベースの話
  - LINE Developer アカウントが取得済みで LINE BOT 制作がすぐ取り掛かれる状態

とくに、「プロダクトプロトタイピング I ベースの話」については、生徒さんごとに事情が変わってくるかもなので、LINE Developer アカウントだけあればできる LINE Notify もやってみる予定です。

### もし可能なら M5Stack 事前チェックをしましょう（Slack連絡済み）

授業前にセットアップがうまく行っているか事前確認しましょう。

- [M5Stack セットアップチェック](10-m5stack-check.md)

### M5Stack トラブルシューティング TIPS（Slack連絡済み）

セットアップ周辺でSlack などのやり取りで出てきたトラブルシューティング TIPSをまとめています。（進行形）

- [M5Stack トラブルシューティング TIPS](11-m5stack-trouble-shooting-tips.md)

## 授業開始

では授業をはじめましょう！

左のメニューから「M5Stack の導入」をクリックしましょう。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

# M5Stack セットアップチェック

[前回の宿題](../lecture01/99-homework.md) を行ってみてセットアップがうまく行っているか簡単なチェックをしておきましょう。

## 0. 進め方

以下の導入チェックを 1 → 2 → 3 の順に進めましょう。

## 1. M5Stack ボード設定の導入チェック

![image](https://i.gyazo.com/0cdeeff94e075310b5592e849232fbcb.jpg)

まだ M5Stack は PC につなぎません。

![image](https://i.gyazo.com/a61828fccd84836aabfac60ab103489b.png)

Arduino IDE を起動して、新規ファイルをクリックします。

![image](https://i.gyazo.com/2b832c5bec5263ae68159976d21ff47a.png)

ツール > ボード > M5Stack-Core-ESP32 を選択します。

![image](https://i.gyazo.com/e86802c00c19dfc5cc8ebad4e020770c.png)

ツール > シリアルポート が、グレーして選択できない状態で、このあと M5Stack のポートが増えるのを待ちます。

![image](https://i.gyazo.com/903d4cda78f3cf10c84f036cad08fe03.jpg)

M5Stack に付属していた USB ケーブルを用意します。

![image](https://i.gyazo.com/2a86c7f1b721555abfaf0105f161ea9f.jpg)

PC と M5Stack をつなぎます。

![image](https://i.gyazo.com/595100dc326e18141cc74ab745a3475a.png)

Windows 10 の場合、Arduino IDE の ツール > シリアルポート に、`COM3` や `COM1` のような `COM` が頭にあるシリアルポート名が表示されていれば無事 M5Stack 用の USB ドライバがインストールされて M5Stack が認識されています。

![image](https://i.gyazo.com/9336adb21f951ddeb5f706b54b8b3923.png)

Mac の場合は、Arduino IDE の ツール > シリアルポート に `/dev/tty.SLAB_USBtoUART` のような `/dev/tty.SLAB_` が頭にあるシリアルポート名が表示されていれば無事 M5Stack 用の USB ドライバがインストールされて M5Stack が認識されています。（小林さんキャプチャ使用させていただきました！）

## 2. M5Stack ライブラリの導入チェック「コードに色がつくか」

さきほど Arduino IDE を起動して新規ファイルに、以下のソースコードをコピーアンドペーストしてライブラリに色がつくか確認してみましょう。

```c
#include <M5Stack.h>

void setup() {
  M5.begin();

  M5.Lcd.println("Hello World");
}

void loop() {
  
}
```

正常に M5Stack のライブラリがインストールされていれば、以下のように、コードに色がつきます。

![image](https://i.gyazo.com/48fe8f4590406a9eeb1d9cf3be21f12f.png)

## 3. 検証してみる

![image](https://i.gyazo.com/c374df997075f55b8975e136d189b513.png)

`2.` で確認したソースコードを保存して `dhw-pp2-99-check-sample` をつけて保存しましょう。保存しないと検証できないのでご注意ください。

![image](https://i.gyazo.com/f4f722a959ba5fb7abf9c11a5cc2c550.png)

保存できたら検証ボタンをクリックします。

![image](https://i.gyazo.com/d5fdf80f0ed1ff0dfb74df1f41716d8b.png)

しばらく（30秒～1分？）、ソースコードを実際にコンパイルして、うまくいくか検証がなされます。

![image](https://i.gyazo.com/ee6776b0c4700342fb66596074f4d8b0.png)

> 最大1310720バイトのフラッシュメモリのうち、スケッチが347205バイト（26%）を使っています。
> 最大327680バイトのRAMのうち、グローバル変数が17596バイト（5%）を使っていて、ローカル変数で310084バイト使うことができます。

のようなメッセージと共に、「コンパイルが完了しました」と表示されれば、ボード設置とライブラリがうまくインストールされて M5Stack 用のコードがコンパイルされるところまで正常だと確認できます。

これ以降は授業で扱う流れで、実際に上記コードを M5Stack に書き込まれて動作します。お楽しみに！

## もしうまく動いてなさそうって思ったら

![image](https://i.gyazo.com/2b44aa7e35f6c257520989ea7319cd51.png)

Slack でお気軽に聞いてくださいー。# M5Stack トラブルシューティング TIPS

ここでは、セットアップ周辺でSlack などのやり取りで出てきたトラブルシューティング TIPSをまとめています。

## コンパイルしようとすると「使用できない名前のライブラリは無視します」と言われる

（小林さん遭遇）

![image](https://i.gyazo.com/5077677cee5f067946716de80392e1f0.png)

原因：以前インストールした M5Stack ライブラリと重複していると予想

対処：ライブラリの重複が怪しかったので、Mac内で「M5Stack」関係のデータ全て消してもう一度ライブラリ入れてみた（小林さん対応）

## Mac Big Sur でコンパイルすると ValueError: dlsym(RTLD_DEFAULT, kIOMasterPortDefault): symbol not found エラーが出る

（小林さん遭遇）

原因：どうやらBig Surの仕様のせいらしい

対処：[macOS Big SurでESP32のコンパイルが通らなかった件を解決したメモ \#m5stack \- Qiita](https://qiita.com/n0bisuke/items/69366541f4372cb49463)（小林さん対応）

## no protocol というエラーが出る

（さわださん遭遇）

![image](https://i.gyazo.com/c4acda3bd13af44e88a105a06efb6b21.png)

ひとまず、 M5Stack 関連のエラーじゃなさそうなので保留中。

## シリアルモニタでデバッグしようにも文字化けしてしまう

```c
void setup() {
  // init lcd, serial, but don't init sd card
  M5.begin(true, false, true);
  
  /*
    Power chip connected to gpio21, gpio22, I2C device
    Set battery charging voltage and current
    If used battery, please call this function in your project
  */
  M5.Power.begin();

  M5.Lcd.clear(BLACK);
  M5.Lcd.setTextColor(YELLOW);
  M5.Lcd.setTextSize(2);
  M5.Lcd.setCursor(65, 10);
  M5.Lcd.println("Serial example");
  Serial.println("Serial example");
}
```

このような `Serial.println("Serial example");` を実行した時に

![image](https://i.gyazo.com/5a318a7c28f406373fce40afcebd56f0.png)

文字化けしてしまう。（さわださん遭遇）

![image](https://i.gyazo.com/c1ae6857179993d8e204a2e82972eab1.png)

シリアルモニタ右下を 115200 bps に設定すると文字化けせず受信できます。

![image](https://i.gyazo.com/4679862f1ea0dce4753ce20829a05650.png)

うまくいくとこのように表示されます。# M5Stack の導入

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## まずはチェック

チェックがまだな人もいるかもしれないので、念のためチェックしていきましょう。

- [M5Stack セットアップチェック](10-m5stack-check.md)

### 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/8b62e0c3bf9dad23c0e9ca6362aea085.jpg)

無事に書き込まれると `Hello World` の文が表示されます。

### ソースコードを反映

![image](https://i.gyazo.com/a61828fccd84836aabfac60ab103489b.png)

Arduino IDE を起動して、新規ファイルをクリックします。
```c
#include <M5Stack.h>

void setup() {
  M5.begin();

  M5.Lcd.println("Hello World");
}

void loop() {
  
}
```

上記のソースコードをコピーアンドペーストします。実はチェック時のコードと同じです。

![image](https://i.gyazo.com/48fe8f4590406a9eeb1d9cf3be21f12f.png)

コードにこのように色がついていれば OK です。ライブラリが正しくインストールされて効いている状態です。

### ファイルを保存

![image](https://i.gyazo.com/5923c3950bc2a2ef1576dd6d1afe42f4.png)

`dhw-pp2-study-01-HelloWorld` で保存しておきます。

### 確認して書き込み

念のため、もう一度、以下の設定は確認しておきましょう。

- PC から M5Stack 同梱の USB ケーブルで M5Stack につながっている
- ツール > ボード > M5Stack-Core-ESP32 を選択
- ツール > シリアルポート に M5Stack のポートが認識されている
  - Windows 10 の場合 `COM` が頭にあるシリアルポート名が表示 例: `COM3`
  - Mac の場合は `/dev/tty.SLAB_` が頭にあるシリアルポート名が表示 例: `/dev/tty.SLAB_USBtoUART`
- `#include <M5Stack.h>` などに色がついている 例: ![image](https://i.gyazo.com/377362c26b20027e2a6fd3d6a6801227.png)

確認できたら、

![image](https://i.gyazo.com/62a4680dee3f56a2ca23fad41e8d28f6.png)

マイコンボードを書き込むボタンをクリックします。

![image](https://i.gyazo.com/bbbda50bc7f265d291cb3a803e7924b1.png)

コンパイルを待ちます。

![image](https://i.gyazo.com/459cb6b9ad74028375743347a5d6a5af.png)

このようなログと共に書き込まれます。

以下がログの全文です。参考までに。

```
最大1310720バイトのフラッシュメモリのうち、スケッチが347205バイト（26%）を使っています。
最大327680バイトのRAMのうち、グローバル変数が17596バイト（5%）を使っていて、ローカル変数で310084バイト使うことができます。
esptool.py v3.0-dev
Serial port COM3
Connecting.....
Chip is ESP32-D0WDQ6-V3 (revision 3)
Features: WiFi, BT, Dual Core, 240MHz, VRef calibration in efuse, Coding Scheme None
Crystal is 40MHz
MAC: 08:3a:f2:44:60:74
Uploading stub...
Running stub...
Stub running...
Changing baud rate to 921600
Changed.
Configuring flash size...
Auto-detected Flash size: 16MB
Compressed 8192 bytes to 47...
Writing at 0x0000e000... (100 %)
Wrote 8192 bytes (47 compressed) at 0x0000e000 in 0.0 seconds (effective 10922.6 kbit/s)...
Hash of data verified.
Flash params set to 0x024f
Compressed 17392 bytes to 11186...
Writing at 0x00001000... (100 %)
Wrote 17392 bytes (11186 compressed) at 0x00001000 in 0.2 seconds (effective 909.4 kbit/s)...
Hash of data verified.
Compressed 347328 bytes to 154525...
Writing at 0x00010000... (10 %)
Writing at 0x00014000... (20 %)
Writing at 0x00018000... (30 %)
Writing at 0x0001c000... (40 %)
Writing at 0x00020000... (50 %)
Writing at 0x00024000... (60 %)
Writing at 0x00028000... (70 %)
Writing at 0x0002c000... (80 %)
Writing at 0x00030000... (90 %)
Writing at 0x00034000... (100 %)
Wrote 347328 bytes (154525 compressed) at 0x00010000 in 2.6 seconds (effective 1074.1 kbit/s)...
Hash of data verified.
Compressed 3072 bytes to 128...
Writing at 0x00008000... (100 %)
Wrote 3072 bytes (128 compressed) at 0x00008000 in 0.0 seconds (effective 3510.9 kbit/s)...
Hash of data verified.

Leaving...
Hard resetting via RTS pin...
```

### 動かしてみる

書き込まれたら M5Stack を確認しましょう。

![image](https://i.gyazo.com/8b62e0c3bf9dad23c0e9ca6362aea085.jpg)

無事に書き込まれると `Hello World` の文が表示されます。

![image](https://i.gyazo.com/a7c051278279d9fb57ca6ce2e10bcb76.jpg)

そう、最小のフォントサイズ 1 だとこんなに小さいんですが、キレイに表示されるのがすごいですね。

もし「もっと文字大きくしたいなー」など思ったなら、自己フィードバックが生まれて何かしたくなってる良い傾向です！

フォントサイズが厳密に気になるひとはこちら → [M5Stack Basic と M5Stack Core2 のデフォルトフォントのサイズステップが分かったメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/02/12/m5stack-basic-and-core2-default-fontsize-maybe-7px-knowledge/)

# 次にすすみましょう

左のナビゲーションから「Wi-Fi リスト確認」にすすみましょう。# Wi-Fi につなぐ前に周辺の Wi-Fi を確認

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/8656356ef8d3754cb5eba0aa4d99b58f.jpg)

書き込みと同時に周辺の Wi-Fi リストを表示します。

## ソースコードを反映

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。

```c
#include <M5Stack.h>
#include "WiFi.h"

// Factory Test を抜粋
// https://github.com/m5stack/M5Stack/blob/master/examples/Basics/FactoryTest/FactoryTest.ino

void wifi_test() {
    WiFi.mode(WIFI_STA);
    WiFi.disconnect();
    delay(100);

    Serial.println("scan start");
    M5.Lcd.println("scan start");

    // WiFi.scanNetworks will return the number of networks found
    int n = WiFi.scanNetworks();
    Serial.println("scan done");
    M5.Lcd.println("scan done");
    if (n == 0) {
        Serial.println("no networks found");
        M5.Lcd.println("no networks found");
    } else {
        Serial.print(n);
        M5.Lcd.print(n);
        Serial.println(" networks found");
        M5.Lcd.println(" networks found");
        for (int i = 0; i < n; ++i) {
            // Print SSID and RSSI for each network found
            Serial.print(i + 1);
            M5.Lcd.print(i + 1);
            Serial.print(": ");
            M5.Lcd.print(": ");
            Serial.print(WiFi.SSID(i));
            M5.Lcd.print(WiFi.SSID(i));
            Serial.print(" (");
            M5.Lcd.print(" (");
            Serial.print(WiFi.RSSI(i));
            M5.Lcd.print(WiFi.RSSI(i));
            Serial.print(")");
            M5.Lcd.print(")");
            Serial.println((WiFi.encryptionType(i) == WIFI_AUTH_OPEN)?" ":"*");
            M5.Lcd.println((WiFi.encryptionType(i) == WIFI_AUTH_OPEN)?" ":"*");
            delay(5);
        }
    }
    Serial.println("");
    M5.Lcd.println("");
}


void setup() {
  
    // initialize the M5Stack object
    M5.begin();
    
    M5.Power.begin();
    
    M5.Lcd.setBrightness(100);
    M5.Lcd.fillScreen(BLACK);
    M5.Lcd.setCursor(10, 10);
    M5.Lcd.setTextColor(WHITE);
    M5.Lcd.setTextSize(2);
    M5.Lcd.printf("WiFi Test!");

    M5.Lcd.setCursor(0, 0);
    M5.Lcd.fillScreen(BLACK);
    wifi_test();
    
}

void loop(){
    M5.update();
}
```

こちらを `dhw-pp2-study-02-TestWiFiList` で保存します。

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

書き込みと同時に周辺の Wi-Fi リストを表示します。

![image](https://i.gyazo.com/8656356ef8d3754cb5eba0aa4d99b58f.jpg)

自分の作業場の Wi-Fi 名が表示されてますでしょうか。

これでチェックできること

- Wi-Fi が M5Stack で動作していることがわかる
- 自分の作業場の Wi-Fi が M5Stack から認識していることがわかる
  - 実際につながないとわからないことも多いが、つながる確率はかなり高まりました！

# 次にすすみましょう

左のナビゲーションから「Wi-Fi につなぐ」にすすみましょう。# Wi-Fi をつないでみる

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/255d8e3093f898093f0f8000b06b9182.png)

Wi-Fi リストで、つなげたい Wi-FI が存在していることが分かったので、つないでみます。IoTの第一歩です。

## ソースコードを反映

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。

```c
#include <WiFiClient.h>
#include <M5Stack.h>
#include <WiFi.h>
 
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
 
////////////////////////////////////////////////////////////////////////////////
   
void setup() {
    // init lcd, serial, but don't init sd card
    // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
    M5.begin(true, false, true);
 
    // スタート
    M5.Lcd.fillScreen(BLACK);
    M5.Lcd.setCursor(10, 10);
    M5.Lcd.setTextColor(WHITE);
    M5.Lcd.setTextSize(3);

    // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
    Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
    M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
     
    // WiFi 接続開始
    WiFi.begin(ssid, password);
   
    while (WiFi.status() != WL_CONNECTED) {
        delay(500);

        // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
        Serial.print(".");
        M5.Lcd.print(".");
    }
 
    // WiFi Connected
    // WiFi 接続完了
    M5.Lcd.setCursor(10, 40);
    M5.Lcd.setTextColor(WHITE);
    M5.Lcd.setTextSize(3);

    // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
    // 前のメッセージが print で改行入っていないので println で一つ入れる
    Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
    M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
    
    // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
    Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
    M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
}

void loop() {
  M5.update();

  // まだ何かを待つような作業はしてないです
}
```

こちらを `dhw-pp2-study-03-TestWiFi` で保存します。

## Wi-Fi 情報を反映して、また保存

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

Wi-Fi 情報を反映します。

- `char *ssid = "Wi-FiのSSID";`
  - ダブルクォーテーションで囲まれている `Wi-FiのSSID` の部分をつなぎたい Wi-Fi の SSID に書き換えます
- `char *password = "Wi-Fiのパスワード";`
  - ダブルクォーテーションで囲まれている `Wi-Fiのパスワード` の部分をつなぎたい Wi-Fi のパスワードに書き換えます

もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/c272c1e6a5ba0025120ba324e25b10b3.jpg)

Connected. となれば成功です。

![image](https://i.gyazo.com/77ff933c65a4b9473b00fcc03ac33466.jpg)

START . . . . . . . . と、なっている場合は、Wi-Fi がつながらないので、ずっと探している状態です。

以下を検討・確認してみましょう。

- プログラムに設定している接続したい Wi-Fi の SSID ・パスワードが合っているか確認
- 接続したい Wi-Fi 側の設定が、無線帯域 2.4GHz 帯、暗号化方式は WPA2/PSK の推奨設定かを確認
  - もし違っていたら、設定を変更できるか検討
  - もし変更が難しい場合は、スマートフォンのテザリング機能でつなげられないかを検討

# 次にすすみましょう

左のナビゲーションから「サーバーにメッセージを送る」にすすみましょう。
# サーバーにメッセージを送ってみる

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/416402edf3476298c3065d0500962a92.png)

このような仕組みです。

![image](https://i.gyazo.com/e9c21a3d286467ed300b2ac6e1f48ad7.jpg)

起動時にサーバーにメッセージが送られ、その後、各ボタンをクリックしてサーバーにメッセージが送られます。

## テストサーバーを用意しました

![image](https://i.gyazo.com/b9f26a859d98bbee5dc509b2cfe3aaa2.png)

授業のためにテストサーバーを用意しました

http://dhw-pp2-2021-test01.herokuapp.com/ui/

- こういうサーバーがあるとデータがちゃんと届いているかのチェックがしやすいです
- ひとまず今回は HTTP で受信するとログが出ます
- 時間に余裕があれば軽くデモします

## ソースコードを反映

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。

```c
#include <M5Stack.h>

// 以下2つはHTTPSでデータを送るためのライブラリ
#include <WiFiClientSecure.h>
#include <ssl_client.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");
}

// HTTP でメッセージ送信部分
void send_message(String msg) {

  // 今回送るホスト名
  const char* hostName = "dhw-pp2-2021-test01.herokuapp.com";
  
  WiFiClientSecure clientHTTPS;

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  
  M5.Lcd.println("-> send_message");
  M5.Lcd.print("msg: ");
  M5.Lcd.println(msg);
  
  Serial.println("-> send_messagey");
  Serial.print("msg: ");
  Serial.println(msg);
  
  if (!clientHTTPS.connect(hostName, 443)) {
    delay(2000);
    return;
  }
  String queryString = msg;

  // Content-Type: application/json
  // で POST 送信で /dhw/pp2/http/message に送信
  String request = String("") +
   "POST /dhw/pp2/http/message HTTP/1.1\r\n" +
   "Host: " + hostName + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/json\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTPS.print(request);
  M5.Lcd.println("clientHTTPS.printed");
  Serial.println("clientHTTPS.printed");
  while (clientHTTPS.connected()) {
    String response = clientHTTPS.readStringUntil('\n');
    if (response == "\r") {
      break;
    }
  }

  // データ送信完了
  M5.Lcd.println("sended.");
  Serial.println("sended.");

  // サーバーから返答を受け取ったらデータを表示
  String response = clientHTTPS.readStringUntil('\n');

  M5.Lcd.println("response:");
  M5.Lcd.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }
}
```

こちらを `dhw-pp2-study-04-TestHTTP` で保存します。

## Wi-Fi 情報を反映して、また保存

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

先ほどと同じように Wi-Fi 情報を反映します。もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/e9c21a3d286467ed300b2ac6e1f48ad7.jpg)

起動時に サーバーに `{"message":"Launched!"}` という JSON データが送られます。

また、3つボタンが並んでいますが、Aボタン、Bボタン、Cボタンでプログラムと対応しています。クリックしてサーバーにメッセージが送られるか確認してみましょう。

たとえば、Cボタンをクリックすると `{"message":"Pushed C"}` という JSON データが送られます。

# 送るデータを変更してみる（書き換え訓練）

これだと送った人が分からないので、英数字で自分の名前を決めて、送るデータをちょっと書き換えましょう。

## Launched メッセージをちょっと変更

```c
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");
```

を、以下のように書き加えます。Seigo で変更した例です。

```c
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Seigo Launched!\"}");
```

## ボタンを押したときのメッセージをちょっと変更

```c
void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }
}
```

を、以下のように書き加えます。Seigo で変更した例です。

```c
void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Seigo Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Seigo Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Seigo Pushed C\"}");
  }
}
```

## 余談：英数字で顔文字表現テクニック

もし余裕があれば、

 - `(^_^)`
 - `(=_=)`
 - `:-)`
 - `;-)`
 - `(*o*)/`

のような顔文字は英数字でも表現できるので、ぜひ試してみましょう～。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「M5Stack から LINE BOT にメッセージを送る」にすすみましょう。# M5Stack から LINE 連携

## まず LINE Developer にログインできるか確認しましょう

![image](https://i.gyazo.com/1694a72ac447a94b60b11e038d602dba.jpg)

このセクションでは M5Stack と LINE の連携をするので、まず LINE Developer にログインできるか確認しましょう。

あと、生徒のみなさんの事情をきいてみる。

## なぜ LINE がプロトタイピングによいのか？

![image](https://i.gyazo.com/01ce9eae3d298ade5a105e76ff75add2.png)

- 使っているユーザーが多く追加で何かインストールさせる手間が少なめなので、早くユーザーに触ってもらえます。
- LINE BOT や LINE Nofity に代表されるチャット UI があるので、表示面、フロントエンドに力をかけすぎず、すぐに触れる仕組みが作れるので早く考えたものを試せます。
- たくさん文献がある。よって、問題解決もしやすく、参考になる事例も多い。検索しながら、つくりたいものを進められます。

これらのメリットから、すばやくつくって試して良くしていくプロトタイピングには相性が良いです。

## 次にすすみましょう

左のナビゲーションから「M5Stack + LINE Notify 連携」にすすみましょう。

# M5Stack から LINE Notify にメッセージを送ろう

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/d4f219471329ee42c7d2b291e7272873.png)

このような仕組みです。

![image](https://i.gyazo.com/e49942702a7683010b16a76d797d83e2.jpg)

Aボタン、Bボタン、Cボタンをクリックすると LINE Notify サーバーにメッセージが送られます。

![image](https://i.gyazo.com/9bc36d121afc4ac5e8b71a2b2c8fe573.png)

先ほど設定した LINE Notify のアカウントにメッセージが表示されます。

## LINE Notify のトークンを取得します

![image](https://i.gyazo.com/c45ee309aa6793bc12f67c24f3a905ce.png)

https://notify-bot.line.me/ja/ からログインします。

![image](https://i.gyazo.com/bf26cdcf093a783aee4ff510ec9ddb68.png)

ログインすると、右上にアカウント名が出るのでクリックします。

![image](https://i.gyazo.com/7cdb07c7e588bac278a5fb0b2dbc9d83.png)

マイページをクリック。

![image](https://i.gyazo.com/0c48f49af1be4e5e7c789366c0b838cf.png)

マイページの下の方に「アクセストークンの発行(開発者向け)」というエリアがあるのでスクロールします。

![image](https://i.gyazo.com/bbba9909e0437e487718479953b198ff.png)

トークンを発行するボタンをクリックします。

![image](https://i.gyazo.com/05b98371bcae556f578cdb96505ecb7c.jpg)

トークンを発行するウィンドウが表示されるので、以下のように対応します。

- トークン名を記入してください (通知の際に表示されます)
  - `M5Stack Notify` と入力
- 通知を送信するトークルームを選択してください
  - `1:1でLINE Notifyから通知を受け取る` を選択

こちらを対応すると、発行するボタンが押せるようになるのでクリックします。

![image](https://i.gyazo.com/abee7f38d2db6897c61cdb42fc29a83c.png)

このようにトークンが表示されるのでメモしましょう。

**このページから移動すると、新しく発行されたトークンは二度と表示されないので気をつけましょう**

メモしたらウィンドウを閉じるボタンをクリックして閉じます。

![image](https://i.gyazo.com/2fcf2f7f0d039737510759301a619485.png)

リストに追加されたことを確認しておきます。

![image](https://i.gyazo.com/07a33eec5562fc6fd67e52aeaa5c2bc9.png)

今回選択した LINE Notify 先のアカウントにこのようなメッセージが来ていることも確認します。

## ソースコードを反映

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。

```c
#include <M5Stack.h>
#include <WiFiClientSecure.h>
#include <ssl_client.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

void setup() {
  
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
}

void send_message(String msg) {

  // LINE Notify のホスト
  const char* hostLINENotify = "notify-api.line.me";

  // LINE Notify のトークン
  const char* tokenLINENotify = "LINE Notify のトークン";
  
  WiFiClientSecure clientHTTPS;

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.println("-> LINE Notify");
  Serial.println("-> LINE Notify");
  M5.Lcd.print("msg: ");
  Serial.print("msg: ");
  M5.Lcd.println(msg);
  Serial.println(msg);
  
  if (!clientHTTPS.connect(hostLINENotify, 443)) {
    delay(2000);
    return;
  }
  String queryString = String("message=") + msg;

  // LINE Notify の API に合わせて送信内容を作る
  // Content-Type は application/x-www-form-urlencoded
  // Authorization: Bearer にトークンを割り当てる
  String request = String("") +
   "POST /api/notify HTTP/1.1\r\n" +
   "Host: " + hostLINENotify + "\r\n" +
   "Authorization: Bearer " + tokenLINENotify + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/x-www-form-urlencoded\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTPS.print(request);
  M5.Lcd.println("clientHTTPS.printed");
  Serial.println("clientHTTPS.printed");
  while (clientHTTPS.connected()) {
    String line = clientHTTPS.readStringUntil('\n');
    if (line == "\r") {
      break;
    }
  }
  
  String response = clientHTTPS.readStringUntil('\n');
  M5.Lcd.println("sended.");
  Serial.println("sended.");

  M5.Lcd.println("response:");
  M5.Lcd.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したらテキストメッセージを LINE Notify へ送る
    send_message("Pushed A");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したらテキストメッセージを LINE Notify へ送る
    send_message("Pushed B");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したらテキストメッセージを LINE Notify へ送る
    send_message("Pushed C");
  }
}
```

こちらを `dhw-pp2-study-05-TestLINENotify` で保存します。

## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

先ほどと同じように Wi-Fi 情報を反映します。

## LINE Notify のトークンを反映

```c
void send_message(String msg) {

  // LINE Notify のホスト
  const char* hostLINENotify = "notify-api.line.me";

  // LINE Notify のトークン
  const char* tokenLINENotify = "LINE Notify のトークン";
```

send_message のすぐ近くにある `const char* tokenLINENotify = "LINE Notify のトークン";` の `LINE Notify のトークン` の部分を、先ほどメモした LINE Notify のトークンに置き換えましょう。ダブルクオーテーションを消していないか気をつけましょう。

## M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/e49942702a7683010b16a76d797d83e2.jpg)

Aボタン、Bボタン、Cボタンをクリックすると LINE Notify サーバーにメッセージが送られます。

![image](https://i.gyazo.com/9bc36d121afc4ac5e8b71a2b2c8fe573.png)

先ほど設定した LINE Notify のアカウントにメッセージが表示されます。

# 次にすすみましょう

左のナビゲーションから「M5Stack + LINE BOT 連携」にすすみましょう。# M5Stack から LINE BOT にメッセージを送ろう

[1時間でLINE BOTを作るハンズオン \(資料\+レポート\) in Node学園祭2017 \#nodefest \- Qiita](https://qiita.com/n0bisuke/items/ceaa09ef8898bee8369d#1-bot%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B) を参考に進めます。

以下に、今回の授業のの手順として、書いてありますので、進めていきましょう。

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/d0ce73c1d8c7992d57aa01df0a323ab0.png)

このような仕組みです。

起動すると、まず `Launched` メッセージが ngrok に送られて、さらに LINE BOT にプッシュメッセージとして送られます。

![image](https://i.gyazo.com/03598f71b9402bacd545881ed0225481.jpg)

ボタンを押すと `response Hello M5Stack!(POST)` と返答が返ってきて、メッセージが ngrok に送られて、さらに LINE BOT にプッシュメッセージとして送られます。

![image](https://i.gyazo.com/9df34d328f5d0433888c75ff964c26a5.png)

うまくいけば、LINE BOT でこのように M5Stack で押した内容が表示されて連携できます。

## LINE BOT の作り方の手順まとめています

こちらにLINE BOT の作り方の手順まとめています。

[LINE BOT 作成手順](12-line-bot-create.md)

まだ、作っていない方は、ぜひ試してみてください。

## Node.js で BOT 開発

Visual Studio Code で開発していきます。

講師の環境は

- Windows 10
- Node.js 14.17.5
- npm 6.14.14

です。

## フォルダを作成して Visual Studio Code ではじめる

![image](https://i.gyazo.com/2f0b578e81dbccbedc7338d165c92bc4.png)

`dhw-pp2-linebot` というフォルダを作成します。

![image](https://i.gyazo.com/fedda70653d896c15c83be417e0c6b25.png)

こちらを Visual Studio Code で開きます。こちらを今回のプロジェクトフォルダとして使います。

## npm の初期化

プロジェクトフォルダ直下で、

```
npm init -y
```

`npm init` コマンドで `package.json` を作成します。

## ライブラリのインストール

```
npm i @line/bot-sdk express
```

コマンドで `@line/bot-sdk` と `express` のLINE BOT に関連するライブラリをインストールします。

## BOT として動かす app.js の作成

![image](https://i.gyazo.com/66bfdf2fece70796b98a935899fd943d.png)

プロジェクトフォルダ直下で Visual Studio Code の新規ファイル作成を使って `app.js` を作成します。

## app.js にソースコードを反映

`app.js` に以下のソースコードをコピーアンドペーストで反映します。

[LINE BOT 作成手順](12-line-bot-create.md) で、作成したBOTのチャンネルシークレットとチャンネルアクセストークンが必要になるので準備しておきましょう。

```js
'use strict';

const express = require('express');
const line = require('@line/bot-sdk');
const PORT = process.env.PORT || 3000;

// 作成したBOTのチャンネルシークレットとチャンネルアクセストークン
const config = {
  channelSecret: '作成したBOTのチャンネルシークレット',
  channelAccessToken: '作成したBOTのチャンネルアクセストークン'
};

// プッシュメッセージで受け取る宛先となる作成したBOTのユーザーID'
const userId = '作成したBOTのユーザーID';

const app = express();

// M5Stack からJSON データを受け取ったときに扱えるようにする設定
// https://qiita.com/kmats/items/2c2502cfa3a633e7e049
app.use('/from/m5stack', express.json()); 

app.get('/', (req, res) => res.send('Hello LINE BOT!(GET)')); //ブラウザ確認用(無くても問題ない)
app.post('/webhook', line.middleware(config), (req, res) => {
    console.log(req.body.events);

    //ここのif分はdeveloper consoleの"接続確認"用なので削除して問題ないです。
    if(req.body.events[0].replyToken === '00000000000000000000000000000000' && req.body.events[1].replyToken === 'ffffffffffffffffffffffffffffffff'){
        res.send('Hello LINE BOT!(POST)');
        console.log('疎通確認用');
        return; 
    }

    Promise
      .all(req.body.events.map(handleEvent))
      .then((result) => res.json(result));
});

const client = new line.Client(config);

async function handleEvent(event) {
  if (event.type !== 'message' || event.message.type !== 'text') {
    return Promise.resolve(null);
  }

  return client.replyMessage(event.replyToken, {
    type: 'text',
    text: event.message.text //実際に返信の言葉を入れる箇所
  });
}

// M5Stack からメッセージを受け取り LINE BOT へプッシュメッセージする部分
app.post('/from/m5stack', async function(req, res){

  console.log('M5Stack からメッセージを受け取り');
  console.log(req.body);

  const pushText = req.body.message;  // 受信した JSON データの message 値を LINE BOT へプッシュする

  client.pushMessage(userId, {
    type: 'text',
    text: pushText,
  });

  res.send('Hello M5Stack!(POST)');
});

app.listen(PORT);

console.log(`Server running at ${PORT}`);
```

## 作成したBOTのチャンネルシークレットとチャンネルアクセストークンを反映

```js
// 作成したBOTのチャンネルシークレットとチャンネルアクセストークン
const config = {
  channelSecret: '作成したBOTのチャンネルシークレット',
  channelAccessToken: '作成したBOTのチャンネルアクセストークン'
};
```

[LINE BOT 作成手順](12-line-bot-create.md) で、作成したBOTのチャンネルシークレットとチャンネルアクセストークンを、それぞれ反映します。

わりと編集中にシングルクォーテーション消してしまったり、channelSecretとchannelAccessTokenを、逆に書いたりしてハマるので気をつけましょう。

## M5Stack から来るプッシュ通知の送り先のユーザーIDを反映

まず、プッシュ通知の送り先であるこの BOT のユーザーIDを LINE Developers から取得します。

https://developers.line.biz/ja/

こちらからログインしましょう。

![image](https://i.gyazo.com/b4cff116ffa19c5ed6b6b2c98e15cedb.png)

今回使っている BOT のチャネル設定に移動します。

![image](https://i.gyazo.com/1e959b391cb50becbdff3fd3ca39b3e2.png)

下にスクロールしていくと `あなたのユーザーID` という項目があるので、これをメモしておきます。

```js
// プッシュメッセージで受け取る宛先となる作成したBOTのユーザーID'
const userId = '作成したBOTのユーザーID';
```

`作成したBOTのユーザーID` の部分を先ほどメモしたユーザーIDで書き換えます。

ここまで設定出来たらファイルを保存します。

## app.js を Node.js で実行して手元のサーバー起動

プロジェクトフォルダ直下で、

```
node app.js
```

コマンドで app.js を Node.js で実行して手元のサーバー起動します。

`Server running at 3000`

と表示されれば起動成功です。

### 動作確認してみる

ちゃんと動作しているか見てみましょう。

Chrome ブラウザで

`http://localhost:3000`

でアクセスすると、

![image](https://i.gyazo.com/4d8c47c50965ff64d49b0641670e1ddd.png)

と表示されます。

これで動作確認は完了です。

## ngrok で手元の PC に外からつながる BOT を立ち上げます

ngrok で手元の PC に外からつながる BOT を立ち上げます。 ngrok が何かは　[こちらの ngrok の説明](https://qiita.com/n0bisuke/items/ceaa09ef8898bee8369d#3-ngrok%E3%81%A7%E3%83%88%E3%83%B3%E3%83%8D%E3%83%AA%E3%83%B3%E3%82%B0) を参考にしてください。

![image](https://i.gyazo.com/67c4d65d66b6e18eb9082d1d6f6bd8fe.png)

こちらを起動している状態で、別のターミナルを立ち上げます。

```
npm i -g ngrok
```

コマンドで ngrok をインストールします。

```
ngrok http 3000
```

先ほど起動した 3000 番のポートで起動しているボットサーバーを ngrok で公開します。

  ngrok by @inconshreveable                                                                               (Ctrl+C to quit)                                                                                                                        Session Status                online                                                                                    Session Expires               1 hour, 59 minutes                                                                        Update                        update available (version 2.3.40, Ctrl-U to update)                                       Version                       2.3.35                                                                                    Region                        United States (us)                                                                        Web Interface                 http://127.0.0.1:4040                                                                     Forwarding                    http://**********.ngrok.io -> http://localhost:3000     Forwarding                    https://**********.ngrok.io -> http://localhost:3000                                                                                                                            Connections                   ttl     opn     rt1     rt5     p50     p90                                                                             0       0       0.00    0.00    0.00    0.00

といったメッセージが表示されるます。

2 つある Forwarding の項目で https が書かれているほうの `https://**********.ngrok.io` までをメモしておきます。`**********` の部分はみなさんの環境によって変わります。

## Webhook URL の更新

![image](https://i.gyazo.com/5d1457a134175c620f142f92177ab373.png)

今回使っている BOT の Messaging API 設定に移動します。

![image](https://i.gyazo.com/c85ed28c0caa79951404327636ef1a44.png)

Webhook URL の項目に移動して以下の手順を行います。（大事な設定なので、一息タイミングを置いています）

### さきほどの URL に `/webhook` をつけて

![image](https://i.gyazo.com/9f162805b70de3e064982abbf3136e3e.png)

さきほどの URL `https://**********.ngrok.io` に `/webhook` をつけて Webhook URL の項目に入力して更新ボタンをクリックします。

![image](https://i.gyazo.com/3340e1c266fdfbfda807586ea34e04b3.png)

同時に Webhook の利用がオンになっていることも確認しましょう。

## BOT にオウム返しが来るか確認しましょう

一旦ここでちゃんと動いているかオウム返しを確認してみましょう。

![image](https://i.gyazo.com/3bf69c731aca0696a7f70f2dfdd9a670.png)

## M5Stack のソースコードを反映

ここから Arduino パートです。

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。

こちら、`dhw-pp2-study-04-TestHTTP` で保存したサーバーにメッセージを送ってみるプログラムとかなり近いものです。ただ ngrok の HTTPS になぜかつながらないので HTTP で対応したコードになっていることにご注意ください。

たとえば Heroku とか別のサーバーの HTTPS は以前の TestHTTP でつながるんですが、なにか ngrok が特殊なんでしょうか。もし、今後 HTTPS のサーバーに何か送る場合は `dhw-pp2-study-04-TestHTTP` で試してみましょう。

前向きに言えば、ここまでで HTTP での送り方と HTTPS での送り方を両方体験できました。

```c
#include <M5Stack.h>

// 以下2つはHTTPSでデータを送るためのライブラリ
// #include <WiFiClientSecure.h>
// #include <ssl_client.h>

// ngrok の HTTPS になぜかつながらないので HTTP で対応
// たとえば Heroku とか別のサーバーの HTTPS は以前の TestHTTP でつながる
#include <WiFi.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");
}

// HTTP でメッセージ送信部分
void send_message(String msg) {

  // TestHTTP からの変更点 1
  // 今回送るホスト名に ngrok のホスト名 (http://なし)を反映
  const char* hostName = "**********.ngrok.io";

  // WiFiClientSecure clientHTTPS;
  // ngrok の HTTPS になぜかつながらないので HTTP で対応
  // 以下 clientHTTPS → clientHTTP
  WiFiClient clientHTTP;

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  
  M5.Lcd.println("-> send_message");
  M5.Lcd.print("msg: ");
  M5.Lcd.println(msg);
  
  Serial.println("-> send_messagey");
  Serial.print("msg: ");
  Serial.println(msg);
  
  // ngrok の HTTPS になぜかつながらないので HTTP で対応 ポート番号変更 443 → 80
  // if (!clientHTTP.connect(hostName, 443)) {
  if (!clientHTTP.connect(hostName, 80)) {
    delay(2000);
    return;
  }
  String queryString = msg;

  // TestHTTP からの変更点 2
  // Content-Type: application/json
  // で POST 送信で /from/m5stack に送信
  String request = String("") +
   "POST /from/m5stack HTTP/1.1\r\n" +
   "Host: " + hostName + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/json\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTP.print(request);
  M5.Lcd.println("clientHTTPS.printed");
  Serial.println("clientHTTPS.printed");
  while (clientHTTP.connected()) {
    String response = clientHTTP.readStringUntil('\n');
    if (response == "\r") {
      break;
    }
  }

  // データ送信完了
  M5.Lcd.println("sended.");
  Serial.println("sended.");

  // サーバーから返答を受け取ったらデータを表示
  String response = clientHTTP.readStringUntil('\n');

  M5.Lcd.println("response:");
  M5.Lcd.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }
}
```

こちらを `dhw-pp2-study-06-LINEBotMessageHTTP_ngrok` で保存します。

## Wi-Fi 情報を反映して

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

先ほどと同じように Wi-Fi 情報を反映します。

## 今回送るホスト名に ngrok のホスト名 (http://なし) を反映

```c
  // 今回送るホスト名に ngrok のホスト名 (http://なし)を反映
  const char* hostName = "**********.ngrok.io";
```

こちらには、今回送るホスト名に ngrok のホスト名 (http://なし) を反映します。

## M5Stack に書き込んでみる

ここで、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

起動すると、まず `Launched` メッセージが ngrok に送られて、さらに LINE BOT にプッシュメッセージとして送られます。

![image](https://i.gyazo.com/03598f71b9402bacd545881ed0225481.jpg)

ボタンを押すと `response Hello M5Stack!(POST)` と返答が返ってきて、メッセージが ngrok に送られて、さらに LINE BOT にプッシュメッセージとして送られます。

![image](https://i.gyazo.com/9df34d328f5d0433888c75ff964c26a5.png)

うまくいけば、LINE BOT でこのように M5Stack で押した内容が表示されて連携できているはずです！

## ngrok 再起動時にやること

ngrok は 2 時間までしか起動しているアドレスのサーバーが使えません。なので、何か実験をするタイミングでサッと使うプロトタイピングに向いています。

もし、ngrok を再起動した場合は、以下の点を対応すれば、作業を再開できます。

- 起動した ngrok のURLを確認して再度メモ
- LINE BOT 側の Webhook URL を今回の ngrok で再度更新
- Arduino のソースコードの今回送るホスト名に ngrok のホスト名 (http://なし) を再度反映

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「SNS からのアウトプットの事例や世界観を把握する」にすすみましょう。
# LINE BOT を作成する

[1時間でLINE BOTを作るハンズオン \(資料\+レポート\) in Node学園祭2017 \#nodefest \- Qiita](https://qiita.com/n0bisuke/items/ceaa09ef8898bee8369d#1-bot%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B)

こちらの、「1. Botアカウントを作成する」～「Botと友達になろう」まで進めます。

## LINE Developers にログイン

![image](https://i.gyazo.com/4bb4c0bffb3c961ea749ec833e2e826b.jpg)

LINE Developers の右上のメニューから自分の LINE アカウントでログインします

https://developers.line.biz/ja/

![image](https://i.gyazo.com/415c9566b4b1d2e51b17f55f59345701.png)

`LINE アカウントでログイン` ボタンをクリックします。

![image](https://i.gyazo.com/5efe71ed2c45acc347a40b34340880f5.png)

メールアドレスとパスワード、もしくは、QRコードでログインできます。

### 言語設定が日本語になっているか確認

![image](https://i.gyazo.com/8391997e7db3ce012a4e4f3010085805.png)

ログインしたあと右下に言語設定のエリアがあるので `日本語` になっているか確認しましょう。以後の流れは、日本語で設定された画面の前提で進みます。

### ログインできない場合は

* LINEのスマートフォンアプリ側で設定を確認しましょう。
* 設定がまだの方はLINEのスマートフォンアプリ画面から 設定>アカウントでメールアドレスを設定できます。
    * [LINEでメールアドレスを新規登録・確認・変更・解除（削除）する方法 \| アプリオ](https://appllio.com/line-mail-address-settings)

## プロバイダーの作成

ログインしたらプロバイダーの作成を行います。

プロバイダーは、自分が作るLINE BOTなどの開発者名やチーム名、企業名になります。
初回だけディベロッパー登録で個人情報を聞かれると思うので回答してから進めましょう。

![image](https://i.gyazo.com/d69a72b6767e358c7bf4808a6546a5ec.png)

コンソール（ホーム）を押してプロバイダーの画面に行きます。

![image](https://i.gyazo.com/545aeaed54b1081be46ccc97ada43006.png)

作成ボタンを押して進みます。

![image](https://i.gyazo.com/4b73740ebdb9a26dfb8fa4457bd2eefc.png)

プロバイダー名は今回は デジハリ開発 と入力して作成ボタンを押して進めましょう。

![image](https://i.gyazo.com/08d33da3d350eef0510f5643d4f26809.png)

デジハリ開発 の プロバイダー のチャネル設定に移動されます。

![image](https://i.gyazo.com/f5dacf9f99c96cef4a5b2a7ba2b0c30d.png)

今回は LINE BOT を作るので `Messaging API` をクリックします。

## BOTの情報入力

BOTの情報を入力します。

![image](https://i.gyazo.com/5e922a871132eda6c0a122f00a9d1c02.png)

チャネルの種類は先ほどMessaging API を選択して入れば、 `Messaging API` となっています。
プロバイダーは デジハリ開発に設定されています。

![image](https://i.gyazo.com/a56c6059ddb93f8a9ea0261adc19ba00.png)

チャネルアイコンは、BOTの顔になるので、お好みの画像を入れましょう。
チャネル名は、今回は「デジハリBOT」にします。

もちろん、自分の自由な名前にしていただいてもOKです！

![image](https://i.gyazo.com/b69ca35da7df9ec380e826dcfafd5636.png)

チャネル説明・大業種・小業種は、とりあえず、なんでもOKですが、悩んだら画像のようにしておきましょう。

![image](https://i.gyazo.com/5384b4ee7c11faa87c6bc93377971b45.png)

メールアドレスは、BOTの開発者にLINE側からお知らせがあるときに受け取るメールアドレスを入力します。
プライバシーポリシーURL/サービス利用規約URL（任意）こちらは、今はなくても大丈夫です。

![image](https://i.gyazo.com/e9ca90c74fc6b980d12f3e680fc8e21f.png)

LINE公式アカウント利用規約 の内容と、LINE公式アカウントAPI利用規約 の内容を確認して、チェックボックスを選択して、作成ボタンをクリックします。

![image](https://i.gyazo.com/2c9c61b4c0e134f050dc84271fc55bd2.png)

こちらは OK をクリック。

最後に、情報利用に関する同意についてというページが出るので、スクロールして内容を確認したら、同意ボタンをクリックできるようになるので、クリックして進めます。

![image](https://i.gyazo.com/673c5772019b52faf8708042f926cddf.png)

作成が完了すると、作成されたデジハリBOTの設定ページに移動します。

## チャネルシークレットをメモする

![image](https://i.gyazo.com/673c5772019b52faf8708042f926cddf.png)

のちほど必要になるチャネルシークレット・チャネルアクセストークンをメモしておきます。

![image](https://i.gyazo.com/2ecb660f54ea6642859393d38c58261f.png)

上部のメニューでチャネル基本設定をクリックします。

![image](https://i.gyazo.com/2a14f044f7b5e7983868bb879b9c8464.png)

チャネル基本設定でチャネルシークレットをスクロールを探して、チャネルシークレットをコピーしてメモしておきます。

## チャネルアクセストークンをメモする

![image](https://i.gyazo.com/09da02fd0ecf211aae686575ae26f09a.png)

上部のメニューで Messageing API 設定をクリックします。

![image](https://i.gyazo.com/257d7f2945334257509452089e1b2c2f.png)

Messageing API 設定からチャネルアクセストークン（ロングターム）を探します。
チャネルアクセストークン（ロングターム）がまだ発行されていないので発行ボタンをクリックします。

![image](https://i.gyazo.com/14fe620ea842aaf6ea2ce51d5782b52e.png)

チャネルアクセストークンが発行されるので、赤い矢印で示したコピーできるボタンをクリックしてコピーしてメモしておきます。

これくらい長い文字列を手で選択してコピーすると、カーソルがズレたりうまく全部コピーできなくて、あとでバグを生みやすいので、コピーボタン利用でお願いします！

## チャネルアクセストークンとチャネルシークレットは BOT の大切な設定です

![image](https://i.gyazo.com/19c9bce2a892144f6c514d805098b70d.png)

チャネルアクセストークンとチャネルシークレットは BOT の大切な設定です。

間違いなくメモできているか、いま一度、確認しましょう。

## BOT の設定を変更する

BOT の設定をしていきます。

![image](https://i.gyazo.com/463bc511b0eb7f6d489a2370c7d9705d.png)

上部のメニューで Messageing API 設定をクリックします。

![image](https://i.gyazo.com/dba92aed365f3d3717448f297c420c11.png)

つづいて、LINE公式アカウント機能の欄で、たとえば、応答メッセージの横にある編集ボタンをクリックするとLINE公式アカウントマネージャーに移動します。

![image](https://i.gyazo.com/d8bc8b44c44577d411a231690486c9da.png)

移動しました。

![image](https://i.gyazo.com/e16e36a28c3405b9ed672f8aa707cb8b.png)

右メニューから応答設定をクリックします。

![image](https://i.gyazo.com/bbbfa50856c244333e29f0c0cf080af4.png)

- 応答メッセージ
  - オフ
- あいさつメッセージ
  - オフ
- Webhook
  - オン

に設定します。

![image](https://i.gyazo.com/3e5dbe3839bb48b74d90dd2ce06d214f.png)

アカウント設定をクリックします。

![image](https://i.gyazo.com/087291cfb097af213b2393cc9802ce82.png)

チャットへの参加の項目で、`グループ・複数人チャットへの参加を許可する` をクリックして設定します。

![image](https://i.gyazo.com/e16e36a28c3405b9ed672f8aa707cb8b.png)

Webhookのオンはうまく反映されない場合があります。もう一度、右メニューから応答設定をクリックして、確認しましょう。

![image](https://i.gyazo.com/e1acdc8c35cb5427786b5d3d8a2317fa.png)

Webhook　がオンになっていればOKです。


## BOTと友達になろう

ここまで準備が出来たら、BOTと友達になりましょう。

LINE Developers の画面に戻り、自分のプロバイダーから、今回の LINE BOT を選択します。

![image](https://i.gyazo.com/3005dee9322bd8cac7ed7c54fa394525.png)

もし、プロバイダーが見つからない方は、自分のプロフィールページに移動してから、右メニューにあるプロバイダーをクリックします。

![image](https://i.gyazo.com/2dbb7bc5badd542ee4f6235a0a27ae71.png)

プロバイダーの中のチャネルを選ぶ画面に移動するので、デジハリBOT を選択しましょう。

![image](https://i.gyazo.com/ce2241de3c8e56ce58b7fc2f0f7267c7.png)

上部のメニューで Messageing API 設定をクリックします。

![image](https://i.gyazo.com/3c7059023e9dbc2fb5aeb3b668e2e92d.png)

ここで表示されるQRコードを使って、自分が作成したBotアカウントと友達になりましょう。

![image](https://i.gyazo.com/361130735c8a807e31a7cd22383f07f7.png)

Android や iOS の LINE アプリの画面です。先ほどのQRコードに合わせて読み取ります。 OS やバージョンによって配置が違うかもしれませんのでご注意ください。

![image](https://i.gyazo.com/5c39802cd9f04681c0a41928041da04f.png)

追加をクリックして、友達追加します。追加すると、友達登録され、ウェルカムメッセージが表示されます。

これで、BOTの友達登録の完了です。## SNS からのアウトプットの事例や世界観を把握する

さて、この章では SNS からのアウトプットの事例や世界観を把握していきます。

## アウトプットをするメリット

このようなメリットがあります。

- 学んだこと・得たスキルが定着しやすくなる
  - アウトプットすると学んだことをもう一度なぞることになります。記憶の整理ができたり、あいまいな箇所を学びなおして、自分にとってすぐに取り出せて使える力へと進化するので、作る上でプラスになります。
- 自分自身と向き合える
  - 案外自分のことってわかりません。アウトプットしたことによって、客観的に自分の思考にながめられます。自分独自のコンテンツが増えてくることで、自分の得意分野、自分が盛り上がる分野が見えてきて、本当につくたいものへの精度が上がっていきます。自分の成長を感じることができるのも良いポイントですね。
- 伝える力が身につく
  - Twitter など SNS で自分で伝えるものをアウトプットすることで試行錯誤すると、自分の制作物自体の見せ方であったり、伝える言葉の使い方や分かりやすさであったり、あるいは写真や動画を効果的に使える視点が身につきます。

ほかにも、ファンや人脈が広がったり、気づく力がついたりと、いろいろとありますが、今回はつくる上で大切な部分をピックアップしました。

今日覚えたものも実践して自分の手に馴染ませていくことで自分の力になります！

## アウトプットの活用

Twitter や Facebook をはじめとした SNS ではたくさんのアウトプットがあり、今後作っていく上で力になるのでうまく活用していきましょう。

ということで、まず M5Stack の情報源をまとめたので一緒にながめていきましょう。

[M5Stack 関連のナレッジ](knowledgeknowledge-m5stack)

今後も良い情報があれば、随時更新予定です。

## アウトプットの事例

### 継続は力になる 1 日 1 ツイートの例

M5Stack と、かなりしっかりした車機構の試行錯誤の事例。

[\#あれるくん \#M5Stack \- Twitter検索 / Twitter](https://mobile.twitter.com/search?q=%23%E3%81%82%E3%82%8C%E3%82%8B%E3%81%8F%E3%82%93%20%23M5Stack&src=typed_query&f=live)

発想→制作→アウトプット→フィードバックの流れを作れている。自己フィードバックによる進化。1日目からの進化がすごい。

### 田中講師の事例

とはいえ、これはガッツリしすぎなのもあるので、まずは私の事例のように小さい試行錯誤で、少しずつ進化させていくことを心がけていく中で、うまく SNS でのアウトプットも活用して自分の作りたいものを磨いていきましょう。

ツイート例 : https://twitter.com/1ft_seabass/status/1299586260982349826

![image](https://i.gyazo.com/e1b14952479648b5c936bf1738134531.jpg)

### とはいえまずは

今日学んだことを、手を動かして復習しながら、楽しんでアウトプットしていきましょう。

## 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

左のナビゲーションから「次回への準備」にすすみましょう。# 次回への準備

![image](https://i.gyazo.com/e8c2de3c335352977e011404b57b1801.png)

次回、第 3 回目への準備についてのご連絡です。

- いよいよ次回センサーを扱うので機材リストを揃えるのをよろしくお願いします
  - https://docs.google.com/spreadsheets/d/1wIQr7Tai836nZ1UZrN1AgeSWpsEOh4kjj_LGNmx6O8U/edit#gid=0
  - 現地で探すのは見つからない場合があるので、スイッチサイエンスなどのインターネット通販をご利用ください。
- LINE Notify や LINE BOT は、今後も使うので整えておきましょう
  - 今日は Visual Studio Code や Node.js を使う前提で、進めましたが
  - LINE Developer アカウントや BOT 設定も整えておきましょう
- 次回、アウトプットする宿題が出ます
  - 制作してアウトプットする課題です。
  - いまのところ、発想力・創造力・アウトプット力を軸に評価します。
  - 詳細は次回お伝えします。

## 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

左のナビゲーションから今日の授業の「README」に戻りましょう。# 第3回 プロトタイピング発展概論・環境構築

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第3回　2021年10月08日（金） 8限　21:00 ～ 22:30　遠隔授業
```

※書かれている時間は予想の所要時間です。前後する可能性があります。

- はじめに 5 分 → このページ
- [宿題について](99-homework.md) 5 分
- [Gitpod で LINE BOT と M5Stack 連携を学ぶ](01-00-gitpod-linebot.md) 20 分
- [M5Stack のボタンやディスプレイの実装を学ぶ](02-00-button-display.md) 20 分
- [M5Stack のセンサー連携を学ぶ その1](03-00-sensor01-firststep.md) 30 分
- [M5Stack 事例を通してプロトタイプをアウトプットする世界観を学ぶ](04-m5stack-output.md) 10 分

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 第 3 回の心構え

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

第 3 回では、IoT開発ボード M5Stack 入門です。

M5Stack のボタンやディスプレイの実装をはじめ、センサー連携について学びます。

- 宿題でのアウトプットもしながら最終制作の作るイメージを固めていきましょう。
- M5Stack の具体的な連携を学びながら作ってアウトプットすることで自分が使える力として定着させていきましょう。
- 第 5 回に第 6 回はじめの締め切りでアウトプットの宿題が出ますが、最終制作へ向けて制作物デモもありますし、作りながら徐々に良くしていくことが大切です。
- センサー連携については、今日第 3 回と次回の第 4 回で 2 回にわたって行います。

## 第 3 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- LINE BOT へ M5Stack からメッセージをだす仕組みを改めて把握する
- M5Stack のディスプレイやボタンを基礎から発展させ一歩踏み込んだ使い方を把握する
- M5Stack へのセンサーのつなぎ方を把握する
- M5Stack から行われるアウトプットを眺めて自分のアウトプットを小さくでもつたーとでするレベル感を把握する

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- LINE Developer アカウントを使用でき LINE BOT の設定が友達登録まで済んでいる
  - LINE BOT の作り方は 前回授業の [LINE BOT を作成する](../lecture02/12-line-bot-create.md) を参考にしましょう
- 今回使う LINE BOT の以下情報をプログラムにすぐ使える状態
  - 情報
    - 今回使う LINE BOT のチャンネルシークレット
    - 今回使う LINE BOT のチャンネルアクセストークン
    - 今回使う LINE BOT のユーザー ID
  - チャンネルシークレット・チャンネルアクセストークンは前回授業の [LINE BOT を作成する](../lecture02/12-line-bot-create.md) を参考、ユーザー ID は [M5Stack から LINE BOT にメッセージを送ろう](../lecture02/02-02-line-bot-push.md) を参考にしましょう。
- M5Stack に Arduino IDE からプログラムを書き込むことができる
- M5Stack で Wi-Fi がつながり先週試した HTTP や LINE Notify につながる
- 自分の Gitpod のアカウントが自分の GitHub のアカウントから作成できている
  - [Gitpod のアカウントを取得する](11-gitpod-account.md) を参考にアカウントを作りましょう。

## 授業開始

では授業をはじめましょう！

左のメニューから「Gitpod で LINE BOT と M5Stack」をクリックしましょう。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

# 宿題について

![image](https://i.gyazo.com/1053e8f7fd0a4236ce30284505e4fec3.png)

## 課題全体からの位置づけ

全体としては

```
- 最終課題　50％
  - 発想力・創造力・アウトプット力・継続開発力 の要素で採点する予定です。
- 授業内の課題　50％
  - 機材をそろえて準備する課題 10％予定
  - 制作してアウトプットする課題 20％ * 2 予定
```

で採点を予定しています。

今回は「制作してアウトプットする課題」20 ％部分の 1 回目です。

なお、第 6 回開始前が締め切りで「制作してアウトプットする課題」の宿題がもう一度あります。

## この宿題の意図

今回の宿題は、いわば自分なりのアウトプットをするスタートです。

最終制作に向けて一気に作ったものを一気にプレゼンしても、急なアウトプットではなかなか伝えきれません。もちろん、その状態でうまれた、自分からのフィードバック、ほかの人からのフィードバックでは、自分が聞き入れられずうまくさばけないでしょう。

最終制作の前に徐々にアウトプットと自己フィードバック・ほかの人からのフィードバックに慣れていくことで、つくる力を定着させて、自分自身と向き合って、自分なりの伝え方やペースをつかんでいきましょう。

## この宿題のゴール

今回の宿題で、つくる→アウトプットのうごきをしてみることで、自分なりのつくりつづけアウトプットするペースをつかむことがゴールです。

そのほかに、

- 自分の内から発想してカタチにする感覚をつかむ
- 自分がつくりたいものへの必要な情報を探索して加えていく感覚をつかむ
- 自分でつくることで、学んだことが定着することを実感する

といったことも把握できるようにしましょう。

## 厳守事項

- M5Stack を必ず使用します
- LINE BOT or LINE Notify を必ず使用します

## 採点基準

![image](https://i.gyazo.com/254a09030420cf82ad22c6e95aedd929.png)

こちらの 4 要素で採点します。

- 提出ボーナス 5点
  - 第 1 回なので提出場所に提出するだけで当ボーナスがつきます
- 発想力 5点
  - 自分の今までの知識や経験に基づいて自分なりに思いついているか（独自性）
  - 自由に発想ができているか（自在性）
- 創造力 5点
  - 発想を自分の技術と自分の考えをうまく組み合わせてカタチにできているか
  - 今の自分から得たものとともに新しい価値にチャレンジをしているか
- アウトプット力 5点
  - 制作物を通じて自分の考えをアウトプット出来ているか
  - 狙った他者（ターゲット）に伝わるように工夫できているか

## 採点の目安

![image](https://i.gyazo.com/e9b768f5fbfe123a0947e08388e4333b.png)

今回の採点の目安をお伝えします。次回の宿題では、少し調整する可能性はあります。

- 発想力
  - Lv.1 授業で学んだことから少しだけ変化して発想している
    - 単純な連想レベル
  - Lv.2 授業で学んだことに自分の今までの知識や経験を加味して発想している
    - 自分の作りたいものが感じられる。学んだ仕組みが自分の作りたいものに反映されている
  - Lv.3 授業で学んだことをうまく自分にとりこんで自由に発想している
    - 自分の作りたいものが明確にある。Lv.2 よりも自由度があり、この先に進もうと色々な発想ができている
- 創造力
  - Lv.1 発想したものを授業で学んだ技術を組み合わせてただカタチにしている
    - サンプルを動かしただけのような、発想が小さくカタチにするものも小さい
  - Lv.2 発想したものを授業で学んだ技術だけでなく自分の今までの力を加味してカタチにしている
    - 授業で学んだ技術が自分とうまくとりこまれ、つくるものに反映しだしている
    - 制作物を作ることに精いっぱいで、なんとか現状を伝えようとしている
  - Lv.3 発想したものをカタチにするだけでなく、それにより試行錯誤をして新しい知識や発想が生まれながらつくっている
- アウトプット力
  - Lv.1 ただハッシュタグをつけて文章でできましたとツイートするだけ
    - つくったことはなんとか伝わるが制作物に対する思いや内容が伝わらない
  - Lv.2 文章だけでなく画像や動画を使って分かりやすく制作物を伝えようと工夫しはじめている
    - 制作物の内容（のみ）を他者に伝えるために試行錯誤がしはじめている
  - Lv.3 制作物を伝えつつ自分の発想や制作過程といったそこに至る経緯が伝えようと工夫しはじめている
    - 制作物だけの「点」だけでなく自分の思考や経緯、伝えるターゲットを意識して「線」として結んで考えられる
    - 制作物を作って終わりでなく、途中経過でも自分の考えたつくったものの価値を試すためのプラスととらえはじめている。
    - 徐々にだが、他者のフィードバックとして、他者からのコメントやいいね！を目を向けはじめている
  - **↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ 第1回宿題ではここまでで採点予定 ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑**
  - Lv.4 つくりつづけることを意識して現状のアウトプットを自分の制作も他者へ伝えることも楽しみはじめている
    - 自分の「つくる」という大きな流れの中で行動している。Lv.3 が過去→現在を伝えているとすると、未来も意識しはじめている。
    - 自己のフィードバックとして、今回はここまでだったけど制作物をこうしたい、技術を新しく加えて制作物を発展させたいなど考えはじめている。
    - 他者のフィードバックとして、他者からのコメントやいいね！を目を向けて、今後のブラッシュアップの糧にしようとしている。
  - Lv.5 つくりながらアウトプットしてフィードバックを得てつくるものを日々磨いている
    - Lv.4 の発展した状態。
    - 日々自分と対話しながら技術や発想をカタチにしつづけている。たとえ小さくても何かしらつくっている。
    - 良い意味でつくるための課題が常にあり日々新しい情報の収集や技術習得をしようとしている。
    - つくりつづけているので伝えたい原資があるため、計画的なアウトプットができる。心の中にドラフト（下書き）がある。
    - そのときの興味ある話題に対しても自分のインスピレーションをもち、つくるものにミックスして瞬間的で魅力あるアウトプットを柔軟に行う場合もある。
    - つくりつづけて自分のつくりたいものへの自己フィードバックがカジュアルに持っていて、それ軸にもちつつ SNS や直接の交流からくる他者のフィードバックをうまく取り込んでいる

以上で、

- 発想力
  - Lv.1 ～ Lv.3 の中での到達具合を 5 点に置き換えます
- 創造力
  - Lv.1 ～ Lv.3 の中での到達具合を 5 点に置き換えます
- アウトプット力
  - 今回は Lv.1 ～ Lv.3 での到達具合を 5 点に置き換えます。
  - もしも、Lv.4 と 5 に至った人は自動的に 5 点となります。

となります。

## 〆切

![image](https://i.gyazo.com/ff5cb71c3ed20c019f4657af37ee46bb.png)

- 10/14 木 23:59 厳守
  - 上記時間までに後述する `提出場所` で自分の行の必須項目に書き込んであることが採点される条件です。この時間に記載されてない場合、採点の対象になりません。

## アウトプットTwitter アカウント URL を事前準備しましょう

![image](https://i.gyazo.com/3e1ce3d6bea1099b2f8365cb65cfa882.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=0

- `Twitter アカウント URL` の自分の行に、https://twitter.com/1ft_seabass のような https://twitter.com からはじまるURLでアカウントを記入しましょう。
- このタイミングで、この授業で Twitter でアウトプットしていくアカウントを確定しましょう。
- 講師が授業においてどうアウトプットしていくかを確認できるようにする意図もあります。
- 第 3 回の授業終了までに決めないと、今回の宿題の採点対象になりません。

## 提出場所

![image](https://i.gyazo.com/3e1ce3d6bea1099b2f8365cb65cfa882.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=0

こちらのスプレッドシートに記入します。

- 【必須】 `アウトプットしたツイートURL` に https://twitter.com/1ft_seabass/status/1439097633751003138 のように自分の投稿したツイートが直接見えるURLを記入しましょう。
  - 採点対象となるツイートは 10/1金 ～ 10/14木 のものとします。
- 【必須】 `コメント 300 文字以内` で今回の自分のアウトプットについてコメントを記入しましょう。
  - どういう意図でつくったか（必須）
  - どう伝わることを狙ってアウトプットしたか（必須）
  - ハッシュタグを追加した場合、ハッシュタグの意図
  - そのほか自分のアウトプットへの熱いメッセージあれば
  - 書きつくせなければ、 [note](https://note.com/) などで記事を追加でアウトプットしてもOKです。そのときは、こちらのスプレッドシートに記入ください。

## ツイート時の注意

ツイート時は `#protoout #DHGS #M5Stack` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。
- `#M5Stack` のアウトプットになるので、こちらもつけて、M5Stack 本家や M5Stack でモノづくりしている人の目に留まるようにしましょう！
- そのほか、自分の投稿に合ったハッシュタグを 1 ～ 2 個つけて狙ったターゲットに向けて届けるのも良いでしょう。
- 「自分のつくったものを元に他者に届ける」を大きく逸脱する、今回のアウトプットと関連性のないハッシュタグで無闇に違うターゲットにむけて届けるのは NG です。
  - （余裕があれば例を出す）

## アドバイス

- センサー類は機材リストに縛られず追加購入して試してみてもOKです。
  - Slack で相談してくれれば、サポートできます
- 第 6 回終了の締め切りで「制作してアウトプットする課題」の宿題がもう一度あります。
  - 第 5 回終了後から 1 週間で作るのは余裕がないと思うので、そろそろ「最終制作へ向けてつくりつづけアウトプットするなかで宿題を提出する」心構えがおススメです。
- 完ぺき主義になりすぎずに、いま作れたものを受け入れて活かしていくことが大切
  - 自分の発想したものが、この制作物でどこが試せるのか、検証できるのか、伝えられるのかを良い着地をさせてアウトプットしていきましょう
- アウトプットだけすごい制作物をつくれることも　まれに　ありますが、基本的には、自分で発想して、どうカタチにしようか試行錯誤して創造したもので、行いましょう。こういった、軸のあるところからアウトプットをしたほうが、自分にもほかの人にも響くことが多いです。
  - 自分に合ったワクワクする良い発想は、つくりたくなる良い創造を呼び込み、伝えたくなるアウトプットをしたくなります！


# 応援しています！

![image](https://i.gyazo.com/87f24c002339296dc2cc1689299c4b78.png)

ということで、アウトプット応援しています！

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「」にすすみましょう。# GitHub のアカウント取得する

![image](https://i.gyazo.com/e4bd057b9b3daf8676e449621a69df92.jpg)

https://github.com/ にアクセスします。

![image](https://i.gyazo.com/b1149c857e6864595ccb2ae13b9401a8.png)

Sign up をクリック。

![image](https://i.gyazo.com/f64426db991d3cf1022522f339cec071.png)


- Enter your email
  - GitHub登録用メールアドレス
- Create a password
  - パスワードを指定
- Enter a username
  - 任意のユーザー名
- Would you like to receive product updates and announcements via email?
  - 製品の最新情報、お知らせなどを不定期にメール受け取りたい場合は y
  - 受け取りたくない場合は n

![image](https://i.gyazo.com/032a6f9b5471aa4739cd64436aa14741.png)

Verify your account でユーザー検証を押して進みます。

![image](https://i.gyazo.com/a7c3f03cfe36c1644436c1dedeec962b.png)

検証が済むと Create Account ボタンが表示されるのでクリックします。

以降は [GitHubアカウントの作成方法 \(2021年版\) \- Qiita](https://qiita.com/ayatokura/items/9eabb7ae20752e6dc79d) の、ステップ5移行を参考に、メール認証まで済ませてアカウントを作成してください。
# Gitpod のアカウントを取得する

[GitHubのアカウント作成](12-github-account.md) が済んでいる前提で進めます。

## Gitpod にアクセスして Sign Up する

![image](https://i.gyazo.com/098b415d6474c81f9b67a0a9207f057f.png)

https://www.gitpod.io/ にアクセスします。右上の Login ボタンをクリックします。

![image](https://i.gyazo.com/ef1e53eca8a043c8e057e5601de97fe3.png)

https://gitpod.io/login にアクセスします。

![image](https://i.gyazo.com/aaa06eebd0697a11b000effead29edcd.png)

Continue with GitHub をクリックします。

![image](https://i.gyazo.com/2b8d2665c775a5c582cd990e41e05c4d.png)

GitHub 側で認証が聞かれるので Authorize gitpod-io ボタンをクリックして認証します。

![image](https://i.gyazo.com/a6b16d42d78d38e8092d5bc546288936.png)

Whats New が出るかもしれません。Continue ボタンをクリックして進みます。

![image](https://i.gyazo.com/dfd1e731a66afc5e61e6b477b826a06b.png)

Workspace ページが表示されます。

これでアカウント作成は完了です。正確には GitHub アカウントで Gitpod に入れるようになりました。

## 授業で使うリポジトリを試しに動かしてみる

https://gitpod.io/#https://github.com/1ft-seabass/dhw-pp2-m5stack-linebot-gitpod-2021

にアクセスして、リポジトリを試しに動かしてみましょう。

![image](https://i.gyazo.com/418fcdb0b0bec25f272daedf7af0aed2.png)

ロードがはじまって、

![image](https://i.gyazo.com/45f46b40b282cef6d9792cdaf5f305e9.png)

ロードが進みます。

![image](https://i.gyazo.com/d04f596110fc58b532c914afa1bf07c3.png)

このように読み込まれたら Gitpod アカウント作成成功、および、ワークスペース立ち上げ成功です。

## 小テク：テーマをダークモードに

今回の資料ではダークモードの Visual Studio Code で説明をするので Gitpod の Light テーマは戸惑うかもしれません。ダークモードに変更してみましょう。

![image](https://i.gyazo.com/47501bdcfc376116672bee54a916c764.png)

右上のメニューから View > Command Pallette をクリックします。

![image](https://i.gyazo.com/6737dfcd1c19221015e394eb3d3d3b85.png)

Theme と打ち込んで検索して Preferences: Color Theme をクリックします。

![image](https://i.gyazo.com/cabdddcde7947e5d8c49560883eca484.png)

Dark(Visual Studio)をクリックします。

![image](https://i.gyazo.com/ea1e302f61f12cb578c574406d0d9eaf.png)

これで、ダークモード化が完了です。

## ワークスペースを閉じる

無料ユーザーだとこのまま起動していると、制限時間の 50 時間を消費してしまうのでワークスペースを閉じます。

![image](https://i.gyazo.com/89eaafbfda32cbb0057a9d2241109bf7.png)

左下の Gitpod の文字をクリックします。

![image](https://i.gyazo.com/c779a78481a80d316809739874290539.png)

`Gitpod: Stop Workspace` をクリックして停止します。

![image](https://i.gyazo.com/9390db6e8af50846e85d322962e1d47a.png)

停止できたら Go to Dashboard をクリックします。

![image](https://i.gyazo.com/f4749258899c60b4d4f71fa822067eae.png)

ダッシュボードに今回のワークスペースが停止された状態（グレーの丸）で表示されていたら停止完了です。

## 使用時間の確認もまめに行いましょう

授業だけでなく自分でも使う場合は FREE アカウントの 50 時間利用制限も消費しやすいです。自分のアカウントでログインして、Plans https://gitpod.io/plans のページを見ておきましょう。

![image](https://i.gyazo.com/2697b0a9c6edd42e4047cf69f054ea20.png)


設定および確認お疲れ様でした。




# Grove 情報検索ナレッジ

このページでは、センサーをはじめてつなぐので、ひとつの Grove センサーで、どのように情報をたどって、M5Stack につないでいくかを学んでいきます。

![image](https://i.gyazo.com/9fcf63bc6544379ec184829112da96a4.jpg)

Grove PIR センサーを例にお伝えします。

## センサー名称を把握

[GROVE \- ミニPIRモーションセンサ \- スイッチサイエンス](https://www.switch-science.com/catalog/3584/)

![image](https://i.gyazo.com/b89c828eb16351b4d1ba1f9deeede9c2.jpg)

まず、スイッチサイエンスさんの購入したページにアクセスしてセンサー名称を把握しましょう。

## 検索してみる → 今回は Google 検索

![image](https://i.gyazo.com/765e62fed3f486423184b79122b3b914.png)

名称で `ミニPIRモーションセンサ Wiki` というキーワードで出てきた [Google 検索結果](https://www.google.com/search?q=GROVE+-+%E3%83%9F%E3%83%8BPIR%E3%83%A2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%BB%E3%83%B3%E3%82%B5+Wiki) です。

このように、うまく検索出来れば Seeed Studio 社の日本語の Wiki ページにたどり着きます。

その他にも、

- スイッチサイエンスのページ自体に Wiki のページがリンクされている
  - 英語 Wiki の場合が多いがなんとかなる
- スイッチサイエンスのページから Seeed Studio の商品ページをたどって、ほぼほぼリンクされている使い方 Wiki ページに行く
  - 例 : [Grove \- mini PIR motion sensor \- Seeed Studio](https://www.seeedstudio.com/Grove-mini-PIR-motion-sensor-p-2930.html)
  - だいたい、使い方 Wiki があるって、すごいと思う
- Seeed Studio の商品ページを検索して、上記と同じく、ほぼほぼリンクされている使い方 Wiki ページに行く
  - 英語ページ www.seeedstudio.com は情報がある。使い方リンクが英語。
    - 例 : https://www.seeedstudio.com/Grove-PIR-Motion-Sensor.html
  - うまくいくと日本語ページもあります。メリットは使い方リンクが日本語になりやすい。
    - 例 : https://jp.seeedstudio.com/Grove-mini-PIR-motion-sensor-p-2930.html

といった方法があります。今あげた方法を駆使すればだいたい見つけられます。

## 使い方 Wiki を参考にする

![image](https://i.gyazo.com/e38f0a9afb71138548a31180df42d1a9.jpg)

今回はこちらのページでした。 → [Grove PIRモーションセンサー \- Seeedウィキ（日本語版）](https://wiki.seeedstudio.com/jp/Grove-PIR_Motion_Sensor/)

![image](https://i.gyazo.com/d60ab7ea5718517888f331672fa69e83.png)

右の目次から Arduino の情報を探します。

![image](https://i.gyazo.com/2f49b7e640bfc5a6e4b8355f50938ac4.jpg)

ハードウェアから、デジタル・アナログ・I2Cといったつなぎ方をざっくり把握します。M5Stack では、後ほど紹介する裏面にあるピン情報と照らし合わせて、差し込むピンを決めます。

今回はデジタル入出力のつなぎ方と分かりました。

![image](https://i.gyazo.com/de9436679867cef5fc4360db343dcb4c.png)

ソフトウェアから、実際に Arduino のソースコードがあります。これソースは M5Stack にかなりの部分、そのまま移植できるので効果が大きいです。私自身も、Grove で動かすときに毎回助かっています。

## M5Stack に得た情報を置き換えていく

![image](https://i.gyazo.com/5f10e3f3b044561349b15715894af522.png)

Seeed Studio 社のソースコードは Arduino UNO で動かすことを想定したものなので、M5Stack に合わせて探っていきます。

## Grove コネクタ付近の刻印を見てつなぐ先をイメージする

Grove は、赤・黒・黄・白の4本の Grove ケーブルで、たくさんの複雑なセンサーの接続（デジタル・アナログ・I2C・SPI・UARTなど）をうまくまとめています。

![image](https://i.gyazo.com/89e6b7f598ee0c50beed6178c46c747d.jpg)

このように、各センサーの Grove コネクタの刻印をみてみると、電流を供給する VCC + と GND - があり、NC は No Connect つながない。SIG はシグナル、今回の PIR センサーの場合はデジタルの ON OFF の信号が通ります。

![image](https://i.gyazo.com/9bca8f96f96788acb170a5dd2080827f.jpg)

Grove ケーブルを挿しこむと、赤・黒・黄・白の各カラーが対応しててわかりやすくなり、つなぐときの意識をサポートしてくれます。

このあたり、ブレッドボードやはんだ付けで回路をつくるばあいは、回路全体の電流の流れからつなぐ場所を意識することを考えると、かなり対応しやすいですね。

## VCC GND に挿すピンを探っていきます

VCC GND に挿すピンを探っていきます。

![image](https://i.gyazo.com/7afcd3777488c6a4783fb3a039be2675.jpg)

M5Stack の場合、ピン番号が丁寧に書かれているので、追いやすいです。Grove の場合は、左側のピン穴に挿すものを使うことが多いので、こちらに注目します。

- 赤ケーブル
  - `5V`
- 黒ケーブル
  - G

まず、電流を供給する VCC + と GND - はこうなることが多いです。

まれに 3V 供給のセンサーの場合は赤ケーブルの 5V のところを `3V3` に挿します。

[Grove \- mini PIR motion sensor \- Seeed Studio](https://www.seeedstudio.com/Grove-mini-PIR-motion-sensor-p-2930.html)

の場合は、

![image](https://i.gyazo.com/dcbd1d752ea61aea1a724a27975ae429.png)

Techinical details の Supply Voltage が 3.3 - 5V なのでどちらでも行けますね。

## SIG のつなぎ方を探っていく

![image](https://i.gyazo.com/9bca8f96f96788acb170a5dd2080827f.jpg)

電流の供給が M5Stack のピンに置き換えられたので、残りの NC と SIG に注目しましょう。ケーブルは、白と黄です。

今回、白ケーブルにあたる、NC は No Connect つなぎません。

黄ケーブルを見ていきます。SIG はシグナル、今回の PIR センサーの場合はデジタルの ON OFF の信号が通ります。

![image](https://i.gyazo.com/f88e31194b50d59bc157774f6416a499.png)

こういった情報も、[Grove PIRモーションセンサー \- Seeedウィキ（日本語版）](https://wiki.seeedstudio.com/jp/Grove-PIR_Motion_Sensor/) に書かれているので確認しながら進めましょう。

![image](https://i.gyazo.com/7afcd3777488c6a4783fb3a039be2675.jpg)

今回は D2 （デジタル入力）なので、M5Stack の場合は、よく 2 か 5 を使います。

このあたりの置き換えのナレッジは私は以下を参考にしてます。

- [m5\-docs/gpio\.md at master · m5stack/m5\-docs](https://github.com/m5stack/m5-docs/blob/master/docs/ja/api/gpio.md)
  - もう少し深く知りたいとき
- [M5Stackでできること 〜使用可能なデジタル入力端子 \- MSR合同会社](https://msr-r.net/m5stack-gpio/)
  - デジタル入出力がどこで使えるか迷ったとき
- [らびやんさんはTwitterを使っています 「M5Stack GPIO表の記述の誤り…12,13,15はLCDでは使ってない。\(14はLCDのCSで使用\) あとG16,17はUARTのほかPSRAMで使用していると追記した方が良さそうな…。 https://t\.co/2IY5JeAoe2」 / Twitter](https://twitter.com/lovyan03/status/1214004705413627910)
  - 進化し続ける M5STack ゆえに情報が追い付いてない悩ましさもあるが、M5Stack 好きな人たちが追っていて楽しい

### 他のつなぎ方にも対応する

デジタルだけでなく、今後、Grove センサーを購入したとして、アナログ・I2C・SPI・UARTなどつなぎ方にも対応するときに、私がどうしているかをシェアします。

私の場合、以下のドキュメントの、

[M5\-Schematic/M5\-Core\-Schematic\(20171206\)\.pdf at master · m5stack/M5\-Schematic](https://github.com/m5stack/M5-Schematic/blob/master/Core/Basic/M5-Core-Schematic(20171206).pdf)

![image](https://i.gyazo.com/174c24dad65b7cea614f3e2d4948d111.png)

の図は結構分かりやすいので、ざっくりこのように読み取りながら使ってます。

- デジタル入出力
  - Arduino 上で D ではじまるもの 例：D2
  - M5Stack裏面の番号
    - 2 , 5
- アナログ入力
  - Arduino 上で A ではじまるもの 例：A0
  - M5Stack裏面の番号
    - 35 , 36
- アナログ出力
  - Arduino 上で A ではじまるもの 例：A0
  - M5Stack裏面の番号
    - 25 , 26
- UART
  - Arduino 上でつなぎ方を RX TX で表現される
  - M5Stack裏面の番号
    - 3 , 1 , 16 , 17
  - 言葉そのものの参考資料（分からなくても使えます）
    - [UARTとは？通信の仕組みを解説 – 衛星ラボ](https://eiseilab.com/uart/)
- I2C
  - Arduino 上でつなぎ方を SDA(データ線) SCL(クロック線) で表現される
  - M5Stack には Grove I2C ポートがあるのでそれを使うのがおススメ
  - 言葉そのものの参考資料（分からなくても使えます）
    - [I2Cの仕組みと使い方 – 衛星ラボ](https://eiseilab.com/i2c/)
- SPI
  - Arduino 上でつなぎ方を MOSI MISO SCK SS で表現される
  - 各センサーのつなぎ方をうまく置き換えて使う。いろいろある。
  - 言葉そのものの参考資料（分からなくても使えます）
    - [SPIの仕組みと使い方 – 衛星ラボ](https://eiseilab.com/spi/)

今回の講義前半では、私の方が上記を整えて、つなぎかたを反映していますが、もしみなさんが自分で Grove センサーを購入してつなぐ場合には、上記のナレッジも意識しつつ、試行錯誤してつなげてみましょう。

![image](https://i.gyazo.com/87f24c002339296dc2cc1689299c4b78.png)

とはいえ、ブレッドボードやはんだ付けでセンサーや回路を一から組んでいくときと比べれば、Grove が応援してくれるところは多いです！うまく案内してくれるはずです！# Gitpod で LINE BOT と M5Stack 連携を学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## Gitpod とは

![image](https://i.gyazo.com/6451152f68865b7eabd6baefa944d8c9.jpg)

新しい開発環境を数秒で自動で構築しブラウザ上で起動するサービスです。開発環境のベースは既存の Git リポジトリをベースにすることができ、たとえば GitHub のようなサービスから開発環境をすぐに構築することできます。

### 手元の PC で環境構築する大半のことを準備してくれる

![image](https://i.gyazo.com/381be0c207f01631d83107e92d1d7f3b.png)

たとえば、前回学んだ [M5Stack から LINE BOT にメッセージを送ろう](../lecture02/02-02-line-bot-push.md) ですが、手元のPCで以下の準備をします。

- Node.js の開発環境を構築する
  - OS ごとに設定が違い、既存のインストールしたもの影響を受ける可能性がある
- Visual Studio Code をインストールしてエディタを準備する
  - ダウンロードなどそれなりの時間
- フォルダを作成して Visual Studio Code ではじめる
  - フォルダを作るだけだが開発しやすい場所にする必要がある
- LINE BOT を動かすために `express` や `@line/bot-sdk` ライブラリをインストール
  - `npm install` すればよいが、場合によっては、インストール時にエラーが出たり、ライブラリの不足による追加インストールなどがある
- app.js のソースコードをコピーアンドペーストあるいは自分でソースコードを準備
  - 各プロジェクトに応じたプログラムが動く

といったことを済ませてから、ようやく開発をすることができます。

### 開発したものの URL の公開も準備してくれる

![image](https://i.gyazo.com/bf10f3c76ff0107bb620d2b509b63f47.png)

また、LINE BOT が出来上がった時に ngrok を使って公開した URL を発行できるようにしますが、そういった部分も Gitpod も替わりに準備してくれます。

# 次にすすみましょう

左のナビゲーションから「Gitpod で LINE BOT スタート」にすすみましょう。# Gitpod で今回の LINE BOT の仕組みをはじめてみる

## 大事なこと

- Chrome ブラウザのなるべく最新版でアクセスしましょう

## 使う Git リポジトリ

すでに、今回の LINE BOT をはじめる環境は作ってあります。

https://github.com/1ft-seabass/dhw-pp2-m5stack-linebot-gitpod-2021 

![image](https://i.gyazo.com/7ae827af1638bebefb1a7d0d7dedce94.png)

こちらを使います。

## Gitpod で構築開始

Gitpod は GitHub 公開されたリポジトリであれば、すぐに `https://www.gitpod.io/#` のあとに GitHub リポジトリのある URL をつけた状態でアクセスすると構築できます。

ということで、以下にアクセスします。

https://www.gitpod.io/#https://github.com/1ft-seabass/dhw-pp2-m5stack-linebot-gitpod-2021

構築がはじまります。

![image](https://i.gyazo.com/668504b5f7cf347e325cd4c51ef7c403.png)

すすんでいきます

![image](https://i.gyazo.com/5acec3af8060d1e00fe3df60209d47da.png)

ここまですすむとだいぶ良い感じです。

![image](https://i.gyazo.com/f074c981bd29de8df0e1b20fb7f6309b.png)

しばらく待つと、このようにブラウザ上で Visual Studio Code が起動し、さきほどの GitHub の Git リポジトリにあるファイルが移植されています。

このあとは、このブラウザ上で Visual Studio Code で作業を進めていきましょう。

## npm install する

`package.json` に、すでに今回使う `express` や `@line/bot-sdk` ライブラリについて登録されているので、 `npm i` することでインストールを開始します。

```bash
npm i
```

コマンドでインストールをはじめます。

![image](https://i.gyazo.com/ae75dab42b90a82312247226cee490d1.png)

はじめてコピーアンドペーストするとブラウザ上で、許可するか聞かれるので、許可しましょう。

![image](https://i.gyazo.com/519376f4d0284d485f5083d0593fc2a7.png)

無事インストールされました。

## 作成したBOTのチャンネルシークレットとチャンネルアクセストークンを反映

```js
// 作成したBOTのチャンネルシークレットとチャンネルアクセストークン
const config = {
  channelSecret: '作成したBOTのチャンネルシークレット',
  channelAccessToken: '作成したBOTのチャンネルアクセストークン'
};
```

[LINE BOT 作成手順](../lecture02/12-line-bot-create.md) で、作成したBOTのチャンネルシークレットとチャンネルアクセストークンを、それぞれ反映します。

わりと編集中にシングルクォーテーション消してしまったり、channelSecretとchannelAccessTokenを、逆に書いたりしてハマるので気をつけましょう。

## M5Stack から来るプッシュ通知の送り先のユーザーIDを反映

まず、プッシュ通知の送り先であるこの BOT のユーザーIDを LINE Developers から取得します。

https://developers.line.biz/ja/

こちらからログインしましょう。

![image](https://i.gyazo.com/b4cff116ffa19c5ed6b6b2c98e15cedb.png)

今回使っている BOT のチャネル設定に移動します。

![image](https://i.gyazo.com/1e959b391cb50becbdff3fd3ca39b3e2.png)

下にスクロールしていくと `あなたのユーザーID` という項目があるので、これをメモしておきます。

```js
// プッシュメッセージで受け取る宛先となる作成したBOTのユーザーID'
const userId = '作成したBOTのユーザーID';
```

`作成したBOTのユーザーID` の部分を先ほどメモしたユーザーIDで書き換えます。

ここまで設定出来たらファイルを保存します。

## app.js を起動してみる

これで準備完了です。

```bash
node app.js
```

こちらのコマンドで app.js を起動してみます。

![image](https://i.gyazo.com/3cd262e2aee82f79b83949de4972a6e8.png)

このように起動します。

![image](https://i.gyazo.com/fb93043a1f85b294ccaa5db911db6165.png)

すぐに新しいブラウザがもうひとつ開いて、今回起動したサーバーのルートアドレスが表示されます。

### 今回のサーバー URL をメモ

![image](https://i.gyazo.com/24e2225aa2e4f7d09b89c6d2ed6ec387.png)

ブラウザのアドレスを見て今回のサーバー URL をメモしておきましょう。

## Webhook URL の更新

https://developers.line.biz/ja/ こちらから、

![image](https://i.gyazo.com/5d1457a134175c620f142f92177ab373.png)

今回使っている BOT の Messaging API 設定に移動します。

![image](https://i.gyazo.com/c85ed28c0caa79951404327636ef1a44.png)

Webhook URL の項目に移動して以下の手順を行います。（大事な設定なので、一息タイミングを置いています）

### さきほどの URL に `/webhook` をつけて反映

![image](https://i.gyazo.com/3c32b8b9286ac4292628af21c546e08b.png)

さきほどの URL `https://**********.gitpod.io` に `/webhook` をつけて Webhook URL の項目に入力して更新ボタンをクリックします。

![image](https://i.gyazo.com/3c32b8b9286ac4292628af21c546e08b.png)

同時に Webhook の利用がオンになっていることも確認しましょう。

## BOT にオウム返しが来るか確認しましょう

一旦ここでちゃんと動いているかオウム返しを確認してみましょう。

![image](https://i.gyazo.com/3bf69c731aca0696a7f70f2dfdd9a670.png)

こちらで設定は出来ました。

# 次にすすみましょう

左のナビゲーションから「M5Stack からメッセージを送る」にすすみましょう。# LINEBOT に M5Stack からメッセージを送る

## 事前準備：ホスト名を準備しましょう

この後の設定で、ホスト名というものが必要になるので、さきほどメモした Gitpod URL からホスト名を分離してメモしておきます。

もし、 `https://3000-hoge-fuga-scnzIUgdS.gitpod.io/` という Gitpod URL の場合は `3000-hoge-fuga-scnzIUgdS.gitpod.io` としてホスト名をメモしておきます。

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/2aac11e5dafe4f5bf9045da64dccf3e2.jpg)

書き込みと同時に Wi-Fi がつながり Launched! というメッセージが Gitpod のサーバーに送られ、 LINE BOT にメッセージが通されます。

![image](https://i.gyazo.com/9e3eb877028c7f9e4b54f1b5994ec2e6.jpg)

さらに A B C 各ボタンを押すと、

![image](https://i.gyazo.com/f1c2f6f8d5ad04acee037335b99c1bfb.png)

押したボタンの情報が LINE BOT に表示されます。

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-07-LINEBotMessageHTTPSToGitpod` というファイル名で保存します。

```c
#include <M5Stack.h>

// 以下2つはHTTPSでデータを送るためのライブラリ
#include <WiFiClientSecure.h>
#include <ssl_client.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");
}

// HTTP でメッセージ送信部分
void send_message(String msg) {

  // 今回送るホスト名 GitPod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";

  WiFiClientSecure clientHTTPS;

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  
  M5.Lcd.println("-> send_message");
  M5.Lcd.print("msg: ");
  M5.Lcd.println(msg);
  
  Serial.println("-> send_messagey");
  Serial.print("msg: ");
  Serial.println(msg);
  
  // ngrok の HTTPS になぜかつながらないので HTTP で対応 ポート番号変更 443 → 80
  if (!clientHTTPS.connect(hostName, 443)) {
    delay(2000);
    return;
  }
  String queryString = msg;

  // TestHTTP からの変更点 2
  // Content-Type: application/json
  // で POST 送信で /from/m5stack に送信
  String request = String("") +
   "POST /from/m5stack HTTP/1.1\r\n" +
   "Host: " + hostName + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/json\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTPS.print(request);
  M5.Lcd.println("clientHTTPS.printed");
  Serial.println("clientHTTPS.printed");
  while (clientHTTPS.connected()) {
    String response = clientHTTPS.readStringUntil('\n');
    if (response == "\r") {
      break;
    }
  }

  // データ送信完了
  M5.Lcd.println("sended.");
  Serial.println("sended.");

  // サーバーから返答を受け取ったらデータを表示
  String response = clientHTTPS.readStringUntil('\n');

  M5.Lcd.println("response:");
  M5.Lcd.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }
}
```


## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## Gitpod のホスト名を反映

```c
  // 今回送るホスト名 Gitpod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";
```

今回送るホスト名 Gitpod のホスト名を反映します。

## M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/2aac11e5dafe4f5bf9045da64dccf3e2.jpg)

うまく設定できていれば、書き込みと同時に Wi-Fi がつながり Launched! というメッセージが Gitpod のサーバーに送られ、 LINE BOT にメッセージが通されます。

![image](https://i.gyazo.com/9e3eb877028c7f9e4b54f1b5994ec2e6.jpg)

さらに A B C 各ボタンを押すと、

![image](https://i.gyazo.com/f1c2f6f8d5ad04acee037335b99c1bfb.png)

押したボタンの情報が LINE BOT に表示されます。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「ディスプレイとボタン実装」にすすみましょう。# M5Stack のボタンやディスプレイの実装を学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## すでに前回の授業で学んでいるボタンとディスプレイの実装

![image](https://i.gyazo.com/c43e51fd3d6ba85b576bcd3d0d13650f.png)

すでに前回の授業で学んでいるボタンとディスプレイの実装ではありますが、もう少し掘り下げます。

## ボタンの詳しい情報

![image](https://i.gyazo.com/adbd8fa5ffc5450b2598126907d912da.png)

ボタンの詳しい情報は、公式ドキュメントを見ると良いです。

[m5\-docs/button\.md at master · m5stack/m5\-docs](https://github.com/m5stack/m5-docs/blob/master/docs/en/api/button.md)

![image](https://i.gyazo.com/921820f0f9fbf88df72acc76d7ee43f9.png)

基本、以前のコードにもあった `M5.BtnA.wasPressed()` の「押されたかどうか」で大体のことはできます。

英語ドキュメントから翻訳ツールを通して整えた内容ですが、以下のようなものがあります。

- `read()`
  - ボタンの状態の読み取りを直接返します。1：押された、0：解放された。
- `isPressed()`
  - Button.read() が最後に呼び出されたときのボタンの状態を返します。1：押された、0：解放された。
- `releasedFor(ミリ秒)`
  - ボタンが押されている（または離されている）かどうかを確認し、ミリ秒単位で指定された時間その状態になっていることを確認します。それに応じてfalse（0）またはtrue（1）を返します。
- `pressedFor(ミリ秒)`
  - ボタンが指定された時間以上押された場合に1を返します。1：押された、0：解放された。
- `lastChange()`
  - ボタンごとの最後の状態を返します。
- `wasReleasefor()`
  - ボタンが離されているかどうかを確認し、ミリ秒単位で指定された時間その状態になっていることを確認します。それに応じてfalse（0）またはtrue（1）を返します。
- `wasReleased()`
  - ボタンが押されるたびに1回だけ1を返します。1：押された、0：解放された。

このように、いろいろ便利な関数があります。

とくに、`pressedFor` のように、ボタンが指定された時間以上押されたかは、自分でイチから組んだ場合はタイマーの実装や、処理が他と重なった時の対応など、たくさんの注意点があるので、すぐに使える関数があるのはありがたいですね。

## ディスプレイの詳しい情報

![image](https://i.gyazo.com/58b30ff54d4fd99dcbb798f3c82147db.png)

ディスプレイの詳しい情報は、公式ドキュメントを見ると良いです。

[m5\-docs/lcd\.md at master · m5stack/m5\-docs](https://github.com/m5stack/m5-docs/blob/master/docs/en/api/lcd.md)

![image](https://i.gyazo.com/ec47767fe7f4f2ada63568a42e7edd96.png)

### すぐ使える定義済みカラーがある

なんといっても、すぐ使える定義済みカラーがあるのは、視認性を高めたり装飾したりと表現に幅が出るのでおススメです。

![image](https://i.gyazo.com/e782a07b4a7ce5356d6c1903384c9166.png)

`M5.Lcd.clear(TFT_ORANGE);` のように使います。一部の定義済みカラーには `TFT_BLACK` が `BLACK` として使えたりするのですが、こういう省略形の文献がハッキリと探せなかったので、試しながら使ってみてください。WHITE , BLACK , BLUE , RED , YELLOW あたりは良く使います。

### そのほかにもいろいろ

そのほかにも

- 丸・三角・ラインの描画
- 読み込んだ JPEG のビットマップ描画
- QR コードの自動生成
- テキストの描画
- プログレスバーの描画などができます

詳しくは以下の文献が分かりやすいので見てみましょう。

- [【M5Stack】第二回 LCDの使い方 全集 \- とある科学の備忘録](https://shizenkarasuzon.hatenablog.com/entry/2020/05/21/012555)
- [【初心者おすすめ】M5Stackライブラリ APIまとめ。公式サイトへのリンク付き。 \| ラズパイの実](https://knt60345blog.com/m5stack_api_list/#toc4)
  - ディスプレイまわりの関数も日本語訳されて分かりやすいです

## テキストのフォントサイズ

正確なレイアウトのためにはフォントサイズの把握は大切です。

[M5Stack Basic と M5Stack Core2 のデフォルトフォントのサイズステップが分かったメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/02/12/m5stack-basic-and-core2-default-fontsize-maybe-7px-knowledge/)

![image](https://i.gyazo.com/c117d8d217095775455aa64fa8fb7df8.jpg)

私の記事を見てみてください。

## 今回のプログラムはどのように動くか

ということで、上記の機能をもう少し踏み込んで作ったプログラムがこちらです。

![image](https://i.gyazo.com/663630ae47c17ce53715f4facbbd0553.jpg)

起動すると PUSH BUTTON! という文字が出てきます。下部には、ボタンの使い方を示すレイアウトが表示されています。

![image](https://i.gyazo.com/1bb9d7a9f43bf616f62bf75b1b1a6bf0.jpg)

A ボタンは OK 、 B ボタンは CANCEL 、 C ボタンは RESET です。

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-11-Button-Display` というファイル名で保存します。

```c
#include <M5Stack.h>


void setup() {
  M5.begin(true, false, true);
  
  M5.Power.begin();

  M5.Lcd.clear(TFT_BLACK);

  // 線を引いてみた目を区切る ちなみに画面サイズは 320 x 240
  M5.Lcd.drawLine(0,200,320,200,WHITE);
  
  // 下部にボタンナビゲーションをつける
  // 描画順は背景から書いて文字を載せる

  // A ボタンの背景
  M5.Lcd.fillRect(28, 204, 80, 26, BLUE);
  M5.Lcd.drawRect(28, 231, 80, 7, BLUE);

  // B ボタンの背景
  M5.Lcd.fillRect(28 + 80 + 15 , 204, 80, 26, RED);
  M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);

  // C ボタンの背景
  M5.Lcd.fillRect(28 + 80 + 15 + 80 + 15 , 204, 75, 26, TFT_GREEN);
  M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, TFT_GREEN);
  
  // A ボタンの説明
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  M5.Lcd.setCursor(55, 210);  // 結構合ってるけど何度も書き出して目視で合わせている
  M5.Lcd.print("OK");

  // B ボタンの説明
  M5.Lcd.setCursor(127, 210);
  M5.Lcd.print("CANCEL");

  // C ボタンの説明
  M5.Lcd.setTextColor(BLACK);
  M5.Lcd.setCursor(227, 210);
  M5.Lcd.print("RESET");

  // テキストを真ん中あたりに出す
  M5.Lcd.setTextSize(4);
  M5.Lcd.setCursor(20, 85);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.print("PUSH BUTTON!");

}

void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, BLUE);
    // テキストを真ん中あたりに出す
    M5.Lcd.setTextSize(5);
    M5.Lcd.setCursor(60, 80);
    M5.Lcd.setTextColor(BLACK);
    M5.Lcd.print("OK ^_^/");
    // 下部の選択状態
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.fillRect(28, 231, 80, 7, WHITE);  // 選択ホワイト
    M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);
    M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, TFT_GREEN);
  } else if (M5.BtnB.wasReleased()) {
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, RED);
    // テキストを真ん中あたりに出す
    M5.Lcd.setTextSize(5);
    M5.Lcd.setCursor(80, 80);  // わかる。ちょっと中央に寄ってないよね。
    M5.Lcd.setTextColor(BLACK);
    M5.Lcd.print("CANCEL");
    // 下部の選択状態
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.drawRect(28, 231, 80, 7, BLUE);
    M5.Lcd.fillRect(28 + 80 + 15, 231, 80, 7, WHITE);  // 選択ホワイト
    M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, TFT_GREEN);
  } else if (M5.BtnC.wasReleased()) {
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, TFT_GREEN);
    // テキストを真ん中あたりに出す
    M5.Lcd.setTextSize(5);
    M5.Lcd.setCursor(90, 80);
    M5.Lcd.setTextColor(BLACK);
    M5.Lcd.print("RESET");
    // 下部の選択状態
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.drawRect(28, 231, 80, 7, BLUE);
    M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);
    M5.Lcd.fillRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, WHITE);  // 選択ホワイト
    // 2 秒後、表示リセットする /////////////////////////
    delay(2000);
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, TFT_BLACK);
    // テキストもリセット
    M5.Lcd.setTextSize(4);
    M5.Lcd.setCursor(20, 85);
    M5.Lcd.setTextColor(WHITE);
    M5.Lcd.print("PUSH BUTTON!");
    // 下部もリセット
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.drawRect(28, 231, 80, 7, BLUE);
    M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);
    M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, WHITE);
  }
}
```

## M5Stack に書き込んでみる

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/663630ae47c17ce53715f4facbbd0553.jpg)

起動すると PUSH BUTTON! という文字が出てきます。下部には、ボタンの使い方を示すレイアウトが表示されています。

![image](https://i.gyazo.com/1bb9d7a9f43bf616f62bf75b1b1a6bf0.jpg)

A ボタンは OK 、 B ボタンは CANCEL 、 C ボタンは RESET です。

このように、ディスプレイの表示も Web におけるスマートフォンでの表示までは自由に行かなくとも、同じような配慮でつくることができ、人が迷いなく触れるナビゲーションを作れることを体験してみてください。

もちろん、絵づくりは大変なところもありますが、楽しんでやってみましょう～。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「センサー連携を学ぶ その1」にすすみましょう。
# M5Stack のセンサー連携を学ぶ その1

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## これからセンサーをつなげていきます

## Grove システムがなぜよいか

[Grove \- Seeed Studio Electronics](https://jp.seeedstudio.com/category/Grove-c-1003.html)

![image](https://i.gyazo.com/b359d329236a0414701c4ccd40fa74d5.jpg)

Grove は Seeed Studio 社が開発した Grove ポートと呼ばれる M5Stack などベースシールド側にある入口に差し込むだけで、すぐにセンサーや動作するもの（アクチュエータ）が使える仕組みです。

3つの特徴があります。

### すぐに使える

![image](https://i.gyazo.com/8265ccd6ddf4957580a7f6aef702acfd.jpg)

Grove コネクタと Grove ポートには逆に差さないように出っ張りがあり、挿し方を間違えて壊してしまったり動かないことが避けられています。

後述するモジュール化やオープンソースであることで、つなぎ方や使い方に（あまり）迷わずすぐに使えます。

### モジュール化

光センサーの例です。

![image](https://i.gyazo.com/bba7efd90c24ac240a80295dc22733e4.jpg)

![image](https://i.gyazo.com/cc53b30650e81d15eab4e7260fa64cde.jpg)

Grove の各パーツは、他にはんだづけやブレッドボードで回路を必要がなく、モジュール（装置・機械・システムを構成する、機能的にまとまった部分）としてまとまっています。

![image](https://i.gyazo.com/a354df133058457c43d811da85e1dbc1.jpg)

たとえば、この光センサーも本来であれば、ブレッドボード上でセンサー抵抗とケーブルが必要です。また、電気の流れを深く理解して回路を作る必要があります。

![image](https://i.gyazo.com/aeb145960b5b0a1ee296c2b7f174d2ef.jpg)

もちろん、回路がうまくいっても実際に動かすマイコンに対して、間違えなくつなげる必要があります。Grove はこのあたりの大部分をカバーしてくれます。

### オープンソース

![image](https://i.gyazo.com/c22ea19f0e1c9ab4aa3e328876a35f42.jpg)

このスイッチサイエンスさんの [GROVE \- 光センサ（パネルタイプ） v1\.1](https://www.switch-science.com/catalog/2854/) のページですが、情報がとても充実しています。

[Grove \- Light Sensor \- Seeed Wiki](https://wiki.seeedstudio.com/Grove-Light_Sensor/)

![image](https://i.gyazo.com/889cae183c6a9c42235c466965761b9b.jpg)

それは、Grove の情報がオープンソースだからです。Grove パーツには、このように、Seeed Studio 社の手厚い Wiki のリファレンスがあり、そこを見るだけで Arduino としてのハードウェアのつなぎ方やソフトウェアとしてのプログラムの書き方がすぐに把握することができます。

実は、電子工作で使うセンサーでもネット上にあまり情報がなかったり、回路図や使い方といった情報も見つかりにくいと、とても開発がしにくく、実際に動かしてたその先、発想して、創造する、アウトプットするところに、なかなか辿り着くことができません。

Grove の仕組みは、オープンソースで情報を公開することによって、制作者がすぐに作れるようにサポートして、さらに触れたことのある人がお互いに情報を共有しやすくしています。

## M5Stack でも Grove が使える

![image](https://i.gyazo.com/66c41f307332b60ef4f1a35f9589751a.png)

もちろん、M5Stack でも連携ができます。外装がしっかりした M5Stack に対して、機能がひと固まりで、ケーブルを挿すだけで使える Grove をつかえば、基板がむき出しになる場所がかな少なくなり、今後できたものを見せたり触ってもらうときにも、すぐに行動に移すことができます。

![image](https://i.gyazo.com/3a83ebae6f049cf22288a13b2b939e4d.jpg)

今回の機材リストで購入した GROVE 4ピン ジャンパオスケーブルを使うことで M5Stack のピンから

![image](https://i.gyazo.com/a40caafe567107837f463d51077fa6c4.jpg)

また、M5Stack には Grove の I2C ポートを備えています。 I2C でつなぐセンサーは高性能で、少し高価（1500～3000円以上）ではあるので、みなさんのつくりたいものに必要になったら検討してみましょう。授業でも I2C センサーについても、状況に応じてご紹介していく予定です。

# 次にすすみましょう

左のナビゲーションから「人感センサー」にすすみましょう。# Grove 人感センサー（PIR センサー）を動かす

![image](https://i.gyazo.com/9fcf63bc6544379ec184829112da96a4.jpg)

## はじめるまえに

まずは動かす。というプロトタイピングを優先します。つなぐための情報をたどるところは省略し、すぐ挿してプログラムを動かしてみるという流れでお伝えします。

授業中に時間があれば、右メニューの [Grove 情報検索ナレッジ](13-grove-search-knowledge.md) をお伝えする予定です。

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/bc2eb4c34f1e5c361b585a28512b324b.jpg)

書き込みすると、センサーに向けて手をかざすと人の気配を感知（人感）して Sensor ON という大文字が赤背景で出てきます。

![image](https://i.gyazo.com/f0dab9fdedb02b2520208f37cd8a6f0f.jpg)

手をかざすのをやめて、しばらく待っていると、 Sensor OFF に戻ります。

## Grove への Grove ケーブルのつなぎかた

![image](https://i.gyazo.com/f543983e1e18d468f2b155090a24328c.jpg)

機材リストで購入した GROVE 4ピン ジャンパオスケーブル と Grove 人感センサーを用意します。

![image](https://i.gyazo.com/cec530b6f80baed72d7991d269bab922.jpg)

Grove と Grove ケーブルのツメを合わせるように差し込みます。

![image](https://i.gyazo.com/76ad5acfd93bd875b3136ff19d3d4246.jpg)

このように差し込みました。

## 外すときはツメを上げてから取りましょう

![image](https://i.gyazo.com/ba514e766c4081d9f5c1042cdd3f7fe6.jpg)

GROVE 4ピン ジャンパオスケーブル は外すときはツメを上げてから取りましょう。

ツメが噛んでいる状態無理やり抜こうとすると、最悪、Grove コネクタやセンサーが歯損したりします。

## M5Stack への Grove ケーブルのつなぎかた

![image](https://i.gyazo.com/f647ce7a0fce3c02fd6ef24b8521aa83.jpg)

裏面右側のピン番号を合わせて以下のようにつなぎます。

- 赤ケーブル
  - 5V
- 黒ケーブル
  - G
- 白ケーブル
  - つながない
- 黄ケーブル
  - 2

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-08-PIR-sensor` というファイル名で保存します。

```c
#include <M5Stack.h>

// 最新のボタンの状態
int currentButtonState = LOW;

// 記録しているボタンの状態（前の状態を比較する）
int buttonState = LOW;

// 黄色いケーブルを差し込む M5Stack ピン番号
int digitalPin = 2;

void setup() {
  
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  M5.Power.begin();

  M5.Lcd.clear(BLACK);
  M5.Lcd.setTextSize(3);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.print("PIR Digital");

}

void loop() {
  M5.update();

  // 値を取得
  int currentButtonState = digitalRead(digitalPin);

  // 値に変化があれば通知
  if( currentButtonState != buttonState ){
    // 現在の状態を記録
    buttonState = currentButtonState;
    if (buttonState == HIGH) {
      // 人感検出 ON
      M5.Lcd.setTextSize(5);
      M5.Lcd.clear(RED);
      M5.Lcd.setCursor(10, 100);  // 良い感じに真ん中に出すカーソル移動
      M5.Lcd.setTextColor(BLACK);
      M5.Lcd.print("Sensor ON");
    } else {
      // 人感検出 OFF
      M5.Lcd.setTextSize(3);
      M5.Lcd.clear(BLACK);
      M5.Lcd.setCursor(10, 100);  // 良い感じに真ん中に出すカーソル移動
      M5.Lcd.setTextColor(WHITE);
      M5.Lcd.print("Sensor OFF");
    }
  }
  
  delay(500);
}
```

## M5Stack に書き込んでみる

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/bc2eb4c34f1e5c361b585a28512b324b.jpg)

書き込みすると、センサーに向けて手をかざすと人の気配を感知（人感）して Sensor ON という大文字が赤背景で出てきます。

![image](https://i.gyazo.com/f0dab9fdedb02b2520208f37cd8a6f0f.jpg)

手をかざすのをやめて、しばらく待っていると、 Sensor OFF に戻ります。

## LINE BOT と連携するソースコードを試す

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-08-PIR-sensor-LINE-BOT` というファイル名で保存します。

```c
#include <M5Stack.h>

// 以下2つはHTTPSでデータを送るためのライブラリ
#include <WiFiClientSecure.h>
#include <ssl_client.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

// 最新のボタンの状態
int currentButtonState = LOW;

// 記録しているボタンの状態（前の状態を比較する）
int buttonState = LOW;

// 黄色いケーブルを差し込む M5Stack ピン番号
int digitalPin = 2;

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");
}

// HTTP でメッセージ送信部分
void send_message(String msg) {

  // 今回送るホスト名 GitPod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";

  WiFiClientSecure clientHTTPS;
  
  Serial.println("-> send_message");
  Serial.print("msg: ");
  Serial.println(msg);
  
  // ngrok の HTTPS になぜかつながらないので HTTP で対応 ポート番号変更 443 → 80
  if (!clientHTTPS.connect(hostName, 443)) {
    delay(2000);
    return;
  }
  String queryString = msg;

  // TestHTTP からの変更点 2
  // Content-Type: application/json
  // で POST 送信で /from/m5stack に送信
  String request = String("") +
   "POST /from/m5stack HTTP/1.1\r\n" +
   "Host: " + hostName + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/json\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTPS.print(request);
  
  Serial.println("clientHTTPS.printed");
  while (clientHTTPS.connected()) {
    String response = clientHTTPS.readStringUntil('\n');
    if (response == "\r") {
      break;
    }
  }

  // データ送信完了
  Serial.println("sended.");

  // サーバーから返答を受け取ったらデータを表示
  String response = clientHTTPS.readStringUntil('\n');

  Serial.println("response:");
  Serial.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();

  // センサーから値を取得
  int currentButtonState = digitalRead(digitalPin);

  // 値に変化があれば通知
  if( currentButtonState != buttonState ){
    // 現在の状態を記録
    buttonState = currentButtonState;
    if (buttonState == HIGH) {
      // 人感検出 ON
      M5.Lcd.setTextSize(5);
      M5.Lcd.clear(RED);
      M5.Lcd.setCursor(10, 100);  // 良い感じに真ん中に出すカーソル移動
      M5.Lcd.setTextColor(BLACK);
      M5.Lcd.print("Sensor ON");
      // JSON 形式のメッセージを飛ばす
      send_message("{\"message\":\"Sensor ON\"}");
    } else {
      // 人感検出 OFF
      M5.Lcd.setTextSize(3);
      M5.Lcd.clear(BLACK);
      M5.Lcd.setCursor(10, 100);  // 良い感じに真ん中に出すカーソル移動
      M5.Lcd.setTextColor(WHITE);
      M5.Lcd.print("Sensor OFF");
      // JSON 形式のメッセージを飛ばす
      send_message("{\"message\":\"Sensor OFF\"}");
    }
  }
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }

  delay(500);
}
```


## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## Gitpod のホスト名を反映

```c
  // 今回送るホスト名 Gitpod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";
```

今回送るホスト名 Gitpod のホスト名を反映します。

## LINE BOT 連携のプログラムを M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## LINE BOT 連携のプログラムを M5Stack に動かしてみる

起動してみると Launched! というメッセージが Gitpod 経由で LINE BOT のほうに送られます。

![image](https://i.gyazo.com/bc2eb4c34f1e5c361b585a28512b324b.jpg)

センサーに向けて手をかざすと人の気配を感知（人感）して Sensor ON という大文字が赤背景で出たうえで Sensor ON というメッセージが送られます。

![image](https://i.gyazo.com/7dd395ce41abe0c8ae92268404115e18.png)

LINE BOT はこのようにメッセージが送られています。

# 次にすすみましょう

左のナビゲーションから「光センサー」にすすみましょう。# Grove 光センサー を動かす

![image](https://i.gyazo.com/f894d7925f9335f8982e33b5f56ee83d.jpg)

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/819cd1259c50711ce5521e06c0771647.jpg)

書き込みすると、光センサーが明るさを感知してディスプレイに明るさをパーセンテージで表示します。

## Grove への Grove ケーブルのつなぎかた

Grove と Grove ケーブルのツメを合わせるように差し込みます。

![image](https://i.gyazo.com/b9775c0daa5367bda28b6eb4e80dcbcc.jpg)

このように差し込みました。

## M5Stack への Grove ケーブルのつなぎかた

![image](https://i.gyazo.com/d771bba6a2e3d54e10b093c557a0acee.jpg)

裏面右側のピン番号を合わせて以下のようにつなぎます。

- 赤ケーブル
  - 5V
- 黒ケーブル
  - G
- 白ケーブル
  - つながない
- 黄ケーブル
  - 35

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-09-Light-sensor` というファイル名で保存します。

```c
#include <M5Stack.h>

// 光センサーの値
int currentLightValue = 0;

// 記録しているボタンの状態（前の状態を比較する）
int lightValue = 0;

// 黄色いケーブルを差し込む M5Stack ピン番号
int analogPin = 35;

void setup() {
  
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  M5.Power.begin();

  M5.Lcd.clear(BLACK);
  M5.Lcd.setTextSize(3);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.print("Light Analog");

  // スピーカーぱちぱち音対策
  dacWrite(25, 0); // Speaker OFF
}

void loop() {
  M5.update();

  // まずアナログ値の素の値として取得 0 - 4096
  int lightSensorBaseValue = analogRead(analogPin);

  // 4096 を最大値としてパーセント値にする
  currentLightValue = lightSensorBaseValue / 4096.00 * 100.00; 
  
  M5.Lcd.clear(BLACK);
  M5.Lcd.setCursor(0, 100);
  
  // 2行目
  M5.Lcd.println("[Light Sensor]");
  M5.Lcd.print("Percent : ");
  M5.Lcd.print(currentLightValue);
  M5.Lcd.println("%");
  
  delay(500);
}
```

## M5Stack に書き込んでみる

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/819cd1259c50711ce5521e06c0771647.jpg)

書き込みすると、光センサーが明るさを感知してディスプレイに明るさをパーセンテージで表示します。

![image](https://i.gyazo.com/ede4ddeffc7c3235e0f3439e8d0b64c3.jpg)

手で隠すと暗くなりパーセンテージが変化することも確認してみましょう。

## LINE BOT と連携するソースコードを試す

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-09-Light-sensor-LINE-BOT` というファイル名で保存します。

```c
#include <M5Stack.h>

// 以下2つはHTTPSでデータを送るためのライブラリ
#include <WiFiClientSecure.h>
#include <ssl_client.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

// 光センサーの値
int currentLightValue = 0;

// 明るいかくらいかの判定 1/0
int currentLightFlag = 1;

// 記録しているボタンの状態（前の状態を比較する）
int lightValue = 0;

// 黄色いケーブルを差し込む M5Stack ピン番号
int analogPin = 35;
void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スピーカーぱちぱち音対策
  dacWrite(25, 0); // Speaker OFF

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");
}

// HTTP でメッセージ送信部分
void send_message(String msg) {

  // 今回送るホスト名 GitPod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";

  WiFiClientSecure clientHTTPS;
  
  Serial.println("-> send_message");
  Serial.print("msg: ");
  Serial.println(msg);
  
  // ngrok の HTTPS になぜかつながらないので HTTP で対応 ポート番号変更 443 → 80
  if (!clientHTTPS.connect(hostName, 443)) {
    delay(2000);
    return;
  }
  String queryString = msg;

  // TestHTTP からの変更点 2
  // Content-Type: application/json
  // で POST 送信で /from/m5stack に送信
  String request = String("") +
   "POST /from/m5stack HTTP/1.1\r\n" +
   "Host: " + hostName + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/json\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTPS.print(request);
  
  Serial.println("clientHTTPS.printed");
  while (clientHTTPS.connected()) {
    String response = clientHTTPS.readStringUntil('\n');
    if (response == "\r") {
      break;
    }
  }

  // データ送信完了
  Serial.println("sended.");

  // サーバーから返答を受け取ったらデータを表示
  String response = clientHTTPS.readStringUntil('\n');

  Serial.println("response:");
  Serial.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();

  // まずアナログ値の素の値として取得 0 - 4096
  int lightSensorBaseValue = analogRead(analogPin);

  // 4096 を最大値としてパーセント値にする
  currentLightValue = lightSensorBaseValue / 4096.00 * 100.00; 
  
  M5.Lcd.clear(BLACK);
  M5.Lcd.setCursor(0, 100);
  
  // 2行目
  M5.Lcd.println("[Light Sensor]");
  M5.Lcd.print("Percent : ");
  M5.Lcd.print(currentLightValue);
  M5.Lcd.println("%");

  // 暗くなったらメッセージを送る
  if(currentLightFlag == 1){
    // 明るいとき 5%以上
    if( currentLightValue < 5.0 ){
      // 暗くなったらメッセージ
      send_message("{\"message\":\"Dark\"}");
      // 暗くなったフラグ
      currentLightFlag = 0;
    }
  } else {
    // 暗いとき
    if( currentLightValue > 5.0 ){
      // 明るくなったらメッセージ
      send_message("{\"message\":\"Light\"}");
      // 明るくなったフラグ
      currentLightFlag = 1;
    }
  }
  
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }

  delay(500);
}
```


## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## Gitpod のホスト名を反映

```c
  // 今回送るホスト名 Gitpod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";
```

今回送るホスト名 Gitpod のホスト名を反映します。

## LINE BOT 連携のプログラムを M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## LINE BOT 連携のプログラムを M5Stack に動かしてみる

起動してみると Launched! というメッセージが Gitpod 経由で LINE BOT のほうに送られます。

![image](https://i.gyazo.com/ede4ddeffc7c3235e0f3439e8d0b64c3.jpg)

光センサーを手で隠すと暗くなると Dark というメッセージを送ります。5 %未満。

![image](https://i.gyazo.com/819cd1259c50711ce5521e06c0771647.jpg)

暗くしてから、明るくすると Light というメッセージを送ります。

![image](https://i.gyazo.com/7ca06702a4d1771f163097131bb5d9a6.png)

LINE BOT はこのようにメッセージが送られています。

# 次にすすみましょう

左のナビゲーションから「温度・湿度センサー」にすすみましょう。# Grove 温度・湿度センサー を動かす

![image](https://i.gyazo.com/8d5578f02a146a3410715b675a3620c2.jpg)

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/83d7047c299d09bae2db87215ceda1e6.jpg)

書き込むと 温度と湿度データが表示されます。

## Grove への Grove ケーブルのつなぎかた

Grove と Grove ケーブルのツメを合わせるように差し込みます。

![image](https://i.gyazo.com/8ce9947a4620d5891ca3548ff1afed3e.jpg)

このように差し込みました。

## M5Stack への Grove ケーブルのつなぎかた

![image](https://i.gyazo.com/799ed69fbe277c5ba0e4fd518fe07e5e.jpg)

裏面右側のピン番号を合わせて以下のようにつなぎます。

- 赤ケーブル
  - 5V
- 黒ケーブル
  - G
- 白ケーブル
  - つながない
- 黄ケーブル
  - 2

## ライブラリをインストール

GitHub の [Seeed\-Studio/Grove\_Temperature\_And\_Humidity\_Sensor のライブラリページ](https://github.com/Seeed-Studio/Grove_Temperature_And_Humidity_Sensor) にアクセスします。

![image](https://i.gyazo.com/6d89dd6d6e9e7cb525293399e4bdf363.png)

Code ボタンをクリックして Download ZIP ボタンからダウンロードします。

![image](https://i.gyazo.com/854ed3b2de05ebb38e187135f9e58de2.png)

スケッチ > ライブラリをインクルード > .ZIP形式のライブラリをインストール をクリックします。

![image](https://i.gyazo.com/bee83bbc530e3a6b8df8b7291212a744.png)

先ほどダウンロードした ZIP ファイルを選択してインストールします。こちらは Windows のファイル選択ですが、Mac の人は適宜読み替えてください。

これでインストール完了です。

![image](https://i.gyazo.com/0926b156ff8ee87a9a8b626d80bbeb92.png)

ツール > ライブラリを管理で、

![image](https://i.gyazo.com/0d505f636d7fa9263971c8af80daccb6.png)

タイプをインストール済みで絞り込んで、Grove Temperature And Humidity Sensor がインストールされていればインストール成功です。

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-10-TempHumid-sensor` というファイル名で保存します。

```c
#include <M5Stack.h>

// 今回のセンサー DHT 11 のライブラリの呼び出し
#include "DHT.h"
#define DHTTYPE DHT11   // DHT 11
// 黄色いケーブルを挿すピンは 2 番ピン
#define DHTPIN 2
// ライブラリの宣言
DHT dht(DHTPIN, DHTTYPE);

void setup() {
  // init lcd, serial, but don't init sd card
  M5.begin(true, false, true);

  Wire.begin();
  
  M5.Power.begin();

  M5.Lcd.clear(BLACK);
  M5.Lcd.setTextSize(3);
  M5.Lcd.print("TempHumid");
  M5.Lcd.setTextColor(WHITE);

  // スピーカーぱちぱち音対策
  dacWrite(25, 0); // Speaker OFF

  dht.begin();
}

void loop() {
  M5.update();

  // 温度データを取得
  float temp_hum_val[2] = {0};
  
  if (!dht.readTempAndHumidity(temp_hum_val)) {
      Serial.print("Humid: ");
      Serial.print(temp_hum_val[0]);
      Serial.print(" %\t");
      Serial.print("Temp: ");
      Serial.print(temp_hum_val[1]);
      Serial.println(" *C");
  } else {
      Serial.println("Failed to get temprature and humidity value.");
  }
  
  M5.Lcd.clear(BLACK);
  M5.Lcd.setCursor(0, 100);
  // 1行目
  M5.Lcd.print("Humid : ");
  M5.Lcd.print(temp_hum_val[0]);
  M5.Lcd.println(" %");
  // 2行目
  M5.Lcd.print("Temp : ");
  M5.Lcd.print(temp_hum_val[1]);
  M5.Lcd.println(" C");

  delay(1500);
}
```

## M5Stack に書き込んでみる

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

### A fatal error occurred: Timed out waiting for packet header が出たら

![image](https://i.gyazo.com/c6d032401793930db1f0cf8909df7c92.png)

このエラーが出た場合は、

![image](https://i.gyazo.com/d56186fe56aedbdb20ab093d65179cda.jpg)

一度、Grove ケーブルを外してから、書き込んでみましょう。温度湿度センサーの仕組み（ Wire あたり）が、ときどき処理を邪魔することがあることが原因です。

## 動かしてみる

![image](https://i.gyazo.com/83d7047c299d09bae2db87215ceda1e6.jpg)

動かしてみると、このように温度と湿度データが表示されます。

2 ～ 3 分しばらく置いていると安定してきますが、他の温度計と比べてみると高めに推移しやすいので、実際に使う場合は、他の温度計で示す温度と見比べて、補正して対応しましょう。

## LINE BOT と連携するソースコードを試す

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-10-TempHumid-sensor-LINE-BOT` というファイル名で保存します。

```c
#include <M5Stack.h>

// 以下2つはHTTPSでデータを送るためのライブラリ
#include <WiFiClientSecure.h>
#include <ssl_client.h>

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

// 今回のセンサー DHT 11 のライブラリの呼び出し
#include "DHT.h"
#define DHTTYPE DHT11   // DHT 11
// 黄色いケーブルを挿すピンは 2 番ピン
#define DHTPIN 2
// ライブラリの宣言
DHT dht(DHTPIN, DHTTYPE);

// カウントダウン用変数 メッセージを送った時間
long messageSentAt = 0;

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(10, 10);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
   
  // WiFi 接続開始
  WiFi.begin(ssid, password);
 
  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 
  
  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）
  
  // 起動時に送る
  delay(1000);
  send_message("{\"message\":\"Launched!\"}");

  // スピーカーぱちぱち音対策
  dacWrite(25, 0); // Speaker OFF

  // 温度湿度センサーの開始
  dht.begin();
}

// HTTP でメッセージ送信部分
void send_message(String msg) {

  // 今回送るホスト名 GitPod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";

  WiFiClientSecure clientHTTPS;
  
  Serial.println("-> send_message");
  Serial.print("msg: ");
  Serial.println(msg);
  
  // ngrok の HTTPS になぜかつながらないので HTTP で対応 ポート番号変更 443 → 80
  if (!clientHTTPS.connect(hostName, 443)) {
    delay(2000);
    return;
  }
  String queryString = msg;

  // TestHTTP からの変更点 2
  // Content-Type: application/json
  // で POST 送信で /from/m5stack に送信
  String request = String("") +
   "POST /from/m5stack HTTP/1.1\r\n" +
   "Host: " + hostName + "\r\n" +
   "Content-Length: " + String(queryString.length()) +  "\r\n" + 
   "Content-Type: application/json\r\n\r\n" +
    queryString + "\r\n";
  
  clientHTTPS.print(request);
  
  Serial.println("clientHTTPS.printed");
  while (clientHTTPS.connected()) {
    String response = clientHTTPS.readStringUntil('\n');
    if (response == "\r") {
      break;
    }
  }

  // データ送信完了
  Serial.println("sended.");

  // サーバーから返答を受け取ったらデータを表示
  String response = clientHTTPS.readStringUntil('\n');

  Serial.println("response:");
  Serial.println(response);
  
  delay(2000);
}

void loop() {
  M5.update();

  // 以前の時間から現在の時間 millis() でどれだけ経過したかを計算
  long spanTime = millis() - messageSentAt;

  // 5秒 = 5000ミリ秒に1回送る
  // センサー取得時間は3秒くらいは確保する
  if (spanTime > 5000) {
    // 送った時間を更新
    messageSentAt = millis();
    // 湿度データを取得
    float humidity = dht.readHumidity();
    // 温度データを取得
    float temperature = dht.readTemperature();
  
    M5.Lcd.clear(BLACK);
    M5.Lcd.setCursor(0, 100);
    M5.Lcd.setTextSize(3);
    // 1行目
    M5.Lcd.print("Humid : ");
    M5.Lcd.print(humidity);
    M5.Lcd.println("%");
    // 2行目
    M5.Lcd.print("Temp : ");
    M5.Lcd.print(temperature);
    M5.Lcd.println("C");

    // float値を文字列で連結できるようにする
    String humidityString = String(humidity);
    String temperatureString = String(temperature);
    // JSON 形式のメッセージを送る
    send_message("{\"message\":\"humidity:" + humidityString + "% temperature:" + temperatureString + "C\"}");
  }
  
  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // \" はダブルクォーテーションで囲まれた中で JSON 内のダブルクォーテーションを表現するために \" でエスケープしてます。
    send_message("{\"message\":\"Pushed A\"}");
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed B\"}");
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    send_message("{\"message\":\"Pushed C\"}");
  }

  delay(1000);
}
```


## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## Gitpod のホスト名を反映

```c
  // 今回送るホスト名 Gitpod のホスト名 (https://なし)を反映
  // https://3000-hoge-fuga-scnzIUgdS.gitpod.io/ の場合は 3000-hoge-fuga-scnzIUgdS.gitpod.io
  const char* hostName = "*********************.gitpod.io";
```

今回送るホスト名 Gitpod のホスト名を反映します。

## LINE BOT 連携のプログラムを M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## LINE BOT 連携のプログラムを M5Stack に動かしてみる

起動してみると Launched! というメッセージが Gitpod 経由で LINE BOT のほうに送られます。

![image](https://i.gyazo.com/83d7047c299d09bae2db87215ceda1e6.jpg)

5秒に1回のタイミングで、センサーからデータが取得されて温度と湿度データが表示されます。

同時に、`humidity:42.00% temperature:29.00C` というメッセージが Gitpod 経由で LINE BOT のほうに送られます。

![image](https://i.gyazo.com/1a103f88247796f4e84723799560a28d.png)

LINE BOT はこのようにメッセージが送られています。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「M5Stack 事例を通してプロトタイプをアウトプットする世界観を学ぶ」にすすみましょう。# M5Stack 事例を通してプロトタイプをアウトプットする世界観を学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## M5Stack 事例の世界観

最近のことをみてみても

![image](https://i.gyazo.com/5ebee6bc09e10a0b67696920c1da0924.jpg)

[\#ｽﾀｯｸﾁｬﾝ \- Twitter検索 / Twitter](https://twitter.com/hashtag/%EF%BD%BD%EF%BE%80%EF%BD%AF%EF%BD%B8%EF%BE%81%EF%BD%AC%EF%BE%9D?src=hashtag_click) のように、面白いけども、すごすぎて圧倒されることもあるかとおもいます。

![image](https://i.gyazo.com/61f042971c353e7350df9bc3e1474bd8.jpg)

[しげきさんはTwitterを使っています 「ケーブルがついてるのでイマイチですが、一応歩き始めました。 \#予算1万円ロボット \#M5Stack https://t\.co/gOuTj2HffR」 / Twitter](https://twitter.com/shi78ge/status/1445400528331190273)

これもすごいですね。ただ、これは元々の電子工作や工学への知見がある人が、 M5Stack に出会ってアウトプットしていることなので、もちろんすごいなーと参考にしつつも、自分は自分で学んだことで、つくりアウトプットしていきましょう。

大切なのは、自分の成長です。

![image](https://i.gyazo.com/43cb8f333d24f03fd377aeb7de5219a4.jpg)

[Nakazawa YutaさんはTwitterを使っています 「M5 stackなるものを買ってみた。。。 https://t\.co/7kkJQN4Jpu」 / Twitter](https://twitter.com/yuta_nakazawa/status/1446168609382801433)

買ってみてこれから試していこうという人もいますし、

![image](https://i.gyazo.com/f02cd96d27c3ff59f035026bf889cb19.jpg)

[Takafumi KunoさんはTwitterを使っています 「テトリスのサンプルコード動いた ArduinoのIDEの画面、10年ぶりぐらいに見て懐かしかった　\#M5Stack https://t\.co/fZeCWEMTjP」 / Twitter](https://twitter.com/quno/status/1408661022227845120)

サンプルコード動かしてみて、たのしー！って人もいます。

![image](https://i.gyazo.com/65b0cfbd9aa13394b555f35f7663210f.jpg)

[Tatz@Freelance Engineer & BloggerさんはTwitterを使っています 「M5Stackで二酸化炭素の濃度を監視してみた https://t\.co/lfPb5oQgqq」 / Twitter](https://twitter.com/TatSae/status/1444829894660313088)

もちろん、ロボットやアバターのような派手さはなくても、自分の目指していること試したいことをじっくりやっているひともいます。

![image](https://i.gyazo.com/87f24c002339296dc2cc1689299c4b78.png)

こういった、幅の広さが M5Stack のアウトプットの良いところですので、適度な距離感でをもちつつ、楽しんでいきましょう～。

# 時間があれば

![image](https://i.gyazo.com/881ab6d92f745def0c77d060fb100917.png)

授業中に時間があれば、右メニューの [Grove 情報検索ナレッジ](13-grove-search-knowledge.md) をお伝えする予定です。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

## 次にすすみましょう

左のナビゲーションから今日の授業の「README」に戻りましょう。
# 第 4 回 IoT開発ボード M5Stack 入門

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第4回　2021年10月15日（金） 8限　21:00 ～ 22:30　遠隔授業
```

※書かれている時間は予想の所要時間です。前後する可能性があります。

- はじめに 10 分 → このページ
- LINE BOT と M5Stack 連携の MQTT による発展を学ぶ 30分
- IoT開発ボード M5Stack のセンサー連携を学ぶ その2 30分
- いままでのセンサー・ボタン・ディスプレイ実装とアウトプットへの関係性を学ぶ 10分
- 次回の宿題について 10分

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 宿題お疲れ様でした！

![image](https://i.gyazo.com/292056186195353716d85baaaf401a42.png)

昨日は宿題ひとまずお疲れ様でしたー。ナイスアウトプットです！

これから採点させていただきます。

## 第 4 回の心構え

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

第 4 回では、IoT開発ボード M5Stack 入門です。

LINE BOT と M5Stack 連携の MQTT による発展をはじめ、引き続き、センサーなどの連携について学びます。

- Grove や内蔵機能といった M5Stack 周辺のどのようなアウトプットが出来るか見えてきます
- といいつつも、最終制作の制作物のデモ発表が第 7 回ということを考えると、のこり 2 回しかないので、徐々にギアを上げていきましょう
- この段階で宿題をしつつ自分の作るものが見えてくると、先々のスケジュールが組みやすくなるので頑張りましょう。

## 第 4 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- MQTT で LINE BOT から M5Stack を制御する仕組みを把握しましょう
- スピーカーや加速度センサーといった M5Stack 内蔵機能の動かし方を把握しましょう
- いままで学んだ実装とアウトプットへの関係性を把握しましょう
- 次回を含め今後の宿題についてのイメージを把握しましょう

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- Gidpod で前回動かしたような LINE BOT がすぐに作れる
- 以前の授業で行っている Arduino IDE からの M5Stack プログラムの書き込み作業がスムーズに行える

## 授業開始

では授業をはじめましょう！

左のメニューから「LINE BOT と M5Stack の MQTT 発展」をクリックしましょう。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

#  LINE BOT と M5Stack 連携の MQTT による発展を学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## いままでの LINE BOT の仕組み

![image](https://i.gyazo.com/4bed29421b7aaea13d3caf413b7d95c8.png)

まず、シンプルに Gitpod で LINE BOT のサーバーを立てることで、ユーザーから見た LINE BOT でオウム返しができています。

![image](https://i.gyazo.com/4fc47f8fa3d09bb9e57c199a3eabcc2d.png)

そこに、Gitpod の LINE BOT のサーバーで、M5Stack からメッセージを受け付ける入口も作っているので、M5Stack からメッセージを受け取ると、それがユーザーから見た LINE BOT にメッセージが届いています。

![image](https://i.gyazo.com/825b91311bb72283f3a8ecbff2a0dd29.png)

ただ、HTTP の場合は M5Stack から Gitpod の LINE BOT サーバーは公開されているので連絡は出来るのですが、その反対の流れ、Gitpod の LINE BOT サーバーから自宅のルーターなどを通じて奥のほうにある M5Stack に直接メッセージを届けるのは難しいです。

## MQTT という技術を使うことによって LINE → M5Stack も可能にする

![image](https://i.gyazo.com/85fc418d4f7144df2bf53ec41124ef38.png)

MQTT という技術を使うと「自分がどんな名前の機器か」「どこからデータを待ち」「どこへデータを知らせる」という情報を MQTT ブローカーに知らせてあげると、いろいろなデバイスでデータが飛び交っても、目的のところにちゃんと届くようにしてくれます。

しかも双方向。まるで、住所と表札のようなものです。

つまり、ちゃんと表札と住所を持てば M5Stack → LINE だけでなく LINE → M5Stack も可能になるんです。

## 今回は講師の方が MQTT ブローカーを用意しています

![image](https://i.gyazo.com/8643891ef601e8e7d99f1a7b8bdb21c9.png)

本来であれば MQTT ブローカーという指揮者のような役割のサーバーが必要ですが、今回は私（講師）の方が、CloudMQTT というサービスで、ひとつブローカーを立ち上げているので、そのまま使いましょう。

### 11月19日（金）まで使えます、以後は自分でつくりましょう

![image](https://i.gyazo.com/d5d28d3e431e48c644bafdeff11f650f.png)

本カリキュラムが終わる 11月19日（金） ごろまで、使えるようにしているので、制作のためにお使いください。

もし、自分でつくって使いたくなったら、私のブログ記事を参考に作ってみましょう。

- [CloudMQTT で最小プラン Humble Hedgehog でインスタンスを作り最低限の設定をするメモ 2021年9月版 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/09/23/cloudmqtt-setting-minimum-plan-202109/)

# 次にすすみましょう

左のナビゲーションから「LINE BOT と MQTT の仕組みを起動する」にすすみましょう。# LINE BOT と MQTT の仕組みを起動する

## 大事なこと

- ここからは Gitpod の LINE BOT 側の作業です
- Chrome ブラウザのなるべく最新版でアクセスしましょう

## 使う Git リポジトリ

すでに、今回の LINE BOT をはじめる環境は作ってあります。

https://github.com/1ft-seabass/dhw-pp2-2021-m5stack-linebot-mqtt

![image](https://i.gyazo.com/3828efa3f5163641d47e6e61b4ba4bf1.png)

こちらを使います。前回の授業で使ったものとは違うのでご注意ください。

## Gitpod で構築開始

Gitpod は GitHub 公開されたリポジトリであれば、すぐに `https://www.gitpod.io/#` のあとに GitHub リポジトリのある URL をつけた状態でアクセスすると構築できます。

ということで、以下にアクセスします。

https://www.gitpod.io/#https://github.com/1ft-seabass/dhw-pp2-2021-m5stack-linebot-mqtt

構築がはじまります。

![image](https://i.gyazo.com/668504b5f7cf347e325cd4c51ef7c403.png)

すすんでいきます

![image](https://i.gyazo.com/5acec3af8060d1e00fe3df60209d47da.png)

ここまですすむとだいぶ良い感じです。

![image](https://i.gyazo.com/0b1c1b37a07db7ebb55c225516813080.png)

しばらく待つと、このようにブラウザ上で Visual Studio Code が起動し、さきほどの GitHub の Git リポジトリにあるファイルが移植されています。

このあとは、このブラウザ上で Visual Studio Code で作業を進めていきましょう。

## npm install する

`package.json` に、すでに今回使う `express` や `@line/bot-sdk` ライブラリについて登録されています。

また、今回使う `mqtt` という MQTT のライブラリも登録されています。

`npm i` することでインストールを開始します。

```bash
npm i
```

コマンドでインストールします。

## 作成したBOTのチャンネルシークレットとチャンネルアクセストークンを反映

```js
// 作成したBOTのチャンネルシークレットとチャンネルアクセストークン
const config = {
  channelSecret: '作成したBOTのチャンネルシークレット',
  channelAccessToken: '作成したBOTのチャンネルアクセストークン'
};
```

[LINE BOT 作成手順](../lecture02/12-line-bot-create.md) で、作成したBOTのチャンネルシークレットとチャンネルアクセストークンを、それぞれ反映します。

わりと編集中にシングルクォーテーション消してしまったり、channelSecretとchannelAccessTokenを、逆に書いたりしてハマるので気をつけましょう。

## M5Stack から来るプッシュ通知の送り先のユーザーIDを反映

まず、プッシュ通知の送り先であるこの BOT のユーザーIDを LINE Developers から取得します。

https://developers.line.biz/ja/

こちらからログインしましょう。

![image](https://i.gyazo.com/b4cff116ffa19c5ed6b6b2c98e15cedb.png)

今回使っている BOT のチャネル設定に移動します。

![image](https://i.gyazo.com/1e959b391cb50becbdff3fd3ca39b3e2.png)

下にスクロールしていくと `あなたのユーザーID` という項目があるので、これをメモしておきます。

```js
// プッシュメッセージで受け取る宛先となる作成したBOTのユーザーID'
const userId = '作成したBOTのユーザーID';
```

`作成したBOTのユーザーID` の部分を先ほどメモしたユーザーIDで書き換えます。

ここまで設定出来たらファイルを保存します。

## MQTT の接続設定

冒頭でもお知らせしたとおり、本来であれば MQTT ブローカーという指揮者のような役割のサーバーが必要ですが、今回は私（講師）の方が、CloudMQTT というサービスで、ひとつブローカーを立ち上げているので、そのまま使いましょう。

```c
// 今回使う CloudMQTT のブローカーアドレス
const clientMQTTAddress = 'CloudMQTT のブローカーアドレス'

// 今回使う CloudMQTT のポート番号
const clientMQTTPort = 1883;

// 今回使う CloudMQTT のユーザー名
const clientMQTTUserName = 'CloudMQTT のユーザー名';

// 今回使う CloudMQTT のパスワード
const clientMQTTPassword = 'CloudMQTT のパスワード';
```

ここの設定を Slack でお知らせする設定で置き換えましょう。

![image](https://i.gyazo.com/c43f8c427941e95754eb23b151d168ce.png)

このような関係性で動作しています。

### 自分の名前の半角英数字で決める

このあと、M5Stack と LINE BOT がやりとりするトピック名などで、半角英数字の自分の名前を決めておきましょう。

### M5Stack からのデータ受信を待つ MQTT トピックに自分の名前を入れる

```js
clientMQTT.on('connect', function () {
  // 接続時にログ
  console.log('MQTT Connected!');
  // M5Stack からのデータ受信を待ちます
  // M5Stack の A B C ボタンを押したときに送られてきます
  clientMQTT.subscribe('/dhw/pp2/mqtt/YOURNAME/publish');
```

こちらのコードに M5Stack からのデータ受信を待つ MQTT トピック `'/dhw/pp2/mqtt/YOURNAME/publish'` の `YOURNAME` のところに自分の名前を入れます。

半角英数字です。自分の名前は `hogehoge` の場合は `'/dhw/pp2/mqtt/hogehoge/publish'` となります。

![image](https://i.gyazo.com/aa6ac3144d65af9e4e9ab3f09df70242.png)

M5Stack から LINE BOT へやり取りするイメージです。

### M5Stack にデータを送る MQTT トピックに自分の名前を入れる

```js
  // M5Stack が待っているトピックにデータを送る
  clientMQTT.publish('/dhw/pp2/mqtt/YOURNAME/subscribe', jsonString);
```

こちらのコードに、M5Stack にデータを送る MQTT トピック `'/dhw/pp2/mqtt/YOURNAME/subscribe'` の `YOURNAME` に自分の名前を入れます。

半角英数字です。自分の名前は `hogehoge` の場合は `'/dhw/pp2/mqtt/hogehoge/subscribe'` となります。

![image](https://i.gyazo.com/3b5fdcfd4083513c0e07f82e9cf4ca9a.png)

LINE BOT から M5Stack へやり取りするイメージです。

### 11月19日（金）まで使えます、以後は自分でつくりましょう

本カリキュラムが終わる 11月19日（金） ごろまで、使えるようにしているので、制作のためにお使いください。

もし、自分でつくって使いたくなったら、私のブログ記事を参考に作ってみましょう。

- [CloudMQTT で最小プラン Humble Hedgehog でインスタンスを作り最低限の設定をするメモ 2021年9月版 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/09/23/cloudmqtt-setting-minimum-plan-202109/)

## app.js を起動してみる

これで準備完了です。

```bash
node app.js
```

こちらのコマンドで app.js を起動してみます。

![image](https://i.gyazo.com/3cd262e2aee82f79b83949de4972a6e8.png)

このように起動します。

![image](https://i.gyazo.com/fb93043a1f85b294ccaa5db911db6165.png)

すぐに新しいブラウザがもうひとつ開いて、今回起動したサーバーのルートアドレスが表示されます。

### 今回のサーバー URL をメモ

![image](https://i.gyazo.com/24e2225aa2e4f7d09b89c6d2ed6ec387.png)

ブラウザのアドレスを見て今回のサーバー URL をメモしておきましょう。

## Webhook URL の更新

https://developers.line.biz/ja/ こちらから、

![image](https://i.gyazo.com/5d1457a134175c620f142f92177ab373.png)

今回使っている BOT の Messaging API 設定に移動します。

![image](https://i.gyazo.com/c85ed28c0caa79951404327636ef1a44.png)

Webhook URL の項目に移動して以下の手順を行います。（大事な設定なので、一息タイミングを置いています）

### さきほどの URL に `/webhook` をつけて反映

![image](https://i.gyazo.com/3c32b8b9286ac4292628af21c546e08b.png)

さきほどの URL `https://**********.gitpod.io` に `/webhook` をつけて Webhook URL の項目に入力して更新ボタンをクリックします。

![image](https://i.gyazo.com/3c32b8b9286ac4292628af21c546e08b.png)

同時に Webhook の利用がオンになっていることも確認しましょう。

## BOT に返答が来るか確認しましょう

一旦ここで、以下のように動作するか確認してみましょう。

![image](https://i.gyazo.com/caea033f69762e2626a7bfc1a1425f7c.png)

送る文字列は、M5Stack で表示できる半角英数字を試してみましょう。

# 次にすすみましょう

左のナビゲーションから「M5Stack 側の仕組みをつくる」にすすみましょう。# M5Stack 側の仕組みをつくる

## 大事なこと

- ここからは M5Stack と Arduino IDE 側の作業です

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/caea033f69762e2626a7bfc1a1425f7c.png)

半角英数字で LINE BOT 側からメッセージを送ってみましょう。Gitpod の LINE BOT サーバー側から MQTT ブローカーへメッセージが送信されます。

![image](https://i.gyazo.com/70ecb50cfaee17985b012d880f16bafb.jpg)

M5Stack 側で MQTT ブローカーからこのメッセージを受け取るので M5Stack にメッセージが届きます。この例は `DHGS Hello!` を送った例です。

![image](https://i.gyazo.com/baa7f80cba18501b3e5518823eae8594.png)

実際の動きはこのようなイメージです。

## ライブラリを Arduino IDE にインストール

### MQTT のやり取りできるライブラリ PubSubClient をインストールする

この作業はインストールなので、一度だけ対応すれば OK です。

以前の温度湿度センサーは GitHub に行かないとライブラリがなかったですが、これは、とてもやりやすく、Arduino のライブラリ管理から検索してインストールできます。

![image](https://i.gyazo.com/0926b156ff8ee87a9a8b626d80bbeb92.png)

ツール > ライブラリを管理 でライブラリマネージャを起動します。

![image](https://i.gyazo.com/6a82b0efb54bc4a78c3faf643f8b8494.png)

`PubSubClient` で検索して、`完全同名` のライブラリを探します。

![image](https://i.gyazo.com/1e50c2b9a016c7a733822ae9d40bc020.png)

マウスを乗せると、バージョンとインストールのボタンが右下に出るので `2.8` のバージョンを指定してインストールボタンをクリックします。

![image](https://i.gyazo.com/5d4ab17b5a0bf7dc323f20ff5efedf3b.png)

インストールできたら、ひょっとすると、リストが一番上に戻ってしまうかもしれませんが、根気よく `PubSubClient` に移動して INSTALLED になっていたら成功です。

### JSON を扱いやすくする ArduinoJson をインストール

この作業はインストールなので、一度だけ対応すれば OK です。

![image](https://i.gyazo.com/0926b156ff8ee87a9a8b626d80bbeb92.png)

ツール > ライブラリを管理 でライブラリマネージャを起動します。

![image](https://i.gyazo.com/b8b223beedfe7b134fe5380e1920e584.png)

`ArduinoJson` で検索して、`完全同名` のライブラリを探します。

マウスを乗せると、バージョンとインストールのボタンが右下に出るので `6.18.5` のバージョンを指定してインストールボタンをクリックします。

![image](https://i.gyazo.com/ec1d0688667c161c941eced03a1bade9.png)

インストールできたら、ひょっとすると、リストが一番上に戻ってしまうかもしれませんが、根気よく `ArduinoJson` に移動して INSTALLED になっていたら成功です。

### ArduinoJson の情報は充実

![image](https://i.gyazo.com/ce0d85128ef8b9dd91734f1176607439.png)

https://arduinojson.org/ というウェブサイトを持っていて情報が充実しています。

![image](https://i.gyazo.com/35ae79ee668a291a65845fb495bb1f32.png)

ソースコードのサンプルもあり、すぐに使いやすくなっています。

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-12-TestMQTT` というファイル名で保存します。

```c
#include <M5Stack.h>

// Wi-Fi をつなぐためのライブラリ
// 今回は MQTT のため
#include <WiFiClient.h>
#include <WiFi.h>

// MQTT をつなぎためのライブラリ
// 今回追加インストールする
#include <PubSubClient.h>  // インストールすれば色がつく
// JSON を扱いやすくするライブラリ
#include <ArduinoJson.h> // こちらは色がついてなくてOK

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

// 今回使いたい CloudMQTT のブローカーのアドレス
const char *mqttEndpoint = "今回使いたい CloudMQTT のブローカーのアドレス";
// 今回使いたい CloudMQTT のポート
const int mqttPort = 1883;
// 今回使いたい CloudMQTT のユーザー名
const char *mqttUsername = "今回使いたい CloudMQTT のユーザー名";
// 今回使いたい CloudMQTT のパスワード
const char *mqttPassword = "今回使いたい CloudMQTT のパスワード";

// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-YOURNAME";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/YOURNAME/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/YOURNAME/subscribe";

// JSON 送信時に使う buffer
char pubJson[255];

// PubSubClient まわりの準備
WiFiClient httpClient;
PubSubClient mqttClient(httpClient);

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）

  // WiFi 接続開始
  WiFi.begin(ssid, password);

  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）

  // ちゃんとつながったと分かるために 2 秒待ってから MQTT の処理に行く
  delay(2000);

  // MQTT の接続先設定
  mqttClient.setServer(mqttEndpoint, mqttPort);
  // MQTT のデータを受け取った時（購読時）の動作を設定
  mqttClient.setCallback(mqttCallback);
  // MQTT の接続
  mqttConnect();
}



void mqttConnect() {

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  
  // MQTT clientID のランダム化（名称重複対策）
  char clientID[40] = "clientID";
  String rndNum = String(random(0xffffff), HEX);
  String deviceIDRandStr = String(deviceID);
  deviceIDRandStr.concat("-");
  deviceIDRandStr.concat(rndNum);
  deviceIDRandStr.toCharArray(clientID, 40);
  M5.Lcd.println("[MQTT]");
  M5.Lcd.println("");
  M5.Lcd.printf("- clientID ");
  M5.Lcd.println("");
  M5.Lcd.println(clientID);

  // 接続されるまで待ちます
  while (!mqttClient.connected()) {
    if (mqttClient.connect(clientID,mqttUsername,mqttPassword)) {
      Serial.println("Connected.");
      M5.Lcd.println("");
      M5.Lcd.println("- MQTT Connected.");
      
      // subTopic 変数で指定されたトピックに向けてデータを送ります
      int qos = 0;
      mqttClient.subscribe(subTopic, qos);
      Serial.println("Subscribe start.");
      M5.Lcd.println("");
      M5.Lcd.println("- MQTT Subscribe start.");
      M5.Lcd.println(subTopic);

      // 初回データ送信 publish ///////////
      // データ送信のための JSON をつくる
      DynamicJsonDocument doc(1024);
      doc["message"] = "Connected";
      // pubJson という変数に JSON 文字列化されたものが入る
      serializeJson(doc, pubJson);
      // pubTopic 変数で指定されたトピックに向けてデータを送ります
      mqttClient.publish(pubTopic, pubJson);
    } else {
      // MQTT 接続エラーの場合はつながるまで 5 秒ごとに繰り返します
      Serial.print("Failed. Error state=");
      Serial.println(mqttClient.state());
      // Wait 5 seconds before retrying
      delay(5000);
    }
  }
}

// JSON を格納する StaticJsonDocument を準備
StaticJsonDocument<2048> jsonData;

// MQTT のデータを受け取った時（購読時）の動作を設定
void mqttCallback (char* topic, byte* payload, unsigned int length) {
  
  // データ取得
  String str = "";
  Serial.print("Received. topic=");
  Serial.println(topic);
  for (int i = 0; i < length; i++) {
      Serial.print((char)payload[i]);
      str += (char)payload[i];
  }
  Serial.print("\n");

  // 来た文字列を JSON 化して扱いやすくする
  // 変換する対象は jsonData　という変数
  DeserializationError error = deserializeJson(jsonData, str);

  // JSON パースのテスト
  if (error) {
    Serial.print(F("deserializeJson() failed: "));
    Serial.println(error.f_str());
    return;
  }

  // 以下 jsonData 内が JSON として呼び出せる
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  M5.Lcd.println("MQTT Subscribed data");

  // データの取り出し
  // https://arduinojson.org/v6/example/parser/
  const char* message = jsonData["message"];

  // データの表示
  M5.Lcd.setCursor(0, 100);
  M5.Lcd.setTextSize(4);
  M5.Lcd.println(message);
  
}

// 常にチェックして切断されたら復帰できるようにする対応
void mqttLoop() {
  if (!mqttClient.connected()) {
      mqttConnect();
  }
  mqttClient.loop();
}
 
void loop() {

  M5.update();

  // 常にチェックして切断されたら復帰できるようにする対応
  mqttLoop();

  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed A";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed B";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed C";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  }
}
```

## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## MQTT の接続設定を反映

LINE BOT と同じように 今回は私（講師）の方が、CloudMQTT というサービスで、ひとつブローカーを立ち上げているので、そのまま使いましょう。

```c
// 今回使いたい CloudMQTT のブローカーのアドレス
const char *mqttEndpoint = "今回使いたい CloudMQTT のブローカーのアドレス";
// 今回使いたい CloudMQTT のポート
const int mqttPort = 1883;
// 今回使いたい CloudMQTT のユーザー名
const char *mqttUsername = "今回使いたい CloudMQTT のユーザー名";
// 今回使いたい CloudMQTT のパスワード
const char *mqttPassword = "今回使いたい CloudMQTT のパスワード";
```

ここの設定を Slack でお知らせする設定で置き換えましょう。

## LINE BOT でも設定した自分の名前を思い出しましょう

このあと、MQTT の送受信トピックとクライアントIDに自分の名前を反映します。

LINE BOT でも設定した自分の名前を思い出して、`全く同じもの` を使いましょう。

## MQTT の送受信トピックとクライアントIDに自分の名前を反映します

MQTT では「自分がどんな名前の機器か」「どこからデータを待ち」「どこへデータを知らせる」という情報を MQTT ブローカーに知らせてあげると、いろいろなデバイスでデータが飛び交っても、目的のところにちゃんと届くようにしてくれます。しかも双方向。

まるで、住所と表札のようなものです。

とにもかくにも、これが重複してしまうと、違うところにデータが送られてしまったり、自分の名前がほかの人と同じになって混乱してしまいます。

```c
// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-YOURNAME";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/YOURNAME/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/YOURNAME/subscribe";
```

たとえば、hogehoge さんなら YOURNAME を hogehoge に変更します。

```c
// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-hogehoge";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/hogehoge/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/hogehoge/subscribe";
```

ということで、こちらの以下の説明を見つつ変更していきましょう。

- デバイスID ≒ 表札
  - hogehoge さんなら YOURNAME を hogehoge に変更します。- hogehoge さんなら YOURNAME を hogehoge に変更します。
    - つまり、 `"M5Stack-YOURNAME"` を `"M5Stack-hogehoge"` に変更します。
  - MQTTの設定ではクライアントIDという扱いになっていて、ソースコードを追っていくと最終的にクライアントIDとして割り当てられます
    - ここではこのデバイスIDの名称に、後の処理でさらにランダム値を付与してます。`M5Stack-hogehoge` であれば `M5Stack-hogehoge-43ff13` のようなランダム値が加わります。
    - デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが名前を変えるのが確実なので、ちゃんと変更しましょう。
- MQTT メッセージを知らせるトピック ≒ 手紙を送る住所
  - hogehoge さんなら YOURNAME を hogehoge に変更します。
    - つまり、 `"/dhw/pp2/mqtt/YOURNAME/publish"` を `"/dhw/pp2/mqtt/hogehoge/publish"` に変更します。
- MQTT メッセージを待つトピック ≒ 手紙を受け付ける住所
  - hogehoge さんなら YOURNAME を hogehoge に変更します。
    - つまり、 `"/dhw/pp2/mqtt/YOURNAME/subscribe"` を `"/dhw/pp2/mqtt/hogehoge/subscribe"` に変更します。


## M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## LINE BOT の Gitpod がスリープしてたら起こす

![image](https://i.gyazo.com/9bf4ba6a54072e0d6a08ae66a7c9ceca.png)

ここまで作業で時間が経過していると、LINE BOT の Gitpod がスリープしているかもしれません。

そのときは、Open Workspace で起こしてあげましょう。

## 動かしてみる

![image](https://i.gyazo.com/2c6b403d3913cf02138e19cb25a68193.jpg)

書き込みと同時に Connected というメッセージが MQTT ブローカーに送信されます。

実際に M5Stack から接続されているデバイスID（clientID）やデータを待ち受けるトピック subscribe が表示されているので YOURNAME になっていないかや、設定した名前が Gitpod 側で設定した名前と一致しているかを確認しましょう。

![image](https://i.gyazo.com/956797f426bacaf2caa91a2023a3cadb.png)

同時に、Gitpod の LINE BOT サーバー側で MQTT ブローカーから Connected のデータを受け取るので LINE BOT にメッセージが届きます。

同様に ABC のボタンを押すと同じ流れでメッセージが送られます。これが、まず、 MQTT ブローカーが中継した M5Stack と LINE BOT のまずは動作確認です。

ABC のボタンを押す段階では M5Stack の画面に変化はなくて大丈夫です。

![image](https://i.gyazo.com/caea033f69762e2626a7bfc1a1425f7c.png)

つづいて、半角英数字で LINE BOT 側からメッセージを送ってみましょう。Gitpod の LINE BOT サーバー側から MQTT ブローカーへメッセージが送信されます。

![image](https://i.gyazo.com/70ecb50cfaee17985b012d880f16bafb.jpg)

M5Stack 側で MQTT ブローカーからこのメッセージを受け取るので M5Stack にメッセージが届きます。この例は `DHGS Hello!` を送った例です。

### うまく動かない場合は MQTT のトピックを確認してみましょう

うまくいかない場合の一つの原因として MQTT のトピックが M5Stack と Gitpod の LINE BOT サーバとでうまく紐づいていないことがあります。

いま一度、ちゃんと `自分の名前が半角英数字で M5Stack と Gitpod の LINE BOT サーバ両方に反映されているか確認` してみましょう。

これは seigo として設定した例です。

![image](https://i.gyazo.com/66ed32a7bcb98c2037261034bb472b7f.png)

M5Stack でのソースコードではこちらで設定しています。 YOURNAME のままになってませんか？

![image](https://i.gyazo.com/1ef830abebef80d3d8da634704ee6058.png)

Gitpod では clientMQTT.publish に同じ名前でしているか確認しましょう。

![image](https://i.gyazo.com/7e83f720b7781937f8b231acc863da69.png)

同じく clientMQTT.subscribe に同じ名前でしているか確認しましょう。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「センサー連携を学ぶ その2」にすすみましょう。# IoT開発ボード M5Stack のセンサー連携を学ぶ その2

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

# 次にすすみましょう

左のナビゲーションから「スピーカー」にすすみましょう。# M5Stack スピーカーを動かす

内蔵されているスピーカーを鳴らします。

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/1dfc9a4a72a623e02dc6a3d008299de8.jpg)

以前のボタンとディスプレイのサンプルに、スピーカーで音を鳴らすのも加えています。より押したときの楽しさが伝わるのと、何が起こったかがメロディによって分かるようにいています。

![image](https://i.gyazo.com/67ee6368fad0b12028ec549849f752a1.jpg)

動画での様子はツイート済みです。→ https://twitter.com/1ft_seabass/status/1448820901340876838

## スピーカーの関数

![image](https://i.gyazo.com/9b87e36a19925728592abbf3822c88fe.png)

スピーカーを動かす関数は以下に説明があります。

- 本家の英語のドキュメント
  - [m5\-docs](https://docs.m5stack.com/en/api/speaker)
- ちょっと以前の情報だけど日本語訳のドキュメント
  - [m5\-docs/speaker\.md at master · m5stack/m5\-docs](https://github.com/m5stack/m5-docs/blob/master/docs/ja/api/speaker.md)

音を止める、ボリュームを設定する、音階で指定の期間鳴らるといったシンプルな構成です。

### 音階で鳴らすときはトーンという値で周波数を指定する

[圧電ブザーを鳴らせてみよう · Arduino docs](https://fabkura.gitbooks.io/arduino-docs/content/chapter7.html)

音階で鳴らすときはトーンという値で周波数を指定しますが、こちらのページ具体的な値の指定の仕方が載っています。Arduinoでの鳴らし方ですが、M5Stackでの tone 値にも同じように適用できます。

![image](https://i.gyazo.com/4d7b1697599d83b73e510bcded042a29.png)

より、ひろーい音階が気になる人は [Play a Melody using the tone\(\) function \| Arduino](https://www.arduino.cc/en/Tutorial/BuiltInExamples/toneMelody) こちらも参考になります。

## ソースコードを反映＆保存

ということで動かしていきましょう。

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-13-Speaker` というファイル名で保存します。

```c
#include <M5Stack.h>


void setup() {
  // M5Stack 自体の初期化
  M5.begin(true, false, true);

  // 電源まわりの初期化
  // こうしないとバッテリー状態が更新されない模様
  M5.Power.begin();
  
  M5.Lcd.clear(TFT_BLACK);

  // 線を引いてみた目を区切る ちなみに画面サイズは 320 x 240
  M5.Lcd.drawLine(0,200,320,200,WHITE);
  
  // 下部にボタンナビゲーションをつける
  // 描画順は背景から書いて文字を載せる

  // A ボタンの背景
  M5.Lcd.fillRect(28, 204, 80, 26, BLUE);
  M5.Lcd.drawRect(28, 231, 80, 7, BLUE);

  // B ボタンの背景
  M5.Lcd.fillRect(28 + 80 + 15 , 204, 80, 26, RED);
  M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);

  // C ボタンの背景
  M5.Lcd.fillRect(28 + 80 + 15 + 80 + 15 , 204, 75, 26, TFT_GREEN);
  M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, TFT_GREEN);
  
  // A ボタンの説明
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  M5.Lcd.setCursor(55, 210);  // 結構合ってるけど何度も書き出して目視で合わせている
  M5.Lcd.print("OK");

  // B ボタンの説明
  M5.Lcd.setCursor(127, 210);
  M5.Lcd.print("CANCEL");

  // C ボタンの説明
  M5.Lcd.setTextColor(BLACK);
  M5.Lcd.setCursor(227, 210);
  M5.Lcd.print("RESET");

  // バッテリーレベル
  M5.Lcd.setTextSize(2);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.print("Battery:");
  M5.Lcd.print(M5.Power.getBatteryLevel());

  // テキストを真ん中あたりに出す
  M5.Lcd.setTextSize(4);
  M5.Lcd.setCursor(20, 85);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.print("PUSH BUTTON!");

  // スピーカー音量は 3
  M5.Speaker.setVolume(2);

  // 音を鳴らす ドミソ
  // https://fabkura.gitbooks.io/arduino-docs/content/chapter7.html
  M5.Speaker.tone(523, 200);
  delay(200);
  M5.Speaker.tone(659, 200);
  delay(200);
  M5.Speaker.tone(784, 200);

}

void loop() {
  M5.update();
  
  if (M5.BtnA.wasReleased()) {
    // 音を鳴らす
    M5.Speaker.tone(440, 200);
    delay(200);
    M5.Speaker.tone(440, 200);
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, BLUE);
    // テキストを真ん中あたりに出す
    M5.Lcd.setTextSize(5);
    M5.Lcd.setCursor(60, 80);
    M5.Lcd.setTextColor(BLACK);
    M5.Lcd.print("OK ^_^/");
    // 下部の選択状態
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.fillRect(28, 231, 80, 7, WHITE);  // 選択ホワイト
    M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);
    M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, TFT_GREEN);
  } else if (M5.BtnB.wasReleased()) {
    // 音を鳴らす
    M5.Speaker.tone(261, 200);
    delay(200);
    M5.Speaker.tone(261, 200);
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, RED);
    // テキストを真ん中あたりに出す
    M5.Lcd.setTextSize(5);
    M5.Lcd.setCursor(80, 80);  // わかる。ちょっと中央に寄ってないよね。
    M5.Lcd.setTextColor(BLACK);
    M5.Lcd.print("CANCEL");
    // 下部の選択状態
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.drawRect(28, 231, 80, 7, BLUE);
    M5.Lcd.fillRect(28 + 80 + 15, 231, 80, 7, WHITE);  // 選択ホワイト
    M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, TFT_GREEN);
  } else if (M5.BtnC.wasReleased()) {
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, TFT_GREEN);
    // テキストを真ん中あたりに出す
    M5.Lcd.setTextSize(5);
    M5.Lcd.setCursor(90, 80);
    M5.Lcd.setTextColor(BLACK);
    M5.Lcd.print("RESET");
    // 下部の選択状態
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.drawRect(28, 231, 80, 7, BLUE);
    M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);
    M5.Lcd.fillRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, WHITE);  // 選択ホワイト
    // 2 秒後、表示リセットする /////////////////////////
    delay(2000);
    // 上部だけ背景色で塗りつぶす
    M5.Lcd.fillRect(0, 0, 320, 199, TFT_BLACK);
    // テキストもリセット
    M5.Lcd.setTextSize(4);
    M5.Lcd.setCursor(20, 85);
    M5.Lcd.setTextColor(WHITE);
    M5.Lcd.print("PUSH BUTTON!");
    // 下部もリセット
    M5.Lcd.fillRect(0, 231, 320, 7, BLACK); // 下部を細く黒で塗りつぶし
    M5.Lcd.drawRect(28, 231, 80, 7, BLUE);
    M5.Lcd.drawRect(28 + 80 + 15, 231, 80, 7, RED);
    M5.Lcd.drawRect(28 + 80 + 15 + 80 + 15, 231, 75, 7, WHITE);
  }
}
```

## M5Stack に書き込んでみる

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/1dfc9a4a72a623e02dc6a3d008299de8.jpg)

以前のボタンとディスプレイのサンプルの動作に加えて、起動時のドミソ、OK と CANCEL ボタンで効果音が鳴るようにしています。

## LINE BOT 連携のプログラムがどのように動くか

つづいて、 LINE BOT 連携です。LINE BOT 連携のプログラムは以下のように動きます。

![image](https://i.gyazo.com/db6aa153b83623eab272864fb2ae0fb1.jpg)

書き込みと同時に Connected というメッセージが MQTT ブローカーに送信されます。

![image](https://i.gyazo.com/5d8170e76d125d1e4dbd18ccc73e9d1b.png)

LINE BOT から `sound1` ・ `sound2` ・ `sound3` とメッセージを送ります。

![image](https://i.gyazo.com/c7837e3e08d85c3282e760a8fb97076d.jpg)

たとえば、 sound1 というメッセージを LINE BOT から MQTT ブローカーへデータを送ると、M5Stack が MQTT ブローカー からデータを待ち受けているので sound1 というメッセージを受信して、ドミソとメロディが流れます。

![image](https://i.gyazo.com/068c0cfa4f80d2b0916e8d06bbf1c930.png)

実際の動作はこのようなイメージです。

## LINE BOT と連携するソースコードを試す

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-14-Speaker-LINE-BOT` というファイル名で保存します。

```c
#include <M5Stack.h>

// Wi-Fi をつなぐためのライブラリ
// 今回は MQTT のため
#include <WiFiClient.h>
#include <WiFi.h>

// MQTT をつなぎためのライブラリ
// 今回追加インストールする
#include <PubSubClient.h>  // インストールすれば色がつく
// JSON を扱いやすくするライブラリ
#include <ArduinoJson.h> // こちらは色がついてなくてOK

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

// 今回使いたい CloudMQTT のブローカーのアドレス
const char *mqttEndpoint = "今回使いたい CloudMQTT のブローカーのアドレス";
// 今回使いたい CloudMQTT のポート
const int mqttPort = 1883;
// 今回使いたい CloudMQTT のユーザー名
const char *mqttUsername = "今回使いたい CloudMQTT のユーザー名";
// 今回使いたい CloudMQTT のパスワード
const char *mqttPassword = "今回使いたい CloudMQTT のパスワード";

// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-YOURNAME";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/YOURNAME/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/YOURNAME/subscribe";

// JSON 送信時に使う buffer
char pubJson[255];

// PubSubClient まわりの準備
WiFiClient httpClient;
PubSubClient mqttClient(httpClient);

void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）

  // WiFi 接続開始
  WiFi.begin(ssid, password);

  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）

  // ちゃんとつながったと分かるために 2 秒待ってから MQTT の処理に行く
  delay(2000);

  // MQTT の接続先設定
  mqttClient.setServer(mqttEndpoint, mqttPort);
  // MQTT のデータを受け取った時（購読時）の動作を設定
  mqttClient.setCallback(mqttCallback);
  // MQTT の接続
  mqttConnect();

  // スピーカー音量
  M5.Speaker.setVolume(2);
}



void mqttConnect() {

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  
  // MQTT clientID のランダム化（名称重複対策）
  char clientID[40] = "clientID";
  String rndNum = String(random(0xffffff), HEX);
  String deviceIDRandStr = String(deviceID);
  deviceIDRandStr.concat("-");
  deviceIDRandStr.concat(rndNum);
  deviceIDRandStr.toCharArray(clientID, 40);
  M5.Lcd.println("[MQTT]");
  M5.Lcd.println("");
  M5.Lcd.printf("- clientID ");
  M5.Lcd.println("");
  M5.Lcd.println(clientID);

  // 接続されるまで待ちます
  while (!mqttClient.connected()) {
    if (mqttClient.connect(clientID,mqttUsername,mqttPassword)) {
      Serial.println("Connected.");
      M5.Lcd.println("");
      M5.Lcd.println("- MQTT Connected.");
      
      // subTopic 変数で指定されたトピックに向けてデータを送ります
      int qos = 0;
      mqttClient.subscribe(subTopic, qos);
      Serial.println("Subscribe start.");
      M5.Lcd.println("");
      M5.Lcd.println("- MQTT Subscribe start.");
      M5.Lcd.println(subTopic);

      // 初回データ送信 publish ///////////
      // データ送信のための JSON をつくる
      DynamicJsonDocument doc(1024);
      doc["message"] = "Connected";
      // pubJson という変数に JSON 文字列化されたものが入る
      serializeJson(doc, pubJson);
      // pubTopic 変数で指定されたトピックに向けてデータを送ります
      mqttClient.publish(pubTopic, pubJson);
    } else {
      // MQTT 接続エラーの場合はつながるまで 5 秒ごとに繰り返します
      Serial.print("Failed. Error state=");
      Serial.println(mqttClient.state());
      // Wait 5 seconds before retrying
      delay(5000);
    }
  }
}

// JSON を格納する StaticJsonDocument を準備
StaticJsonDocument<2048> jsonData;

// MQTT のデータを受け取った時（購読時）の動作を設定
void mqttCallback (char* topic, byte* payload, unsigned int length) {
  
  // データ取得
  String str = "";
  Serial.print("Received. topic=");
  Serial.println(topic);
  for (int i = 0; i < length; i++) {
      Serial.print((char)payload[i]);
      str += (char)payload[i];
  }
  Serial.print("\n");

  // 来た文字列を JSON 化して扱いやすくする
  // 変換する対象は jsonData　という変数
  DeserializationError error = deserializeJson(jsonData, str);

  // JSON パースのテスト
  if (error) {
    Serial.print(F("deserializeJson() failed: "));
    Serial.println(error.f_str());
    return;
  }

  // 以下 jsonData 内が JSON として呼び出せる
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  M5.Lcd.println("MQTT Subscribed data");

  // データの取り出し
  // https://arduinojson.org/v6/example/parser/
  const char* message = jsonData["message"];

  // 文字の比較は strcmp が　0 のときで一致している判定ができます
  // https://programming.pc-note.net/c/mojiretsu5.html
  if(strcmp(message, "sound1")==0){
    // 音を鳴らす ドミソ
    M5.Speaker.tone(523, 200);
    delay(200);
    M5.Speaker.tone(659, 200);
    delay(200);
    M5.Speaker.tone(784, 200);
    // データの表示
    M5.Lcd.setCursor(0, 100);
    M5.Lcd.setTextSize(4);
    M5.Lcd.println(message);
  } else if(strcmp(message, "sound2")==0){
    // 音を鳴らす ドド！
    M5.Speaker.tone(523, 100);
    delay(100);
    M5.Speaker.tone(523, 100);
    // データの表示
    M5.Lcd.setCursor(0, 100);
    M5.Lcd.setTextSize(4);
    M5.Lcd.println(message);
  } else if(strcmp(message, "sound3")==0){
    // 音を鳴らす ソミー
    M5.Speaker.tone(784, 200);
    delay(200);
    M5.Speaker.tone(659, 500);
    // データの表示
    M5.Lcd.setCursor(0, 100);
    M5.Lcd.setTextSize(4);
    M5.Lcd.println(message);
  }
  
}

// 常にチェックして切断されたら復帰できるようにする対応
void mqttLoop() {
  if (!mqttClient.connected()) {
      mqttConnect();
  }
  mqttClient.loop();
}
 
void loop() {

  M5.update();

  // 常にチェックして切断されたら復帰できるようにする対応
  mqttLoop();

  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed A";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed B";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed C";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  }
}
```

## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## MQTT の接続設定を反映

LINE BOT と同じように 今回は私（講師）の方が、CloudMQTT というサービスで、ひとつブローカーを立ち上げているので、そのまま使いましょう。

```c
// 今回使いたい CloudMQTT のブローカーのアドレス
const char *mqttEndpoint = "今回使いたい CloudMQTT のブローカーのアドレス";
// 今回使いたい CloudMQTT のポート
const int mqttPort = 1883;
// 今回使いたい CloudMQTT のユーザー名
const char *mqttUsername = "今回使いたい CloudMQTT のユーザー名";
// 今回使いたい CloudMQTT のパスワード
const char *mqttPassword = "今回使いたい CloudMQTT のパスワード";
```

ここの設定を Slack でお知らせする設定で置き換えましょう。

## LINE BOT でも設定した自分の名前を思い出しましょう

このあと、MQTT の送受信トピックとクライアントIDに自分の名前を反映します。

LINE BOT でも設定した自分の名前を思い出して、`全く同じもの` を使いましょう。

## MQTT の送受信トピックとクライアントIDに自分の名前を反映します

MQTT では「自分がどんな名前の機器か」「どこからデータを待ち」「どこへデータを知らせる」という情報を MQTT ブローカーに知らせてあげると、いろいろなデバイスでデータが飛び交っても、目的のところにちゃんと届くようにしてくれます。しかも双方向。

まるで、住所と表札のようなものです。

とにもかくにも、これが重複してしまうと、違うところにデータが送られてしまったり、自分の名前がほかの人と同じになって混乱してしまいます。

```c
// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-YOURNAME";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/YOURNAME/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/YOURNAME/subscribe";
```

たとえば、hogehoge さんなら YOURNAME を hogehoge に変更します。

## LINE BOT 連携のプログラムを M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## LINE BOT の Gitpod がスリープしてたら起こす

![image](https://i.gyazo.com/9bf4ba6a54072e0d6a08ae66a7c9ceca.png)

ここまで作業で時間が経過していると、LINE BOT の Gitpod がスリープしているかもしれません。

そのときは、Open Workspace で起こしてあげましょう。

## LINE BOT 連携のプログラムを M5Stack に動かしてみる

![image](https://i.gyazo.com/db6aa153b83623eab272864fb2ae0fb1.jpg)

書き込みと同時に Connected というメッセージが MQTT ブローカーに送信されます。

実際に M5Stack から接続されているデバイスID（clientID）やデータを待ち受けるトピック subscribe が表示されているので YOURNAME になっていないかや、設定した名前が Gitpod 側で設定した名前と一致しているかを確認しましょう。

![image](https://i.gyazo.com/5d8170e76d125d1e4dbd18ccc73e9d1b.png)

LINE BOT から `sound1` ・ `sound2` ・ `sound3` とメッセージしてみましょう。

![image](https://i.gyazo.com/c7837e3e08d85c3282e760a8fb97076d.jpg)

たとえば、 sound1 というメッセージを LINE BOT から MQTT ブローカーへデータを送ると、M5Stack が MQTT ブローカー からデータを待ち受けているので sound1 というメッセージを受信して、ドミソとメロディが流るので試してみましょう。

# 次にすすみましょう

左のナビゲーションから「動きセンサー」にすすみましょう。# 動きセンサー（加速度・ジャイロ・磁気）

M5Stack の内蔵センサーとして動きセンサー（加速度・ジャイロ・磁気）があります。

> ![image](https://static-cdn.m5stack.com/resource/docs/static/assets/img/product_pics/core/core_mpu6886_bmm150_axis.webp)

詳しくは [M5Stackの仕様](https://docs.m5stack.com/en/core/gray) に書かれていますが、引用したこちらの図の通り、地球の磁気で地面の方向が分かり、加速度・ジャイロで M5Stack 自体の回転する動きを検出できます。

![image](https://i.gyazo.com/51d40e9c3fb28753ea88364fd477c1c0.jpg)

[M5Stack/IMU\.ino at master · m5stack/M5Stack](https://github.com/m5stack/M5Stack/blob/master/examples/Basics/IMU/IMU.ino)

こちらの本家のサンプルを動かすとクルクル回転させると値の様子を体感することができます。

ただ yaw が回り続けるという難しいところがあり。こちらの記事で解決できるようです。

[M5Stackの回転データが勝手に回り続けることになる問題の対策 \- Qiita](https://qiita.com/foka22ok/items/53d5271a21313e9ddcbd)

gyroXYZ accXYZ は素のセンサーの値なので慣れないと扱いにくいです、直感的なのは pitch roll yaw です。

![Flight dynamics with text \- ローリング \- Wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Flight_dynamics_with_text.png/1280px-Flight_dynamics_with_text.png)

pitch roll yaw　は、こちらの記事が分かりやすいです。 → [ローリング \- Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0)

## 今回のプログラムはどのように動くか

![image](https://i.gyazo.com/be07e958f93633c9b589c9f27e79e382.jpg)

起動すると、床に置けば水平状態の `(-_-)` という顔をします。

![image](https://i.gyazo.com/2d8a6d04be1e34f78d761b2b897e99d6.jpg)

正面から向かって左方向にパタンとたおすと、顔文字が変わり pitch LEFT の文字が出ます。

![image](https://i.gyazo.com/542b497cb0a17fca6a863e8deae47087.jpg)

正面から向かって右方向にパタンとたおすと、顔文字が変わり pitch RIGHT の文字が出ます。

## ソースコードを反映＆保存

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-15-TestIMU` というファイル名で保存します。

```c
#define M5STACK_MPU6886
#include <M5Stack.h>

// それぞれの値の初期定義
// 加速度
float accX = 0.0F;
float accY = 0.0F;
float accZ = 0.0F;

// ジャイロ
float gyroX = 0.0F;
float gyroY = 0.0F;
float gyroZ = 0.0F;

// 姿勢 pitch,roll,yaw
float pitch = 0.0F;
float roll  = 0.0F;
float yaw   = 0.0F;

float temp = 0.0F; // この温度は空間の温度というより、機器自体の温度

// 左右どちらに倒れているか
float modePitch = 0;
// 以前の modePitch を記録
float modePitchPrevious = 0; 

void setup(){
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // 電源の初期化
  M5.Power.begin();

  // 動きまわりのセンサー初期化
  M5.IMU.Init();

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(3);
  M5.Lcd.setCursor(0, 100);
  M5.Lcd.println("Test IMU");

  delay(5000);

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(120, 100);
  M5.Lcd.println("(-_-)");
}

void loop() {
  
  // センサー取得
  M5.IMU.getGyroData(&gyroX,&gyroY,&gyroZ);  // ジャイロ
  M5.IMU.getAccelData(&accX,&accY,&accZ);  // 加速度
  M5.IMU.getAhrsData(&pitch,&roll,&yaw);  // 姿勢 pitch,roll,yaw
  M5.IMU.getTempData(&temp);
  
  // 状態を常に取得し続けて現在の値を modePitch に分類する
  if( pitch < -50 ){
    // 左に倒す
    modePitch = -1;
  } else if( pitch > 50 ){
    // 右に倒す
    modePitch = 1;
  } else {
    // 机に水平に置かれている
    modePitch = 0;
  }
  
  // 以前の値 modePitchPrevious と現在の値 modePitch を比べて変化があったら表示を変えて、値を記録しなおす
  if( modePitch != modePitchPrevious ){
    // 表示を変える
    if( modePitch == -1 ){
      // 左に倒す
      M5.Lcd.fillScreen(BLACK);
      M5.Lcd.setCursor(120, 100);
      M5.Lcd.println("(0_-)");
      M5.Lcd.setCursor(70, 130);
      M5.Lcd.println("pitch LEFT!");
    } else if( modePitch == 1 ){
      // 右に倒す
      M5.Lcd.fillScreen(BLACK);
      M5.Lcd.setCursor(120, 100);
      M5.Lcd.println("(-_0)");
      M5.Lcd.setCursor(50, 130);
      M5.Lcd.println("pitch RIGHT!");
    } else {
      // 机に水平に置かれている
      M5.Lcd.fillScreen(BLACK);
      M5.Lcd.setCursor(120, 100);
      M5.Lcd.println("(-_-)");
    }
    // 値を記録しなおす
    modePitchPrevious = modePitch;
  }
  
  delay(10);
}
```

## M5Stack に書き込んでみる

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## 動かしてみる

![image](https://i.gyazo.com/be07e958f93633c9b589c9f27e79e382.jpg)

まず起動したらテーブルの上や床に水平に置いてください。

Test IMU というタイトルが出て 5 秒後くらいに水平状態の `(-_-)` という顔をします。

![image](https://i.gyazo.com/2d8a6d04be1e34f78d761b2b897e99d6.jpg)

正面から向かって左方向にパタンとたおすと、顔文字が変わり pitch LEFT の文字が出ます。

![image](https://i.gyazo.com/542b497cb0a17fca6a863e8deae47087.jpg)

正面から向かって右方向にパタンとたおすと、顔文字が変わり pitch RIGHT の文字が出ます。

素早く倒すと、途中で軸が大きくブレるので、一瞬だけ横倒したことになる判定が出るかもしれません。

そーっと使えば問題ないですが、荒い操作でもうまく動くようにしたい方はぜひ調整してみてください。

## LINE BOT と連携するソースコードを試す

Arduino IDE で新規ファイルを作成し、以下のコードをコピーアンドペーストします。こちらを `dhw-pp2-study-16-IMU-LINE-BOT` というファイル名で保存します。

```c

// 動きセンサー関連を使うライブラリ
#define M5STACK_MPU6886

#include <M5Stack.h>

// Wi-Fi をつなぐためのライブラリ
// 今回は MQTT のため
#include <WiFiClient.h>
#include <WiFi.h>

// MQTT をつなぎためのライブラリ
// 今回追加インストールする
#include <PubSubClient.h>  // インストールすれば色がつく
// JSON を扱いやすくするライブラリ
#include <ArduinoJson.h> // こちらは色がついてなくてOK

// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";

// 今回使いたい CloudMQTT のブローカーのアドレス
const char *mqttEndpoint = "今回使いたい CloudMQTT のブローカーのアドレス";
// 今回使いたい CloudMQTT のポート
const int mqttPort = 1883;
// 今回使いたい CloudMQTT のユーザー名
const char *mqttUsername = "今回使いたい CloudMQTT のユーザー名";
// 今回使いたい CloudMQTT のパスワード
const char *mqttPassword = "今回使いたい CloudMQTT のパスワード";

// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-YOURNAME";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/YOURNAME/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/YOURNAME/subscribe";

// JSON 送信時に使う buffer
char pubJson[255];

// PubSubClient まわりの準備
WiFiClient httpClient;
PubSubClient mqttClient(httpClient);

// それぞれの値の初期定義
// 加速度
float accX = 0.0F;
float accY = 0.0F;
float accZ = 0.0F;

// ジャイロ
float gyroX = 0.0F;
float gyroY = 0.0F;
float gyroZ = 0.0F;

// 姿勢 pitch,roll,yaw
float pitch = 0.0F;
float roll  = 0.0F;
float yaw   = 0.0F;

float temp = 0.0F; // この温度は空間の温度というより、機器自体の温度

// 左右どちらに倒れているか
float modePitch = 0;
// 以前の modePitch を記録
float modePitchPrevious = 0; 


void setup() {
  // init lcd, serial, but don't init sd card
  // LCD ディスプレイとシリアルは動かして、SDカードは動かさない設定
  M5.begin(true, false, true);

  // 電源の初期化
  M5.Power.begin();
  
  // スタート
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.print("START");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.print("START");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）

  // WiFi 接続開始
  WiFi.begin(ssid, password);

  while (WiFi.status() != WL_CONNECTED) {
      delay(500);

      // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
      Serial.print(".");
      M5.Lcd.print(".");
  }

  // WiFi Connected
  // WiFi 接続完了
  M5.Lcd.setCursor(10, 40);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  // 前のメッセージが print で改行入っていないので println で一つ入れる
  Serial.println("");  // Arduino のシリアルモニタにメッセージを出し改行が最後に入る
  M5.Lcd.println("");  // M5Stack LCDディスプレイにメッセージを出す改行が最後に入る（英語のみ） 

  // Arduino のシリアルモニタ・M5Stack LCDディスプレイ両方にメッセージを出す
  Serial.println("WiFi Connected.");  // Arduino のシリアルモニタにメッセージを出す
  M5.Lcd.println("WiFi Connected.");  // M5Stack LCDディスプレイにメッセージを出す（英語のみ）

  // ちゃんとつながったと分かるために 2 秒待ってから MQTT の処理に行く
  delay(2000);

  // MQTT の接続先設定
  mqttClient.setServer(mqttEndpoint, mqttPort);
  // MQTT のデータを受け取った時（購読時）の動作を設定
  mqttClient.setCallback(mqttCallback);
  // MQTT の接続
  mqttConnect();

  // 動きまわりのセンサー初期化
  M5.IMU.Init();
}



void mqttConnect() {

  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  
  // MQTT clientID のランダム化（名称重複対策）
  char clientID[40] = "clientID";
  String rndNum = String(random(0xffffff), HEX);
  String deviceIDRandStr = String(deviceID);
  deviceIDRandStr.concat("-");
  deviceIDRandStr.concat(rndNum);
  deviceIDRandStr.toCharArray(clientID, 40);
  M5.Lcd.println("[MQTT]");
  M5.Lcd.println("");
  M5.Lcd.printf("- clientID ");
  M5.Lcd.println("");
  M5.Lcd.println(clientID);

  // 接続されるまで待ちます
  while (!mqttClient.connected()) {
    if (mqttClient.connect(clientID,mqttUsername,mqttPassword)) {
      Serial.println("Connected.");
      M5.Lcd.println("");
      M5.Lcd.println("- MQTT Connected.");
      
      // subTopic 変数で指定されたトピックに向けてデータを送ります
      int qos = 0;
      mqttClient.subscribe(subTopic, qos);
      Serial.println("Subscribe start.");
      M5.Lcd.println("");
      M5.Lcd.println("- MQTT Subscribe start.");
      M5.Lcd.println(subTopic);

      // 初回データ送信 publish ///////////
      // データ送信のための JSON をつくる
      DynamicJsonDocument doc(1024);
      doc["message"] = "Connected";
      // pubJson という変数に JSON 文字列化されたものが入る
      serializeJson(doc, pubJson);
      // pubTopic 変数で指定されたトピックに向けてデータを送ります
      mqttClient.publish(pubTopic, pubJson);
    } else {
      // MQTT 接続エラーの場合はつながるまで 5 秒ごとに繰り返します
      Serial.print("Failed. Error state=");
      Serial.println(mqttClient.state());
      // Wait 5 seconds before retrying
      delay(5000);
    }
  }
}

// JSON を格納する StaticJsonDocument を準備
StaticJsonDocument<2048> jsonData;

// MQTT のデータを受け取った時（購読時）の動作を設定
void mqttCallback (char* topic, byte* payload, unsigned int length) {
  
  // データ取得
  String str = "";
  Serial.print("Received. topic=");
  Serial.println(topic);
  for (int i = 0; i < length; i++) {
      Serial.print((char)payload[i]);
      str += (char)payload[i];
  }
  Serial.print("\n");

  // 来た文字列を JSON 化して扱いやすくする
  // 変換する対象は jsonData　という変数
  DeserializationError error = deserializeJson(jsonData, str);

  // JSON パースのテスト
  if (error) {
    Serial.print(F("deserializeJson() failed: "));
    Serial.println(error.f_str());
    return;
  }

  // 以下 jsonData 内が JSON として呼び出せる
  M5.Lcd.fillScreen(BLACK);
  M5.Lcd.setCursor(0, 0);
  M5.Lcd.setTextColor(WHITE);
  M5.Lcd.setTextSize(2);
  M5.Lcd.println("MQTT Subscribed data");

  // データの取り出し
  // https://arduinojson.org/v6/example/parser/
  const char* message = jsonData["message"];

  // 今回はMQTT のデータを受け取った時（購読時）の動作はなし
}

// 常にチェックして切断されたら復帰できるようにする対応
void mqttLoop() {
  if (!mqttClient.connected()) {
      mqttConnect();
  }
  mqttClient.loop();
}
 
void loop() {

  M5.update();

  // 常にチェックして切断されたら復帰できるようにする対応
  mqttLoop();

  // センサー取得
  M5.IMU.getGyroData(&gyroX,&gyroY,&gyroZ);  // ジャイロ
  M5.IMU.getAccelData(&accX,&accY,&accZ);  // 加速度
  M5.IMU.getAhrsData(&pitch,&roll,&yaw);  // 姿勢 pitch,roll,yaw
  M5.IMU.getTempData(&temp);

  M5.Lcd.setTextSize(3);
  
  // 状態を常に取得し続けて現在の値を modePitch に分類する
  if( pitch < -50 ){
    // 左に倒す
    modePitch = -1;
  } else if( pitch > 50 ){
    // 右に倒す
    modePitch = 1;
  } else {
    // 机に水平に置かれている
    modePitch = 0;
  }
  
  // 以前の値 modePitchPrevious と現在の値 modePitch を比べて変化があったら表示を変えて、値を記録しなおす
  if( modePitch != modePitchPrevious ){
    // 表示を変える
    if( modePitch == -1 ){
      // 左に倒す
      M5.Lcd.fillScreen(BLACK);
      M5.Lcd.setCursor(120, 100);
      M5.Lcd.println("(0_-)");
      M5.Lcd.setCursor(70, 130);
      M5.Lcd.println("pitch LEFT!");
      // データ送信のための JSON をつくる
      DynamicJsonDocument doc(1024);
      doc["message"] = "pitch LEFT!";
      // pubJson という変数に JSON 文字列化されたものが入る
      serializeJson(doc, pubJson);
      // pubTopic 変数で指定されたトピックに向けてデータを送ります
      mqttClient.publish(pubTopic, pubJson);
    } else if( modePitch == 1 ){
      // 右に倒す
      M5.Lcd.fillScreen(BLACK);
      M5.Lcd.setCursor(120, 100);
      M5.Lcd.println("(-_0)");
      M5.Lcd.setCursor(50, 130);
      M5.Lcd.println("pitch RIGHT!");
      // データ送信のための JSON をつくる
      DynamicJsonDocument doc(1024);
      doc["message"] = "pitch RIGHT!";
      // pubJson という変数に JSON 文字列化されたものが入る
      serializeJson(doc, pubJson);
      // pubTopic 変数で指定されたトピックに向けてデータを送ります
      mqttClient.publish(pubTopic, pubJson);
    } else {
      // 机に水平に置かれている
      M5.Lcd.fillScreen(BLACK);
      M5.Lcd.setCursor(120, 100);
      M5.Lcd.println("(-_-)");
      // データ送信のための JSON をつくる
      DynamicJsonDocument doc(1024);
      doc["message"] = "(-_-)";
      // pubJson という変数に JSON 文字列化されたものが入る
      serializeJson(doc, pubJson);
      // pubTopic 変数で指定されたトピックに向けてデータを送ります
      mqttClient.publish(pubTopic, pubJson);
    }
    // 値を記録しなおす
    modePitchPrevious = modePitch;
  }

  if (M5.BtnA.wasReleased()) {
    // A ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed A";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  } else if (M5.BtnB.wasReleased()) {
    // B ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed B";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  } else if (M5.BtnC.wasReleased()) {
    // C ボタンを押したら JSON 形式のメッセージを飛ばす
    // データ送信のための JSON をつくる
    DynamicJsonDocument doc(1024);
    doc["message"] = "Pushed C";
    // pubJson という変数に JSON 文字列化されたものが入る
    serializeJson(doc, pubJson);
    // pubTopic 変数で指定されたトピックに向けてデータを送ります
    mqttClient.publish(pubTopic, pubJson);
  }

  // IMU センサーに合わせて待ち時間を少し加えた
  delay(10);
}
```

## Wi-Fi 情報を反映

```c
// Wi-FiのSSID
char *ssid = "Wi-FiのSSID";
// Wi-Fiのパスワード
char *password = "Wi-Fiのパスワード";
```

自分のつなぎたい Wi-Fi の SSID とパスワードを反映します。

## MQTT の接続設定を反映

LINE BOT と同じように 今回は私（講師）の方が、CloudMQTT というサービスで、ひとつブローカーを立ち上げているので、そのまま使いましょう。

```c
// 今回使いたい CloudMQTT のブローカーのアドレス
const char *mqttEndpoint = "今回使いたい CloudMQTT のブローカーのアドレス";
// 今回使いたい CloudMQTT のポート
const int mqttPort = 1883;
// 今回使いたい CloudMQTT のユーザー名
const char *mqttUsername = "今回使いたい CloudMQTT のユーザー名";
// 今回使いたい CloudMQTT のパスワード
const char *mqttPassword = "今回使いたい CloudMQTT のパスワード";
```

ここの設定を Slack でお知らせする設定で置き換えましょう。

## LINE BOT でも設定した自分の名前を思い出しましょう

このあと、MQTT の送受信トピックとクライアントIDに自分の名前を反映します。

LINE BOT でも設定した自分の名前を思い出して、`全く同じもの` を使いましょう。

## MQTT の送受信トピックとクライアントIDに自分の名前を反映します

MQTT では「自分がどんな名前の機器か」「どこからデータを待ち」「どこへデータを知らせる」という情報を MQTT ブローカーに知らせてあげると、いろいろなデバイスでデータが飛び交っても、目的のところにちゃんと届くようにしてくれます。しかも双方向。

まるで、住所と表札のようなものです。

とにもかくにも、これが重複してしまうと、違うところにデータが送られてしまったり、自分の名前がほかの人と同じになって混乱してしまいます。

```c
// デバイスID
// デバイスIDは機器ごとにユニークにします
// YOURNAME を自分の名前の英数字に変更します
// デバイスIDは同じMQTTブローカー内で重複すると大変なので、後の処理でさらにランダム値を付与してますが、名前を変えるのが確実なので、ちゃんと変更しましょう。
char *deviceID = "M5Stack-YOURNAME";

// MQTT メッセージを LINE BOT に知らせるトピック
// YOURNAME を自分の名前の英数字に変更します
char *pubTopic = "/dhw/pp2/mqtt/YOURNAME/publish";

// MQTT メッセージを LINE BOT から待つトピック
// YOURNAME を自分の名前の英数字に変更します
char *subTopic = "/dhw/pp2/mqtt/YOURNAME/subscribe";
```

たとえば、hogehoge さんなら YOURNAME を hogehoge に変更します。

## LINE BOT 連携のプログラムを M5Stack に書き込んでみる

そして、もう一度保存します。（大事）

![image](https://i.gyazo.com/45b0fd6ce672dc9a0055d45aa290e235.png)

M5Stack に書き込んでみましょう。

## LINE BOT の Gitpod がスリープしてたら起こす

![image](https://i.gyazo.com/9bf4ba6a54072e0d6a08ae66a7c9ceca.png)

ここまで作業で時間が経過していると、LINE BOT の Gitpod がスリープしているかもしれません。

そのときは、Open Workspace で起こしてあげましょう。

## LINE BOT 連携のプログラムを M5Stack に動かしてみる

まず起動したらテーブルの上や床に水平に置いてください。

![image](https://i.gyazo.com/487cb8afe544cf2cb56ff3228d2fc56e.png)

起動すると Connected というメッセージが M5Stack から MQTT ブローカーに送信され、LINE BOT がキャッチして、そのメッセージを表示します。

![image](https://i.gyazo.com/2d8a6d04be1e34f78d761b2b897e99d6.jpg)

正面から向かって左方向にパタンとたおすと、顔文字が変わり pitch LEFT の文字が出ます。

![image](https://i.gyazo.com/542b497cb0a17fca6a863e8deae47087.jpg)

正面から向かって右方向にパタンとたおすと、顔文字が変わり pitch RIGHT の文字が出ます。

![image](https://i.gyazo.com/b7493cbbd3b68d1d84feb97e7785cc36.png)

M5Stack から MQTT ブローカーにメッセージが送信され、LINE BOT がキャッチして、そのメッセージを表示します。

# 次にすすみましょう

左のナビゲーションから「さまざまな連携例」にすすみましょう。# さまざまな連携例

ここまでは、内蔵センサーや Grove センサーを LINE BOT につなげるような事例で「みなさんにもすぐに試せる」ことを中心にお伝えしてきましたが、M5Stack の連携にもいろいろな広がりがあります。

おもに私の事例を軸に、いくつかダイジェストで紹介していきます。

## より突っ込んだ M5Stack 操作

### MQTT に送る JSON をよりカスタマイズしてビジュアル変更演出実験

![image](https://www.1ft-seabass.jp/memo/uploads/2020/10/controlling-m5stack-from-node-red-mqtt-json-senarios_00-644x358.jpg)

JSON で、シナリオデータを送って、ディスプレイの背景色を変えたり、文字を変えたり、かつ変わる秒数を細かく指定出来たりという事例。

[M5Stack で MQTT から Node\-RED 経由で JSON データでまとめてシナリオを渡してビジュアルが変わる仕組みを作ったメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2020/10/31/controlling-m5stack-from-node-red-mqtt-json-senarios/)

### LINE Beacon 例

![image](https://www.1ft-seabass.jp/memo/uploads/2021/01/m5stack-line-beacon-with-node-red-line-bot_00-644x314.png)

LINE Beacon の信号を M5Stack から出せると、M5Stack はビーコンを出すだけの仕組みでセンサーやボタンなどと連携ができて、ビーコン検出後の LINE での通知は LINE BOT に任せることができて、また違った用途がイメージできます。

[M5Stack に LINE Beacon で書き込み Node\-RED で作った LINE BOT とやり取りするメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/01/03/m5stack-line-beacon-with-node-red-line-bot/)

## センサーで考えが広がる例

### サーマルカメラ例

![image](https://www.1ft-seabass.jp/memo/uploads/2021/05/grove-thermal-camera-ir-array-mlx90640-110-degree-firststep_00-800x448.jpg)

対象物の熱の状態を見る熱センサー サーマルカメラ を M5Stack の連携。本来、サーマルカメラは 1 pixel ごと情報が来るため処理負荷が高いですが M5Stack だとバッチリ取得できます。

[Grove 赤外線サーマルカメラ IRアレイ MLX90640 110度 を M5Stack で動かしたメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/05/05/grove-thermal-camera-ir-array-mlx90640-110-degree-firststep/)

- 難しめのセンサー接続についての試行錯誤を見てみたい人は是非。

### CO2 センサー例

![image](https://www.1ft-seabass.jp/memo/uploads/2021/03/m5stack-connect-grove-co2-sensor-scd30_01-644x366.jpg)

COVID-19 の時期には欠かせないセンサー CO2 センサー。こちらの連携例。

[M5Stack と Grove CO2＆温度＆湿度センサー SCD30 をつないで計測するメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/03/08/m5stack-connect-grove-co2-sensor-scd30/)

- 難しめのセンサー接続についての試行錯誤を見てみたい人は是非。
- CO2 センサーのような、いま社会で必要度が高いものを取得できると、いろいろな使い方がパーッと広がってきます

## 見た目大事系

### ハロウィンの光り物にピッタリ

![image](https://zoe6120.com/wp-content/uploads/2019/07/IMG_1645.jpg)

M5Stack + テープLED の事例。はんだ付けが必要だが、光って強い。

[M5StackとESP32でNeoPixel互換LEDテープを点灯する – zoe log](https://zoe6120.com/2019/07/03/990/)

## ほかの技術との連携で広がっていく例

### ローコードツール Node-RED と MQTT で連携する例

![image](https://www.1ft-seabass.jp/memo/uploads/2018/05/m5stack-meets-nodered-with-mqtt_01.png)

[M5StackとNode\-REDをMQTTで連携するメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2018/05/10/m5stack-meets-nodered-with-mqtt/)

### クラウドとの連携 IBM Cloud

![image](https://www.1ft-seabass.jp/memo/uploads/2018/05/m5stack-meets-ibm-watson-iot-platform_01-644x271.png)

[M5StackをIBM Watson IoT Platform \(QuickStart\) にデータ送信＆可視化するメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2018/05/24/m5stack-meets-ibm-watson-iot-platform/)

### クラウドとの連携 AWS

![image](https://www.1ft-seabass.jp/memo/uploads/2018/05/m5stack-meets-aws-iot_01-644x336.png)

[M5Stackにつないだデジタル入力をAWS IoTにデータ送信するメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2018/05/25/m5stack-meets-aws-iot/)

### スプレッドシート的なデータの貯め方ができる AirTable 連携例

![image](https://www.1ft-seabass.jp/memo/uploads/2021/10/m5stack-airtable-api-connect_01-800x415.png)

[M5Stack から HTTPS で AirTable にデータを書き込むメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2021/10/07/m5stack-airtable-api-connect/)

### むちゃくちゃ組み合わせた事例

![image](https://www.1ft-seabass.jp/memo/uploads/2018/07/tello-fly-m5stack-command-force-land_02.png)

鍵をかけると、ドローンが飛ぶという、謎の連携。ドローンの UDP プロトコルを Node-RED が中継して M5Stack ＋EAO 鍵スイッチ の反応を届けています。

[トイドローン Tello をM5Stack＋EAO 鍵スイッチで緊急着陸させるメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2018/07/18/tello-fly-m5stack-command-force-land/)


## 使いこなすためにパワーは使いますが頑張りましょう～

![image](https://i.gyazo.com/8bb6da4820529871e09aa5d80d1483c8.png)

ここまでくると、いろいろな知見知った時に、自分でうまく切り取って自分の作りたいものに加えることが大切になってきますががんばりましょう！

# 次にすすみましょう

左のナビゲーションから「いままでの実装とアウトプットへの関係性を学ぶ」にすすみましょう。# いままでのセンサー・ボタン・ディスプレイ実装とアウトプットへの関係性を学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

すでに制作をはじめていますが、内蔵センサー・Grove センサー・ボタン・ディスプレイ・スピーカーあたりのひと通り学んだところでアウトプットへの関係性を振り返ってみましょう。

## 内蔵ディスプレイ

![image](https://i.gyazo.com/aa25587bac5a50c1697b651f668a2cd3.png)

広いエリアで視覚的に伝わるのが内蔵ディスプレイです。背景色やテキストをはじめ、定期的に位置や大きさを変えていくことによってアニメーションも可能です。

ツイート時でも実際に触ってもらう場合でも、パッと触りたくなる案内をディスプレイに出せるようにしましょう。

ツイート時は動画や写真ですぐにわかるような見せ方を心がけると、説明が少なく直感的に伝わるコンテンツが作りやすいです。実際に触ってもらう場合では、触れるときに迷わないような案内を表示すると、同様の効果が得られます。

どちらにも言えることですが、何が起こっているかについても、丁寧に表示していくことで、使う人見る人がびっくりしない優しいユーザーインターフェースになります。

また、スマートフォンや Web での見せ方伝え方も、 M5Stack のディスプレイの見せ方に活用できる場合があります。うまく加えていきましょう。

## 内蔵スピーカー

![image](https://i.gyazo.com/2496cf10b5cab471ec4548eb3a979167.png)

聴覚に情報を伝えるのは音です。

ディスプレイで見ている情報に対して補助的に音をつけるのも、より分かりやすさが増して効果的です。

音の特性は見たときの補助的な伝達だけではありません。たとえば、視覚に頼らない伝達。M5Stack そのものを見なくても、隣の部屋で M5Stack から音が聞こえれば何かしらの情報を伝えることができます。

唐突な音では周囲をびっくりさせる可能性はあるので取り扱いには注意が必要ですが、あらかじめ、どういった音が鳴るかを示したり、説明が無くても直感的に良し悪しが分かるメロディを組み合わせれば、ディスプレイだけではない効果的な伝達できます。

## 内蔵ボタン

![image](https://i.gyazo.com/d7f5598b726b15ce670584a255837a2c.png)

M5Stack の 3 つのボタンは実装しやすく、M5Stack を触れた人が M5Stack と次のコミュニケーションをするための大切な入口になります。ディスプレイと組み合わせて説明付きのボタン操作で、分かりやすく自分のコンテンツに案内することもできるでしょう。

ボタンをただ押すだけだと 3 つの操作しかできないように思いますが、長押しや素早い2度押しを組み合わせることで操作が広がります。複雑なコマンドもできるので、たとえば、素早い2度押しで仕組みのリセットをしたり、デバッグモードを長押しに仕込んでみたり、自分のつくった M5Stack をうまく拡張していきましょう。

## 動きまわりのセンサー（加速度・コンパス・ジャイロ）

![image](https://i.gyazo.com/d4a6eef783d0b1ba614eb4652f450c2a.png)

加速度・コンパス・ジャイロ センサーは、扱うためには少し難易度が高いです。

ですが、うまく実装できると、ロボットの姿勢制御や人の複雑な動きの検知といったことも可能なので奥深いものです。

加速度はモノの移動だけでなく震度を計算することができたり色々なことに使えるので、気になる人は調べてみるとイイでしょう。コンパスは地磁気をもとに方角を検知したり地面の方向を知ることができます。

## 内蔵バッテリー

![image](https://i.gyazo.com/45a1659f2b05f40e1df08b10e7abb9ce.png)

普段は USB で書き込んでいるため、常時給電されているので気づきにくいですが、 M5Stack はバッテリーがあるため、USB から離しても、内蔵バッテリーが続くかぎり給電なしで動かすことができます。

ですが、[m5\-docs](https://docs.m5stack.com/en/core/gray) にもあるとおりで、`110mAh @ 3.7V` と、あまり大きい電池ではありません。

また、Wi-Fi やインターネット接続を繰り返す処理は電池の消費が激しくてすぐにバッテリーがなくなってしまうでしょう。

もちろん、サッと見せるときには心強い味方になってくれますが、使い続けるときには、他のモバイルバッテリーをつなげたり、PCやコンセントからの優先での給電も意識して自分のコンテンツを考えていきましょう。

IoT では、電源問題はつねに意識する事柄なので、うまく付き合っていきましょう。

モバイルバッテリーによっては M5Stack 程度の電流だと省エネ判定されて1分くらいで勝手に自動 OFF になるものも存在します。

- [【白色】IoT機器用モバイルバッテリー cheero Canvas 3200mAh \- スイッチサイエンス](https://www.switch-science.com/catalog/2618/)
- [【黒色】IoT機器用モバイルバッテリー cheero Canvas 3200mAh \- スイッチサイエンス](https://www.switch-science.com/catalog/3167/)

のような、IoT 向きの自動電源 OFF のない、手動で電源 ON / OFF できて給電を維持できるモバイルバッテリーもあるので、状況に応じて検討しましょう。（個人的には、1積もっておいて損はないです）

すぐ誰かに見せるか？ずっと使い続けるか？といったところバッテリーの扱いと密接に関係するので、つくったあとにどういうシチュエーションで仕組みを使っていくかを考えながら進めましょう。

## Grove センサー

![image](https://i.gyazo.com/ad4c9453685b492d9b9601a2c7464b15.png)

Grove センサーは以前の授業ですでに良さは伝えていますが、あらためて、M5Stack アウトプットの目線から言うと M5Stack から先の「広がり」を担当しています。

- [Grove \- スイッチサイエンス](https://www.switch-science.com/catalog/list/145/)
- [Grove \- Seeed Studio 社](https://jp.seeedstudio.com/category/Grove-c-1003.html)

には、豊富な Grove シリーズが紹介されているので、アイデアの種として考えて自分の作りたいものと対話させていくのはおススメです。実は、講師の田中も定期的にエクササイズと考えて、リストを眺めながら発想を膨らませています。

![image](https://i.gyazo.com/8bb32622e4297518448fcf6b5a267705.jpg)

↑ [センサ \- スイッチサイエンス](https://www.switch-science.com/catalog/list/379/) の一部

自分の発想をもとに使える技術を探して覚えていく探索も大切です。そして、このように技術（センサー）をベースに現実世界を想像しながら発想することも大切です。

発想と技術を行き来させることで自分のスキルを磨いていきましょう。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「次回の宿題について」にすすみましょう。# 次回の宿題について

![image](https://i.gyazo.com/1053e8f7fd0a4236ce30284505e4fec3.png)

## 課題全体からの位置づけ

全体としては

```
- 最終課題　50％
  - 発想力・創造力・アウトプット力・継続開発力 の要素で採点する予定です。
- 授業内の課題　50％
  - 機材をそろえて準備する課題 10％予定
  - 制作してアウトプットする課題 20％ * 2 予定
```

で採点を予定しています。

今回は「制作してアウトプットする課題」20 ％部分の 2 回目です。

## この宿題の意図

今回の宿題は、前の宿題でできた自分なりのアウトプットをつづけることがテーマです。

最終制作に向けて、アウトプットを積み重ねていきます。「つくってみたら他のことも検討したい」「もっとこうしたい」といった自己フィードバック。ツイートすることやほかの人に触ってもらうフィードバック。これらのフィードバックで制作物を進化させていきます。

最終制作では、およそ 5 分の発表の中で

- この作品のコンセプト
- どうつくりつづけたか
- 制作デモ
- 

## この宿題のゴール

今回の宿題で、つくりつづける、つまり複数回アウトプットする感覚をつかむことがゴールです。

そのほかに、

- 自分の目指している大きなコンセプトや目標から逆算して細かなアウトプットする計画力
- 宿題の1回目よりも、授業で学んだことをより自分のものとして扱えること
- 制作物をつくることだけに追われるだけでなく、制作物その周辺のことも意識する

といったことも把握できるようにしましょう。

## 厳守事項

- `New!!` アウトプットするツイートは 3 つ以上のツイートします
- `New!!` アウトプットするツイートの間隔は 1 日（24時間）以上とします
- `New!!` アウトプットするツイートの中で、メインのアウトプットするツイートを 1 つ以上のツイートします
- `New!!` アウトプットするツイートの中で、現状の途中経過の制作物に他者フィードバックを受けて自分なりにちょっとでも磨いた 1 つ以上のツイートします
  - 他者フィードバック例
    - ツイートにもらったコメントを他者フィードバックとして自分なりにちょっとでも磨く
    - 家族や友人などを他者フィードバックとして自分なりにちょっとでも磨く
- 制作物には M5Stack を必ず使用します
- 制作物には 自分でつくったフロントエンド or LINE BOT or LINE Notify を必ず使用します

## アウトプットするツイートについて

![image](https://i.gyazo.com/e91bd58887716ab461f35ea0b2778e84.png)

1 回目の宿題では 1 つだけのアウトプットでしたが、今回はつくりつづけて複数のツイートをします。

上記はあくまで例ですが、厳守事項にある「3 つ以上のツイートします」「メインのアウトプットするツイートを 1 つ以上」「現状の途中経過の制作物に他者フィードバックを受けて自分なりにちょっとでも磨く」を守って制作していきましょう。

もちろん `小 → 小 → メイン` でなくて `メイン → メイン → メイン` というすごい進捗でも OK です。ただし、`小 → 小 → 小` という、淡々とアウトプットするのは NG です。

## 採点基準

![image](https://i.gyazo.com/254a09030420cf82ad22c6e95aedd929.png)

こちらの 4 要素で採点します。

- 発想力 5点
  - 自分の今までの知識や経験に基づいて自分なりに思いついているか（独自性）
  - 自由に発想ができているか（自在性）
- 創造力 5点
  - 発想を自分の技術と自分の考えをうまく組み合わせてカタチにできているか
  - 今の自分から得たものとともに新しい価値にチャレンジをしているか
- アウトプット力 10点
  - 制作物を通じて自分の考えをアウトプット出来ているか
  - 狙った他者（ターゲット）に伝わるように工夫できているか

## 採点の目安

![image](https://i.gyazo.com/e9b768f5fbfe123a0947e08388e4333b.png)

今回の採点の目安をお伝えします。次回の宿題では、少し調整する可能性はあります。

- 発想力
  - Lv.1 授業で学んだことから少しだけ変化して発想している
    - 単純な連想レベル
  - Lv.2 授業で学んだことに自分の今までの知識や経験を加味して発想している
    - 自分の作りたいものが感じられる。学んだ仕組みが自分の作りたいものに反映されている
  - Lv.3 授業で学んだことをうまく自分にとりこんで自由に発想している
    - 自分の作りたいものが明確にある。Lv.2 よりも自由度があり、この先に進もうと色々な発想ができている
- 創造力
  - Lv.1 発想したものを授業で学んだ技術を組み合わせてただカタチにしている
    - サンプルを動かしただけのような、発想が小さくカタチにするものも小さい
  - Lv.2 発想したものを授業で学んだ技術だけでなく自分の今までの力を加味してカタチにしている
    - 授業で学んだ技術が自分とうまくとりこまれ、つくるものに反映しだしている
    - 制作物を作ることに精いっぱいで、なんとか現状を伝えようとしている
  - Lv.3 発想したものをカタチにするだけでなく、それにより試行錯誤をして新しい知識や発想が生まれながらつくっている
- アウトプット力
  - Lv.1 ただハッシュタグをつけて文章でできましたとツイートするだけ
    - つくったことはなんとか伝わるが制作物に対する思いや内容が伝わらない
  - Lv.2 文章だけでなく画像や動画を使って分かりやすく制作物を伝えようと工夫しはじめている
    - 制作物の内容（のみ）を他者に伝えるために試行錯誤がしはじめている
  - Lv.3 制作物を伝えつつ自分の発想や制作過程といったそこに至る経緯が伝えようと工夫しはじめている
    - 制作物だけの「点」だけでなく自分の思考や経緯、伝えるターゲットを意識して「線」として結んで考えられる
    - 制作物を作って終わりでなく、途中経過でも自分の考えたつくったものの価値を試すためのプラスととらえはじめている。
    - 徐々にだが、他者のフィードバックとして、他者からのコメントやいいね！を目を向けはじめている
  - **↓↓↓↓↓↓ 第2回宿題では以下が解放されます ↓↓↓↓↓↓**
  - Lv.4 つくりつづけることを意識して現状のアウトプットを自分の制作も他者へ伝えることも楽しみはじめている
    - 自分の「つくる」という大きな流れの中で行動している。Lv.3 が過去→現在を伝えているとすると、未来も意識しはじめている。
    - 自己のフィードバックとして、今回はここまでだったけど制作物をこうしたい、技術を新しく加えて制作物を発展させたいなど考えはじめている。
    - 他者のフィードバックとして、他者からのコメントやいいね！を目を向けて、今後のブラッシュアップの糧にしようとしている。
  - Lv.5 つくりながらアウトプットしてフィードバックを得てつくるものを日々磨いている
    - Lv.4 の発展した状態。
    - 日々自分と対話しながら技術や発想をカタチにしつづけている。たとえ小さくても何かしらつくっている。
    - 良い意味でつくるための課題が常にあり日々新しい情報の収集や技術習得をしようとしている。
    - つくりつづけているので伝えたい原資があるため、計画的なアウトプットができる。心の中にドラフト（下書き）がある。
    - そのときの興味ある話題に対しても自分のインスピレーションをもち、つくるものにミックスして瞬間的で魅力あるアウトプットを柔軟に行う場合もある。
    - つくりつづけて自分のつくりたいものへの自己フィードバックがカジュアルに持っていて、それ軸にもちつつ SNS や直接の交流からくる他者のフィードバックをうまく取り込んでいる

以上で、

- 発想力
  - Lv.1 ～ Lv.3 の中での到達具合を 5 点に置き換えます
- 創造力
  - Lv.1 ～ Lv.3 の中での到達具合を 5 点に置き換えます
- アウトプット力
  - 今回は Lv.1 ～ Lv.5 での到達具合を 10 点に置き換えます。

となります。

## 〆切

![image](https://i.gyazo.com/ff5cb71c3ed20c019f4657af37ee46bb.png)

- 10/28 木 23:59 厳守
  - 上記時間までに後述する `提出場所` で自分の行の必須項目に書き込んであることが採点される条件です。この時間に記載されてない場合、採点の対象になりません。

## 提出場所

![image](https://i.gyazo.com/4f35b07964756ac84fe403ef7064e6cc.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=386298483

こちらのスプレッドシートに記入します。

- ツイートするアカウンとは以前の宿題と同じものでお願いします。
- 【必須】 `アウトプットしたツイートURL 1` ・ `アウトプットしたツイートURL 2` ・ `アウトプットしたツイートURL 3` に https://twitter.com/1ft_seabass/status/1439097633751003138 のように自分の投稿したツイートが直接見えるURLを記入しましょう。
  - 採点対象となるツイートは 10/15金 ～ 10/28木 のものとします。
- 【必須】 `コメント 300 文字以内` で今回の自分のアウトプットについてコメントを記入しましょう。
  - どういう意図でつくったか（必須）
  - どう伝わることを狙ってアウトプットしたか（必須）
  - ハッシュタグを追加した場合、ハッシュタグの意図
  - そのほか自分のアウトプットへの熱いメッセージあれば
  - 書きつくせなければ、 [note](https://note.com/) などで記事を追加でアウトプットしてもOKです。そのときは、こちらのスプレッドシートに記入ください。
- 【必須】現状の途中経過の制作物に他者フィードバックを受けて自分なりにどう対応したかを書きましょう。
  - どこからフィードバックを受けたか（必須）
  - どんな風にちょっとでも磨いたか（必須）

## ツイート時の注意

ツイート時は `#protoout #DHGS #M5Stack` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。
- `#M5Stack` のアウトプットになるので、こちらもつけて、M5Stack 本家や M5Stack でモノづくりしている人の目に留まるようにしましょう！
- そのほか、自分の投稿に合ったハッシュタグを 1 ～ 2 個つけて狙ったターゲットに向けて届けるのも良いでしょう。
- 「自分のつくったものを元に他者に届ける」を大きく逸脱する、今回のアウトプットと関連性のないハッシュタグで無闇に違うターゲットにむけて届けるのは NG です。
  - （余裕があれば例を出す）

## アドバイス

- センサー類は機材リストに縛られず追加購入して試してみてもOKです。
  - Slack で相談してくれれば、サポートできます
- 第 4 回終了後から 1 週間で作るのは余裕がないと思うので、そろそろ「最終制作へ向けてつくりつづけアウトプットするなかで宿題を提出する」心構えがおススメです。
- 完ぺき主義になりすぎずに、いま作れたものを受け入れて活かしていくことが大切
  - 自分の発想したものが、この制作物でどこが試せるのか、検証できるのか、伝えられるのかを良い着地をさせてアウトプットしていきましょう
- アウトプットだけすごい制作物をつくれることも　まれに　ありますが、基本的には、自分で発想して、どうカタチにしようか試行錯誤して創造したもので、行いましょう。こういった、軸のあるところからアウトプットをしたほうが、自分にもほかの人にも響くことが多いです。
  - 自分に合ったワクワクする良い発想は、つくりたくなる良い創造を呼び込み、伝えたくなるアウトプットをしたくなります！


# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから README に戻りましょう。

# 第5回 IoT開発ボード設置・外装入門

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第5回　2021年10月22日（金） 8限　21:00 ～ 22:30　遠隔授業
```

※書かれている時間は予想の所要時間です。前後する可能性があります。

- はじめに 10 分 → このページ
- IoT開発ボード M5Stack の外装や設置のプロトタイプの世界観を学ぶ 20 分
- 身近なものを外装や設置に活用する手法を学ぶ 30 分
- 外装や設置時の最低限押さえる注意ポイントを学ぶ 20 分
- 第 7 ～ 8 回の最終課題について 10 分

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 第 5 回の心構え

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

第 5 回では、IoT開発ボード設置・外装の入門を学びます。

M5Stack のボタンやディスプレイの実装をはじめ、センサー連携について学びます。

- M5Stack の外装や設置についてのメリットを改めてふりかえり、身近なものを外装や設置に活用する手法を学びます
- 最終発表の第 7 回まで、あと 2 回です。そろそろつくったものをまとめながら、プレゼンできるようにスライドを作っていきましょう
- 今日は座学が中心です。

## 第 5 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- ソフトウェアのプロトタイプと同じように外装や設置のプロトタイプもイメージできるようにする
- ソフトウェアだけでなく外装や設置もつくりつづけるためのポイントを把握する
- ソフトウェア・外装・設置それぞれが、どのようにアウトプットにつながるかを把握する

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- 最終発表向けた制作物がほぼほぼ決まっていて、自分の外装や設置についてどうするかが想像できる状態

## 授業開始

では授業をはじめましょう！

左のメニューから「外装や設置のプロトタイプの世界観」をクリックしましょう。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

# IoT開発ボード M5Stack の外装や設置のプロトタイプの世界観を学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## プロトタイピングとは試すだけではなくその先が見えることも大事

![image](https://i.gyazo.com/0948d2813896a4a088470af93affc2df.png)

自分の作るプロダクトは、伝えるユーザーであったり、自分の考えであったり、さまざまな影響で変化し続けるものです。ですので、最初から全てを見通すことは難しいです。

そのため、素早く作って試すプロトタイピングは大事。

さらに作ったことよって、その先が見えることによって具体的な実装方法が見つかったり、ユーザーの操作をより良くする改善ポイントが見つかったり、はたまたより良く伝える手法が磨くことができます。

## 自己完結と人に見せることの良さ

![image](https://i.gyazo.com/ad801973390a7119d949f080ba66c541.png)

自分だけ完結してしまうと「これでいいや」になったり「不便だけど自分が合わせちゃおう」と自己最適化になりがち。
もちろん、制作の初期は仕方ありませんが、このまま他の人に伝える（触ってもらう）となると、使いにくさがノイズとなって自分の伝えたい本当の良さが伝わりません。

ですので、早いうちから勇気をもって、人に触ってもらいながらプロダクトを磨いていきましょう。

そうすることで、他者からのフィードバックが生まれます。たとえば、具体的な使いにくいポイントが見え次にどういう実装をしていけばいいかが見えるでしょう。たとえば、思いもしなかった良さに気づくことができ、新しい発想が生まれることもあるかもしれません。

## 身近な人に見せれることが第一歩。机の外に出ましょう。

![image](https://i.gyazo.com/2abe2c6923c518b6474caf6506e402e7.png)

では誰にアウトプットしていくか。それは、まず　身近な人　です。家族・パートナー・友人といった相手に触ってもらうことは色々なメリットがあります。

- 気軽に声をかけやすい
  - 展示会のような不特定多数の人を相手に、触ってもらい使ってもらうまでは一苦労です。身近な人の場合は声がかけやすく気軽なアウトプットに向いています。
- 素直なフィードバックが得やすい
  - 身近な人の場合、良い意味で遠慮がありません。手加減のない触り方をしてくれますし、使いにくいときのコメントもしっかりもらうことができるでしょう。

### 参考記事：ビッグオー駆動型開発

ややネタっぽい記事ですが、ユーザーインタビューやユーザーテストなど、ユーザー中心にしたデザインの入り口としてはとてもよいです。

https://web.archive.org/web/20140701071250/http://fladdict.net/blog/2014/02/big-o-driven.html

### 閑話休題：今回のサンプルを私の息子に触ってもらった例

![image](https://i.gyazo.com/5610064c50c99bac950ca23e0b603deb.jpg)

うっかり作業机に置いていた時に見つけて息子が触りまくった例です。

![image](https://i.gyazo.com/6cfadc52738ac5141aca7511993aa8f4.jpg)

まず、M5Stack が多少の無茶な触り方をしても大丈夫だったという気づきを得ることができました。仮に基板むきだしのものだと、とてもじゃないですが触らせることができません。

そして、このあと音を鳴らすことでより面白がってくれました。

## 外装・設置は他者に伝えるうえでの重要な入り口

プレゼンテーション中にリアルタイムデモで見せて他者に伝える、身近な人に直接触ってもらい他者に伝える、展示をして不特定多数の他者に伝える、いろいろなアウトプットの伝え方がありますが、外装・設置は他者に伝えるうえでの重要な入り口です。

![image](https://i.gyazo.com/e404c99ba7d8487a2104b5bd07789985.png)

まず、サッと手元で見せるなら外装は大事です。以前の授業で伝えましたが、あらためて、身近な人に伝える触ってもらうと考えるとどうでしょう？

やはり基板むき出しというのは触れてもらうのが怖いですよね。それ以前に「いやだ触るの」と相手側から躊躇されてしまうかもしれません。

アウトプットをしてからのフィードバックを得られるスタートラインに立てないのはもったいないです。今回は M5Stack そのものの外装の話に加えて、段ボールなど他の素材を加えて伝える TIPS をお伝えします。

![image](https://i.gyazo.com/5f704859d26d5fff993d3204556108e9.png)

さらにステップアップして、家で常設して使ってもらったり、展示で見せたい場合には外装だけでなく、設置の仕方も大切になってきます。こちらについても、身近な素材を中心に TIPS をお伝えします。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「身近なものを外装や設置に活用」にすすみましょう。

# 身近なものを外装や設置に活用する手法を学ぶ 1

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## ソフトウェアは手軽に書き換えることができプロトタイピング向き

![image](https://i.gyazo.com/cd807570cbbee915df45eb5342be6fcb.png)

いままで、みなさんは M5Stack のソフトウェア面を中心にプロトタイピングをしてきました。

ソフトウェアはプログラム（命令）を書き換えることによって、M5Stack で言えばセンサーに合わせてデータを取得したり、LINE BOT にデータをやり取りしたり、ボタンやディスプレイの動きを手軽に変えることができます。

ソフトウェアは、素早く作って試してフィードバックを得るというプロトタイピングの視点から考えると、とても相性が良いものです。

## 外装、設置もプロトタイピングととらえることが大切

外装、設置を含めてハードウェア部分は、本来であれば普通に取り組んでしまう場合、ソフトウェアと比べて、作り上げるまでが手間がかかったり、手軽に後戻りができなかったり難しい面があります。

外装、設置もプロトタイピングととらえることが大切です。身近なものを外装や設置に活用して、ソフトウェアと近い感覚でプロトタイピングできるよう、学んでいきましょう。

- いつでも粗く作ることができる
- 壊れても直すことができる
- 間違いに気づいても直すことができる
- つくって楽しい

このような、ソフトウェアにおけるプロトタイピング同じポイントを大事にします。

## 紙や段ボールによるプロトタイピング

![image](https://i.gyazo.com/eaa136739ae77c790efde166b4f9a848.jpg)

身近にある素材として、紙や段ボールはおススメです。

![image](https://i.gyazo.com/c55faac88c7966017b3c9a4bc0fcf2b5.jpg)

たとえば、[micro:bit v2\.0の新機能で、叩くと音を奏でる段ボール楽器](https://www.pc-koubou.jp/magazine/50844) のように、音の鳴る仕組みをつくって試してみるというところであれば、このように段ボールの箱を使ってつくることができます。

![image](https://i.gyazo.com/1af30dec83f462a79d778b040603dd5f.jpg)

[micro:bitでルーレットゲーム](https://www.pc-koubou.jp/magazine/41952) のサンプルのようにボタン部分を段ボールで作っていますが、ちゃんと押すことができます。

また、ペンで文字を書くことによってボタンを分かりやすくすることができます。もちろん、人に伝えるうえで「こんなに雑でいいのか・・・？」と思うかもしれませんが、そういう気づきが生まれれば次のタイミングで磨いていけばよいのです。

![image](https://i.gyazo.com/7433f5fc8588b81eaacd24c46370af4a.jpg)

[超初心者でも簡単！micro:bitで表情が変わるロボット](https://www.pc-koubou.jp/magazine/34014) では、空き箱のボール紙を使って作っています。

見た目を作りきることで強く印象付けて案内することは大切ですが、相手にもざっくり見立てられるくらいに留めて使ってもらうという力の抜き方も大事です。

こうすることによって、パワーをかけた制作物がうまく伝わらず消耗してやり直すよりも、粗く見えるがちょっと親しみが出るくらいで、触ってもらえるくらいでアウトプットして、フィードバックによる次のつくるを軽やかに行うことができます。

## タッパー（密閉容器）

![image](https://i.gyazo.com/0ea985943ddf28c51dc6a6f4d0f1fd3b.jpg)

100 円ショップで購入できる、タッパー（密閉容器）もおススメです。サイズが豊富で、柔らかいプラスチックの場合はカッターでも刃が入りコードの穴あけや封入の加工がしやすいです。

どれくらい豊富かというところは以下の記事も見てみましょう。

[ダイソーのタッパー全サイズ 種類を調査 ガラスのやおすすめを紹介！ \| 100均情報部](https://xn--w8j1bps3l.net/282.html)

![image](https://i.gyazo.com/2355667a9d1c00ce16f6177807f7cb98.jpg)

また、このような、やや硬い素材のプラスチックも穴あけの加工はしにくいですが、頑丈で設置するときに、対応しやすいです。

紙や段ボールと比べて強度があり展示時にも安心です。

### 実装例1

![image](https://i.gyazo.com/4760580800fc640eef4c4d9fe04714e0.jpg)

私が以前行った実装例です。

![image](https://i.gyazo.com/218e1b6dd066d3c03fd6a7f35e326982.jpg)

こちらは、わりと良く使っている電池ケースです。柔らかい素材なので色々な試行錯誤を重ねて、CO2・温湿度センサーと M5Stack を封入しました。横の穴で天井に吊るすことができて、計測時にも扱いやすかったです。

- [実装の様子の一連の流れ](https://twitter.com/1ft_seabass/status/1382882665032949761)

### 実装例2

![image](https://i.gyazo.com/31fe78ec4e3ead065a9caad0e57aeb12.jpg)

うこさんの [「LINEで操作できるスマートロックのプロトタイプを弊社に実装した（製作7時間・材料費約3500円）」 / Twitter](https://twitter.com/ukokq/status/1181550006890684418)

## 100 円ショップはアイデアと素材の宝庫

![image](https://i.gyazo.com/c98aaef7b577d8f9827acf66522c1e8e.jpg)

タッパー（密閉容器）をはじめ 100 円ショップは、つくる上でのアイデアと素材の宝庫です。ハイスキルなメイカーなひとでも、100円ショップにある素材や電子部品は定期的に巡回して、参考にしている人は多いです。

イチから自分でつくれなくても、ケースや部品など出来合いのものを 100 円ショップで購入して活用するのは、プロトタイピングにはおすすめです。100　円ショップで色々な素材を見ることで発想が広がったり実現度が高まったりするので、定期的に眺めておくとよいでしょう。

また、展示をする際も、100 円ショップで調達できるものが把握できていると、何かが壊れたときや、新しく何かを加えたいときに、いざというときに、近場の 100 円ショップで調達できるというテクニックも使えます。

いくつか、プロトタイプに便利な素材をご紹介します。

### グルーガン

![image](https://i.gyazo.com/d54e81137101d61a3f26fc66e3e21fb3.jpg)

段ボールや紙の素材を使うときにグルーガンは役に立ちます。素早く固まって接着スピードも速く、接着も強く、作業が素早く行えます。

- [【初心者必見】グルーガンの使い方と気を付けるポイント ｜ コラムカテゴリー：お役立ち ｜ コラム \- くらしメイド ｜ ＤＣＭ](https://www.dcm-hc.co.jp/kurashimade/c_useful/20190216192203.html)

### マスキングテープ

![image](https://i.gyazo.com/c71d24e26a564adcdbd8caee20cdfb3f.jpg)

段ボールや紙の素材を使うときにマスキングテープもおすすめです。こちらは、一度貼り付けても、きれいに剥がすことができ、試行錯誤に向いています。何かをより強く固定するときに仮留めとしても使えるので重宝します。

セロハンテープやガムテープは一度つけてしまうと、跡が残ったり紙を痛めやすいので、一発勝負になりがちで試行錯誤に向いていません。

つけた部分が見栄えするので、電子工作部分が衝撃でハズレたりしないようにする固定するときにも助けになります。工作時に「どこをつけてこの構造を作った」ということが目で見て伝わりやすいのも特徴です。

### その他の素材

- 結束バンド
- 絶縁テープ
- USB ケーブル
- など

## 図工レベルの制作力をうまく取り入れていきましょう

![image](https://i.gyazo.com/445e912b4067c05b12269fcb196b21c5.jpg)

ここまでで紹介した手法は、難しい工具はあまり登場せず図工レベルのものです。このレベルであれば、身近な素材からすぐにはじめることができ、途中で修正もしやすいです。手元の PC の横で、ソフトウェアの制作もしながらつくるにはもってこいです。

ここでもプロトタイプです。

いきなり、難易度の高い構造物にチャレンジしてうまくいかなかったり時間がかかって挫折するよりも、粗くてもすぐに作れて試行錯誤できることを大事にして、自分のプロダクトを伝えるための入り口としてのインターフェースをつくってみましょう。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「身近なものを外装や設置に活用2」にすすみましょう。

# 身近なものを外装や設置に活用する手法を学ぶ 2

ここでは、もう少し深掘りしたテクニックをいくつか紹介します。

## 設置といえば M5Stack の背面には磁石がある

気づいている人もいるかもしれませんが M5Stack の背面には磁石が内蔵されています。ですので、磁石のつく素材にイイ感じにくっつきます。

![image](https://i.gyazo.com/90c1a543fdfff9970ab881e0414aac72.jpg)

このように、冷蔵庫にくっつけた例です。これをうまく使うだけでも、設置をする助けになるでしょう。

![image](https://i.gyazo.com/f68fc52b19a158dca7eea7a22ca81d92.jpg)

突っ張り棒も鉄でできているので、このようにくっつきます。（もうすこし補強したほうがイイとは思いますが）

あくまで一例ですが、自分が作りたいプロダクトの設置場所で磁石が生かせないか考えてみるのも良いでしょう。

## LEGO

![image](https://i.gyazo.com/7c5443a595a3f66176543806b5db3486.jpg)

LEGO は柔軟に形が作りやすく、プラスチック素材のため絶縁できるので電子工作の部品とも相性が良いです。もちろんカラフルで見栄えがするため、見る人にも触りやすさがあります。

![image](https://i.gyazo.com/b72843dd10f8ce78b33a7743532c36d3.jpg)

たとえば、このように以前の展示で Grove カラーセンサーを LEGO で構築しました。

![image](https://i.gyazo.com/d8032b0895b86b53dbccbdd4a691c217.jpg)

カラーのろうそくを立てるとセンサーが色を認識してライトに同じ色を伝えるという仕組みです。

### LEGOのその他の事例

![image](https://i.gyazo.com/028da2d55ebc4ebf91c460c5e8a4635f.jpg)

[@1ft\_seabass \#LEGO \- Twitter検索 / Twitter](https://twitter.com/search?q=%401ft_seabass%20%23LEGO&src=typed_query&f=live)

### LEGO バラ売りの視点

LEGO のパッケージ売りも良いですが、つくる上ではパーツの種類のバランスが整っていないこともあるのでやりづらいです。実は LEGO バラ売りをしているサイトがいくつかあり、インスピレーションの宝庫です。

- [LEGO・レゴパーツ・ミニフィグ通販 【ECOBRICKエコブリック】](https://ecobrick.jp/)
- [レゴパーツからミニフィグまで揃う通販専門のレゴショップ ブリッカーズ](https://www.brickers.jp/)
- [レゴパーツ・LEGO・ミニフィグの通販の販売店∥StarBrick37\(スターブリック\)](https://starbrick37.com/)

たとえば、

![image](https://i.gyazo.com/c7189d6ee74e9f04e566a97e5f29feb8.png)

このように、バラ売りで色々と探すことができます。

![image](https://i.gyazo.com/d4cec2f1d9fe92a84cc6e155477d3740.png)

![image](https://i.gyazo.com/731f2c8e65dbdc8f0b6710495568595d.jpg)

こういったアイテムも展示やプレゼン時に魅力的に見えて、楽しさが伝わります。

## 3M コマンド タブも試行錯誤しやすい

![image](https://i.gyazo.com/7e41fd4e7b16dfaf63c7ba321425c4ed.jpg)

設置面では [3M コマンド タブ](https://www.command.jp/3M/ja_JP/command-jp/) もおすすめです。しっかり貼れて、簡単にはがせるので、設置面の試行錯誤に向いています。

![image](https://i.gyazo.com/d6d10f1b7e8f13a38ca6b5dee67e436e.jpg)

ザラザラしていない滑らかな面の場合は、かなり強くくっつくので、長い時間設置していても安心です。といいつつ、このように、木材のハリの部分にくっつけたものも、安定して接着されているので、利用できる範囲は広いです。

## 結束バンドで設置

![image](https://i.gyazo.com/05d0c28b3cfe78ebad4e9e39241f0e45.jpg)

試行錯誤という点では、結束バンドも活用できます。

![image](https://i.gyazo.com/e8ce3dff441159133a249d126dc5ab37.jpg)

これはあくまで一例ですが色々な場所にかなり強く結束することができます。

もしも位置を変えたくなったり、違う設置を思いついたりしたときは、ニッパーやハサミで切断して外してやり直すことができます。

## その他の事例いくつか

- [micro:bit 地磁気センサーで宝探しゲームを作ろう！ \| パソコン工房 NEXMAG](https://www.pc-koubou.jp/magazine/44545)
- [micro:bit Makecodeで光センサーを使った「開けてはいけないお菓子箱」 \| パソコン工房 NEXMAG](https://www.pc-koubou.jp/magazine/31344)
  - 家にあったアリものの箱を使った例
- [micro:bitでおうちトレーニングツールを作る](https://www.pc-koubou.jp/magazine/36517)
  - 定規とマスキングテープを使った例

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「」にすすみましょう。# 外装や設置時の最低限押さえる注意ポイントを学ぶ

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

プロトタイプにおいて、サッと作れなくなるような制約は避けるべきですが、気をつけることはあります。

## 作業中の感電やショート注意

![image](https://i.gyazo.com/01b4de6825914d913d5c1b8348bed9fd.png)

最低限の電流の流れは把握して金属面の接触は避けましょう。

## 水気には注意

![image](https://i.gyazo.com/a6dbc4de59f7f746c69a117aa174a4ec.png)

M5Stack に外装がしっかりありますが、湿気や水気には他の電子工作と同様弱いです。

## ケガをさせないように外装をちゃんとしましょう

![image](https://i.gyazo.com/15e7580eaf5031f79db71b264ec687b5.png)

M5Stack だけなら良いのですが、他にセンサーや動くものを取り付けるときは、触る人がケガをしないように気をつけましょう。

## 使ってもらうユーザーに分かりやすいかを考えましょう

![image](https://i.gyazo.com/b13a2c1017fd1a6893eb3f408f867439.png)

外装も設置も実際に使ってもらう人が、最初にどのように触れて、どのように操作をしてみて、どのように動くかを考えながら作りましょう。

もちろん、一度見せてみて分かりにくい伝わりにくいところを良くしていくことも大切です。

## 3D プリンタや木工鉄工 DIY も良いが、起動コストを意識しましょう

![image](https://i.gyazo.com/556c485a1123a1dce8515ecd6189320c.jpg)

CAD ソフトでつくった形状を、現実のオブジェクトとして出力できる3D プリンタであったり、

![image](https://i.gyazo.com/fcc874d8b5034ad3433a55ddf8dde763.jpg)

このような木工鉄工 DIY も、つくる人には素敵なスキルです。

![image](https://i.gyazo.com/0658151fc8bd99c99b698d0178158e0a.jpg)

しかし、これらは準備や作業に慣れていないと、プロトタイプの気持ちの起動されるとき（つくろうという気持ちを起こすとき）に大切な「粗く作る」ではなく、時間をかけてしっかり作るに行きがちになります。

まずは、身近な加工しやすい素材で手慣れた工作・図工スキルからはじめるのが良いでしょう。ソフトウェアでもハードウェアでも、つくるときにいつでも粗く作りだせることができることは大切です。

3D プリンタについては、有効な使い方もあるので、次の授業でもう少し補足できるかもしれません。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「最終課題について」にすすみましょう。

# 最終課題について

![image](https://i.gyazo.com/f91e1feeb95141876a9276a6cb715ca8.png)

## 第 7 回と第 8 回を分けようと思いましたが！

連続性があるので、ひとつのドキュメントに収めました。

## 課題全体からの位置づけ

全体としては

```
- 最終課題　50％
  - 発想力・創造力・アウトプット力・継続制作力※ の要素で採点する予定です。
- 授業内の課題　50％
  - 機材をそろえて準備する課題 10％予定
  - 制作してアウトプットする課題 20％ * 2 予定
```

※以前は継続開発力としていましたが `継続制作力` としました。 

で採点を予定しています。

今回は最終課題です。

第 7 回では制作デモを伴うプレゼンテーションを行い、生徒同士でフィードバックを行います。

第 8 回では、そのフィードバックを元に自分なりに制作物のブラッシュアップを行ってプレゼンテーションを行っていただきます。

## この宿題の意図

いよいよ、最終課題です。

M5Stack ・アウトプットすること・つくりつづけることを学んだプロダクトプロトタイピング II 。いままでの集大成としてプレゼンテーションしていただき、フィードバックを受けて自分のプロダクトを一歩磨いていくアクションをしましょう。

## この宿題のゴール

この宿題のゴールは、今後、自分のプロダクトをつくりつづけるために、発想し創造し、アウトプットし、フィードバックを得て、またつくるサイクルへつなげていくこと一度以上回すことがゴールです。

そのほかにも、

- M5Stack ・アウトプットすること・つくりつづけることをバラバラではなくうまく融合させる
- プレゼンテーションするというアウトプットを体験し今後のアウトプットに活かす
- 発表することによって自分自身のフィードバックも活性化し、よりよい制作につながる

といったことも把握できるようにしましょう。

## 第 7 回の流れ

![image](https://i.gyazo.com/a487699b6132c7a8ee291008a43d5163.png)

- 最終課題として作ったものをプレゼンテーションします
  - 伝える内容
    - この作品はどんなものか（コンセプトや自分の想い）
    - どうつくりつづけたか
    - 制作デモ
      - 動画デモ or リアルタイムデモ必須
- プレゼンテーションの制限時間は 1 人あたり  7 分以内
- 発表後、フィードバックフォームから「良かった点」「気になった点、こうするといいなっていう点」フィードバックを書き込み
  - これは生徒全員が他の生徒全員に対して授業時間内のリミットで行います
  - 予定フォーム → URL 見えますか？
    - https://forms.gle/VrjbHhUuNANiv2Ln9
- 授業終了後、フィードバックを踏まえて第 8 回にブラッシュアップ
    - 生徒の皆さんが見れる予定スプレッドシート → URL 見えますか？
      - https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit?resourcekey#gid=913017201

## 第 8 回の流れ

![image](https://i.gyazo.com/a487699b6132c7a8ee291008a43d5163.png)

- 第 7 回を踏まえてブラッシュアップした内容をプレゼンテーションします
  - 伝える内容
    - どんなフィードバックをピックアップしたか
    - そのフィードバックを自分なりにどう消化しアウトプットしたか
    - 今後の展望・目指すところ
- スライドを画面シェアしてプレゼンテーションします
- プレゼンテーションの制限時間は 1 人あたり 5 分以内
- 1 人が発表後、2 ～ 3 分質疑応答

## 厳守事項

- 制作物には M5Stack を使用した IoT の仕組みにしましょう
  - 例：
    - M5Stack を操作画面（LINE BOT or LINE Notify or 何かしら自作のWebの仕組み ）で遠隔操作する
    - M5Stackで何かしらのセンサーや入力によって Web 上の何か（LINE BOT or LINE Notify or 何かしら自作のWebの仕組み ）を動かす
- 第 7 回
  - 制作デモを伴うプレゼンテーションを時間内に行いましょう
  - 各生徒は他の生徒全員にアンケートフォームから授業内にフィードバックを行いましょう
  - 提出場所のフォルダに第 7 回で発表した自分のスライドを提出しましょう
  - 提出場所のスプレッドシートに今回の自分の最終課題についてコメントを書きましょう
- 第 8 回
  - 前回のフィードバックを元に、自分なりに制作物のブラッシュアップを行ってプレゼンテーションを時間内に行いましょう
  - 提出場所のフォルダに第 8 回で発表した自分のスライドを提出しましょう
  - 提出場所のスプレッドシートに今回の自分のブラッシュアップについてコメントを書きましょう

## 第 7 回の採点基準

![image](https://i.gyazo.com/cde6f43a81eff49bb72d784b695f9352.png)

こちらの 3 要素で採点します。 30 点。

- 発想力 10点
  - 自分の今までの知識や経験に基づいて自分なりに思いついているか（独自性）
  - 自由に発想ができているか（自在性）
- 創造力 10点
  - 発想を自分の技術と自分の考えをうまく組み合わせてカタチにできているか
  - 今の自分から得たものとともに新しい価値にチャレンジをしているか
- アウトプット力 10点
  - 制作物を通じて自分の考えをアウトプット出来ているか
  - 狙った他者（ターゲット）に伝わるように工夫できているか

## 第 8 回の採点基準

![image](https://i.gyazo.com/2fef3f7c4c5c85f762b431a724ca3a51.png)

こちらの 2 要素で採点します。 20 点。

- アウトプット力 10点
  - 制作物を通じて自分の考えをアウトプット出来ているか
  - 狙った他者（ターゲット）に伝わるように工夫できているか
  - `New!` 第 7 回を踏まえてツイートなどでアウトプットしているか
- 継続制作力 10点
  - 自分や他の人からのフィードバックを受け入れてつくりつづけようとしているか
  - ただ、受け入れるだけでなく、自分なりに消化した上で、自分のプロダクトを磨いているか
  - 自分の目指す方向性を自分で理解しながらリアルタイムにプロダクトを考えてつくり続けているか

## 採点の目安

![image](https://i.gyazo.com/1d7db6c8dbf045153908d63c8880ef60.png)

最終課題の採点の目安をお伝えします。状況を見て、少し調整する可能性はあります。

- 発想力
  - Lv.1 授業で学んだことから少しだけ変化して発想している
    - 単純な連想レベル
  - Lv.2 授業で学んだことに自分の今までの知識や経験を加味して発想している
    - 自分の作りたいものが感じられる。学んだ仕組みが自分の作りたいものに反映されている
  - Lv.3 授業で学んだことをうまく自分にとりこんで自由に発想している
    - 自分の作りたいものが明確にある。Lv.2 よりも自由度があり、この先に進もうと色々な発想ができている
- 創造力
  - Lv.1 発想したものを授業で学んだ技術を組み合わせてただカタチにしている
    - サンプルを動かしただけのような、発想が小さくカタチにするものも小さい
  - Lv.2 発想したものを授業で学んだ技術だけでなく自分の今までの力を加味してカタチにしている
    - 授業で学んだ技術が自分とうまくとりこまれ、つくるものに反映しだしている
    - 制作物を作ることに精いっぱいで、なんとか現状を伝えようとしている
  - Lv.3 発想したものをカタチにするだけでなく、それにより試行錯誤をして新しい知識や発想が生まれながらつくっている
- アウトプット力
  - Lv.1 ただハッシュタグをつけて文章でできましたとツイートするだけ
    - つくったことはなんとか伝わるが制作物に対する思いや内容が伝わらない
  - Lv.2 文章だけでなく画像や動画を使って分かりやすく制作物を伝えようと工夫しはじめている
    - 制作物の内容（のみ）を他者に伝えるために試行錯誤がしはじめている
  - Lv.3 制作物を伝えつつ自分の発想や制作過程といったそこに至る経緯が伝えようと工夫しはじめている
    - 制作物だけの「点」だけでなく自分の思考や経緯、伝えるターゲットを意識して「線」として結んで考えられる
    - 制作物を作って終わりでなく、途中経過でも自分の考えたつくったものの価値を試すためのプラスととらえはじめている。
    - 徐々にだが、他者のフィードバックとして、他者からのコメントやいいね！を目を向けはじめている
  - Lv.4 つくりつづけることを意識して現状のアウトプットを自分の制作も他者へ伝えることも楽しみはじめている
    - 自分の「つくる」という大きな流れの中で行動している。Lv.3 が過去→現在を伝えているとすると、未来も意識しはじめている。
    - 自己のフィードバックとして、今回はここまでだったけど制作物をこうしたい、技術を新しく加えて制作物を発展させたいなど考えはじめている。
    - 他者のフィードバックとして、他者からのコメントやいいね！を目を向けて、今後のブラッシュアップの糧にしようとしている。
  - Lv.5 つくりながらアウトプットしてフィードバックを得てつくるものを日々磨いている
    - Lv.4 の発展した状態。
    - 日々自分と対話しながら技術や発想をカタチにしつづけている。たとえ小さくても何かしらつくっている。
    - 良い意味でつくるための課題が常にあり日々新しい情報の収集や技術習得をしようとしている。
    - つくりつづけているので伝えたい原資があるため、計画的なアウトプットができる。心の中にドラフト（下書き）がある。
    - そのときの興味ある話題に対しても自分のインスピレーションをもち、つくるものにミックスして瞬間的で魅力あるアウトプットを柔軟に行う場合もある。
    - つくりつづけて自分のつくりたいものへの自己フィードバックがカジュアルに持っていて、それ軸にもちつつ SNS や直接の交流からくる他者のフィードバックをうまく取り込んでいる
- 継続制作力（つくりつづける力）
  - Lv.1
    - 自分や他の人からのフィードバックに目を向けはじめている
    - フィードバックに対しての対話は少ないが、なんとかつくろうとしている
  - Lv.2
    - フィードバックを自分のつくりつづける糧にする意識がある
    - フィードバックをただ受け入れるだけでなく、自分に作りたい軸があり、自分なりにフィードバック消化した上でプロダクトに反映している
  - Lv.3
    - Lv.2 から発展した状態
    - 自分の目指す方向性を自分で理解しており、フィードバックとうまく融合させながら、先を見据えてリアルタイムにプロダクトを考えてつくり続けようと行動している

## 第 7 回 提出場所

![image](https://i.gyazo.com/f31f0a37c64f84203adf5ebd7e86b647.png)


https://drive.google.com/drive/folders/1jrOE4hWfi3x_jQZz_Xn-FsVDfeAKtk9o

第 7 回終了までに、最終課題を発表した自分の ~~スプレッドシート~~ スライドをこちらにアップロードしましょう。Google スライド推奨。

![image](https://i.gyazo.com/ff6d87f56597f436f7a3e5a1ebef0c00.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=386298483

こちらのスプレッドシートに、今回の自分の最終課題についてコメントを記入しましょう。

  - どういう意図で最終課題をつくったか（必須）
  - どう伝わることを狙ってプレゼンテーションしたか（必須）
  - そのほか自分のアウトプットへの熱いメッセージあれば

## 第 8 回 提出場所

![image](https://i.gyazo.com/9470e97bd0c0637b9451de5031d1c8af.png)

https://drive.google.com/drive/folders/1-qQM9du1tYWp1tsw825-xpabR5aLywDp

第 8 回終了までに、ブラッシュアップについて自分の発表した ~~スプレッドシート~~ スライドをこちらにアップロードしましょう。Google スライド推奨。

![image](https://i.gyazo.com/bade2c607337ece8011631469039d536.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=167621219

こちらのスプレッドシートに、今回の自分のブラッシュアップについてコメントを記入しましょう。
  - どのフィードバックを自分なりに消化してブラッシュアップしたか（必須）
  - 今後どのようにつくりつづけていくかの考え（必須）
  - そのほか自分のアウトプットへの熱いメッセージあれば

## Google スライド推奨にしちゃったけどよいですか？

![image](https://i.gyazo.com/e08b7298cc964e54f307413b98ac1a70.jpg)

みなさんに聞いてみる。~~とくに問題なければ、必須にしたい。~~ → スライドデータは PowerPoint や Keynote もOK。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから README に戻りましょう。

# 第6回 IoT開発ボード設置・外装実践

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第6回　2021年10月29日（金） 8限　21:00 ～ 22:30　遠隔授業
```

※書かれている時間は予想の所要時間です。前後する可能性があります。

- 10 分 はじめに
- 30 分 宿題を通じて入門で学んだことを元に設置・外装まで実践を学ぶ
- 30 分 プロトタイプの過程をアウトプットしフィードバックを得る手法を学ぶ
- 20 分 他の人からフィードバックを得るためのアンケート方法を学ぶ

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 宿題お疲れ様でした！

![image](https://i.gyazo.com/292056186195353716d85baaaf401a42.png)

昨日は宿題ひとまずお疲れ様でしたー！これから採点させていただきます。

今回宿題を通して、連続アウトプットを課すことで、自分のプロダクトについて、いつもより常に意識を置けました。自分のアウトプットを客観的にながめることで、自分の考えやプロダクトを整理することもできました。

普段の日常や忙しいことがあるときに、自分のつくりたいことから意識が遠のいてしまってアウトプットが難しくなることも体験できたね。

ちゃんと連続アウトプットをコンプリート出来た方はおめでとうございます！

そして、コンプリート出来た方も出来なかった方も、自分の普段の生活の流れと、つくりつづけることのバランスの取り方がこうなるんだ、ということを把握できたので、心に留めて、今後に活かしていきましょう。

うまくいかなかったことも糧にして、サッと切り替えの良さもプロトタイピングには大切です！

## 第 6 回の心構え

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

第 6 回では、第6回 IoT開発ボード設置・外装実践です。

学んだ設置・外装からの実践への進み方を学んだり、最終課題へ向けての取り組み方を学びます。

- のこり 1 週間でプレゼンテーションをするために、制作と発表資料作り両面でがんばりましょう。
- フィードバックにどう取り組んでいくかも意識できるようにしましょう。

## 第 6 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- 設置・外装について様々なステップの踏み方を把握しましょう。
- フィードバックつながるように、どのｙほうにプレゼンテーションするかの手法を把握しましょう。
- 自分のプロダクトの糧になるように、フィードバック得てどう反映するかを把握しましょう。

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- 「制作してアウトプットする課題」の 2 回目が終わり、ある程度アウトプットできている状態で、あとは制作と発表資料作りに集中できている状態
- 今日学んだこともプレゼンテーションに柔軟に取り込めるように余裕がある状態

## 授業開始

では授業をはじめましょう！

左のメニューから「外装や設置のプロトタイプの実践」をクリックしましょう。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

# 外装や設置のプロトタイプの実践

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## LEGO + Grove

レゴブロックにもくっつく Grove 純正の Wrapper というものがあります。

![image](https://i.gyazo.com/e8135d74dfba41775128e0964bf6b6fe.jpg)

![image](https://i.gyazo.com/4bfb62f8276dfa23672d1515b9b7c0d9.jpg)

これにGroveをつけると連結できたりレゴブロックにもくっつし、ネジ止めで木材などに固定できます。

- 参考記事
  - [レゴブロックにもくっつくGrove純正のWrapperがステキだったメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2017/09/14/grove-wrapper-is-cool/)
- 購入先
  - [Grove \- Blue Wrapper 1\*2\(4 PCS pack\) \- Seeed Studio](https://www.seeedstudio.com/Grove-Blue-Wrapper-1-2-4-PCS-pack.html)
  - [Grove \- Wrapper 1 x 2 青（4個パック） \- スイッチサイエンス](https://www.switch-science.com/catalog/6999/)

## Grove の設置に便利な長ーいケーブル

今後、Grove センサーを扱っていくときに、 M5Stack から Grove を遠くに離して設置したいケースもあると思います。

> ![imaege](https://d2air1d4eqhwg2.cloudfront.net/images/5217/500x500/6314d39d-8e6e-4366-aaeb-43ceefdd0a9d.jpg)
> 
> [M5Stack用GROVE互換ケーブル 200 cm（1個入り） \- スイッチサイエンス](https://www.switch-science.com/catalog/5217/)

M5Stack 用の Grove 長い互換ケーブルというのがあるので、覚えておくと良いでしょう。もちろん、離しすぎると、電流が弱くなりセンサーがうまく動かない可能性もありますが、そのあたりは自分で試してみると良いと思います。

こういった延長、単純なデジタル入力センサーであれば、2 m 程度であれば全く問題なかったです（実体験）

そして、色々な長さのケーブルがあるので、シチュエーションに応じて使っていきましょう。

- [M5Stack用GROVE互換ケーブル 20 cm（5個入り） \- スイッチサイエンス](https://www.switch-science.com/catalog/5214/)
- [M5Stack用GROVE互換ケーブル 50 cm（2個入り） \- スイッチサイエンス](https://www.switch-science.com/catalog/5215/)
- [M5Stack用GROVE互換ケーブル 100 cm（1個入り） \- スイッチサイエンス](https://www.switch-science.com/catalog/5216/)
- [M5Stack用GROVE互換ケーブル 200 cm（1個入り） \- スイッチサイエンス](https://www.switch-science.com/catalog/5217/)

### LAN ケーブルで延長するちょっと荒っぽいアイデア

このナレッジは自己責任ではありますが、私が試した手に入りやすい LAN ケーブルを利用して電子工作のケーブルに使ってみたというナレッジです。 

![image](https://i.gyazo.com/e0a417b0084caa939a81cb7b1f0455fa.jpg)

[GroveケーブルをLANコネクタを合体させてGroveでのデジタル入出力がLANケーブルで延長できたメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2019/01/11/grove-cable-meets-lan-cable/)

![image](https://i.gyazo.com/a896ee3cac56af66c6f601b6f1824071.jpg)

[市販のLANコネクタ基板キットにGroveコネクタをくっつけるメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2019/01/29/grove-cable-meets-lan-cable-2/)

こういった、大きく展開できるナレッジを持っておくと、設置だけでなく展示するときも自由に考えられるようになるのでおススメです。

## M5Stack Basic用汎用ケース

タッパーを使ったケースの知見もありますが、ぴったりのサイズで樹脂が加工しやすいM5Stack Basicのためにデザインされた汎用ケースというものもあります。

> ![image](https://d2air1d4eqhwg2.cloudfront.net/images/6732/500x500/b0134df9-1ddd-423e-b227-66c4d15d2405.jpg)
> 
> [M5Stack Basic用汎用ケース FUSION CONTAINER \- スイッチサイエンス](https://www.switch-science.com/catalog/6732/)

ある程度、大きさが似たボリュームで収まるときや、ある程度しっかりした見た目を求めていく場合にはこういう選択肢もありでしょう。

私が使う場合は、似たボリュームのタッパーで一回収める実験をして、目測を整えてから使います。

## グルーガンの活用事例

電子工作でグルーガンを使う例として、いくつかご紹介します。

> ![image](https://i.gyazo.com/68cabedd8ddddb53a7a9b2a1f6a4d4ae.jpg)
>
> [NefryBTのGroveポートに直接つなげるためテープLED電子工作をしてみたメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2017/10/19/nefrybt-grove-port-brushup/)

テープ LED のような長くぶら下げたり、結合部分が負荷で外れやすいものは、グルーガンで固定すると便利です。

> ![image](https://i.gyazo.com/774caf83aec475e071d19204f0a67bfb.jpg)
>
> [Wio Node＋Grove リレー＋USB延長ケーブルでUSBライトをIoT化させるメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2016/12/04/wio-node_grove-relay_usb-cable_iot-hack/)

このような、展示用の配線を補強することにも使えます。

その他にも、良い文献がありました。見ていきましょう。

- [Make: Japan \| ホットグルーの11の応用、裏技、改造方法](https://makezine.jp/blog/2016/07/8-great-hot-glue-tips-tricks-hacks.html)
- [電子工作用ではないけど便利な工具　ホットメルトで部品を固定 \| RaspberryPiクックブック](https://www.denshi.club/parts/2016/09/post-15.html)
- [グルーガンの使い方、選び方、修理【図解】](https://diytools1.com/2016/05/13/post-14695/)

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「3Dプリンタプロトタイピング TIPS」にすすみましょう。

# 3Dプリンタプロトタイピング TIPS

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

やや泥臭い TIPS をいくつかお伝えします。

## 3D プリンタもプロトタイピングに活用する方法はある

![image](https://i.gyazo.com/b56d2101009011ec03d2e2f94a190d86.jpg)

先週お伝えしましたが、3Dプリンタは、このようなプロセスを踏んで、現実世界にオブジェクトを作りだします。

- 発想
  - 現実世界で活用したいところを見極める
- 採寸・設計
  - 活用したい場に合うボリュームをなるべく正確に把握し設計する
- モデリング
  - CAD ソフトで活用場所で求める形を CAD データで作り出す
- 成型
  - 3D プリンタの性能に合わせて CAD データから出力する
- 判断
  - うまく出力できれば完了
  - 修正するポイントがある場合は現実世界で活用したいところを見極めに戻る

どのパートもなかなかに難易度が高く、慣れるまでは、起動コストがかかりやすいのが難しいところです。

![image](https://i.gyazo.com/477468be7d81767232b5e5f416a193db.jpg)

このまま、プロトタイピングに取り入れると、ここに割くパワーと時間がかかりすぎて滞りやすいです。

ですが、これからご紹介する手法は、上記の流れをうまくコントロールできます。

## 段ボールのような工作のプロトタイプと組み合わせる手法

採寸・設計の部分は、定規などの測り方や目測で徐々に詰めていくものですが、慣れていないと計測ミスが起き、モデリングや成型に影響が出て、やりなおししがちで時間がかかりやすい部分です。

![image](https://i.gyazo.com/75ca5288c1e7750632239d8165aa222d.jpg)

このように、前もって紙にスキャンで写し取ったり、段ボールなどで仮の箱を作ったものを展開して計測いくと、定規などの測り方や目測に頼らず、イメージ通りの形状に辿り着くことができます。

- [Raspberry Pi Zeroの形状を写しとりIllustratorから123D Designに落としこむまでのメモ　前編 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2016/01/09/raspberry-pi-zero-3dprinter-make-stl_1/)
- [Raspberry Pi Zeroの形状を写しとりIllustratorから123D Designに落としこむまでのメモ　後編 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2016/01/10/raspberry-pi-zero-3dprinter-make-stl_2/)

## 形状データを配布しているところで近いオブジェクトからはじめる

もうひとつおススメの方法は、採寸・設計・モデリングをある程度一気に進められる方法として、形状データを配布しているところで近いオブジェクトからはじめる方法があります。

たとえば、M5Stack でも、

- [M5Stackにスタックできるケースを作る – ししかわのマウス研修 Part\.29 \| アールティ　移動型ロボットブログ](https://rt-net.jp/mobility/archives/12211)
- [M5stackの3Dデータ公開 \| 株式会社応用技術研究所](https://hagane-karakuriya.com/2021/03/18/m5stuck%E3%81%AE3d%E3%83%87%E3%83%BC%E3%82%BF%E5%85%AC%E9%96%8B/)
- [M5StackのCADデータを公開しました \| BotaLab](https://botalab.tech/m5stack_cad_data/)

このように、有志の方が配布いただいています。これをうまく使って、CAD ツールで立方体に押し当ててから形に合わせて削除すれば、ピッタリにハマる形状の出来上がりです。

本来であれば、0.3 mm ほど開いた形状を広げないと、3D プリンターの誤差によってハマらないなどありますが、おおまかなものにすぐにたどり着けます。

こういった形状データを探していくことも、まるでソフトウェア開発において、ある程度出来上がっているライブラリを探すような感覚と似たようなアプローチで、プロトタイプを加速することができます。

## LEGO パーツの試行錯誤例

![image](https://i.gyazo.com/f383b4bb9e253fa6eaff9b1342197227.jpg)

私が行った LEGO と電子工作の試行錯誤例があります。

> ![image](https://i.gyazo.com/b8e9640cdcb1832b960945fdb4f69d59.jpg)
>
> [DMM\.makeでlittleBitsとLEGO連携パーツ（フリーCADデータ）を出力したメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2015/11/02/dmm-make-littlebits-lego/)

電子工作のブロックと LEGO ブロックを組わせて形状の試行錯誤がしやすくならないかというところでこのようなことを行いました。

LEGO のようなメジャーなパーツは以下のようなサイトで 3D プリンタ用のデータを見つけることができます。

- [Thingiverse \- Digital Designs for Physical Objects](https://www.thingiverse.com/)
- [無料の3Dモデル \- Free3D\.com](https://free3d.com/ja/)
- [Free 3D Models and Objects Archive\. Download: 3ds , obj , gsm , max models](https://archive3d.net/)

> ![image](https://i.gyazo.com/94d34c00c5561d7b219eb6447fc3630f.jpg)
> 
> - [littleBitsマウントボードと連携するLEGOパーツの試行錯誤メモ 前編 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2015/11/10/littebits-lego-3dprinter-try-and-error-1/)
> - [littleBitsマウントボードと連携するLEGOパーツの試行錯誤メモ 後編 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2015/11/10/littebits-lego-3dprinter-try-and-error-2/)

このように、この制作に関するほとんどの形状データを、うまくみつけてプロトタイピングを加速することができました。

![image](https://i.gyazo.com/6e360f9dfb2bd3747c45ad2d647181b2.jpg)

- その他の文献
  - [Raspberry Pi Zeroケースの設計ミスを改善しフタまで実装するまでのメモ – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2016/02/07/raspberry-pi-zero-3dprinter-make-stl_3/)
  - [東京メイカーさんにダヴィンチ3Dプリンタの出力レクチャーを受けてきたメモ　前編 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2016/02/12/tokyomaker-3dprinter-lecture-1/)
  - [東京メイカーさんにダヴィンチ3Dプリンタの出力レクチャーを受けてきたメモ　後編 – 1ft\-seabass\.jp\.MEMO](https://www.1ft-seabass.jp/memo/2016/02/23/tokyomaker-3dprinter-lecture-2/)

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「アウトプットしフィードバックを得る手法」にすすみましょう。

# アウトプットしフィードバックを得る手法

![image](https://i.gyazo.com/13bd5b2ba6a6de3bce8f561fe60f9389.png)

いよいよ次回が最終発表というところでアウトプットしフィードバックを得る手法に焦点を合わせて、いろいろな考え方をお伝えしていきます。

## 次回の発表の流れの確認

![image](https://i.gyazo.com/a487699b6132c7a8ee291008a43d5163.png)

- 最終課題として作ったものをプレゼンテーションします
  - 伝える内容
    - この作品はどんなものか（コンセプトや自分の想い）
    - どうつくりつづけたか
    - 制作デモ
      - 動画デモ or リアルタイムデモ必須
- プレゼンテーションの制限時間は 1 人あたり  7 分以内
- 発表後、フィードバックフォームから「良かった点」「気になった点、こうするといいなっていう点」フィードバックを書き込み
  - これは生徒全員が他の生徒全員に対して授業時間内のリミットで行います
  - 予定フォーム → URL 見えますか？
    - https://forms.gle/VrjbHhUuNANiv2Ln9
- 授業終了後、フィードバックを踏まえて第 8 回にブラッシュアップ
    - 生徒の皆さんが見れる予定スプレッドシート → URL 見えますか？
      - https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit?resourcekey#gid=913017201

なお、発表順は、学籍番号順でおこないます。

- 北嶋 眞羽（キタジマ マハ）
- 小林 英恵（コバヤシ ハナエ）
- 畠田 拓（ハタケダ タク）
- 内記 朋冶（ナイキ トモヤ）
- 中田 寛彬（ナカタ ヒロアキ）
- 山下 知章（ヤマシタ トモアキ）
- 澤田 真吾（サワダ シンゴ）
- 佐藤 仁奈（サトウ ニナ）

## アウトプットは伝わってこそ

![image](https://i.gyazo.com/fe36bd60957f3d4144fea7aa02a33665.png)

プレゼンテーションにおいても、ちゃんと伝わることによってフィードバックが生まれます。

このようなポイントに気をつけて自分の考えを伝えていきましょう。

- 画面共有やマイク音声のプレゼン準備はしっかりする
- 大きな声でハキハキと身振り手振りを交えて伝える
- デモへつなげるために相手に伝わるステップを踏む
- 内容の組み立て・時間配分に気をつける

## 画面共有やマイク音声のプレゼン準備はしっかりする

![image](https://i.gyazo.com/0adfc9dad0ac61765ebac23117bc9145.png)

なにより、伝える環境はしっかり整えましょう。今回は、オンライン登壇となります。

- 画面共有がスムーズに出来るか
- マイク音声が相手に聞き取りやすいか
- リアルタイムデモ時の WEB カメラでうまく表示でき伝わるか

あたりを事前にチェックしておきましょう。

とくに、Zoom での画面共有の場合は背景処理によって、見せるデバイスも背景に溶けてしまい見えにくくなる場合があるので注意です。

## 大きな声でハキハキと身振り手振りを交えて伝える

![image](https://i.gyazo.com/ee15b2f3c20537584f3e559c17664051.png)

これは、オンライン登壇でもオフライン登壇でも一緒です。

もちろん、自分のできる限りで大丈夫です。

- この作品はどんなものか（コンセプトや自分の想い）
- どうつくりつづけたか

この部分はただ発表するだけでなく、自分の体験をうまく交えて伝えると、他人事ではなく当事者として話しやすくなります。自分のプロダクトを人に伝えたい！というポジティブな気持ちを乗せましょう。

## プレゼンテーションとしての外装の話

![image](https://i.gyazo.com/94c856ff676f5aaaf09e990f6b00d925.png)

自分のプロダクトにおいて、手元で人に見せる用であったり、展示用であったり、どこかへの設置用であったりを想定して制作している場合もあるでしょう。

ですが、プレゼンテーションとしての外装は、オンラインでもオフラインでも独立した見せ方を考えておくことがおススメです。

今回はオンラインを想定しても色々あります。

- WEB カメラでアップして見やすいものになっているか？
  - 文字だけでなく色も変わって遠目でも分かりやすくしてみる
- ボタン操作をするために両手がふさがってしまいプレゼンしにくくないか？
  - 片手で足りるような、振る動作であったり、押しやすいボタン操作であったりを考える
- 実際にどこかに設置したように想像できるか？
  - あえてミニチュアや仮の設置物を手元に持ってくるなど雰囲気が伝わるようにする
- 手元で見せるために全パーツが見える状態か？あるいは一部でも伝わるか？
- 説明がなくても伝わるような分かりやすい見た目になっているか？
- プレゼンテーションするために手順が多くないか？

などなど、プレゼンテーションする場合は、普段使いと違う、注意点があります。

自分でプレゼンテーションを試してみて、ちゃんと伝わるものになっているか試してみましょう。ちょっとした変更で、とても説明しやすくなったり、グッと魅力的に伝わるようになったりするので、積極的にトライしていきましょう。

## デモへつなげるために相手に伝わるステップを踏む

![image](https://i.gyazo.com/652a7e447e153aee3fe21c4838358b30.png)

今回は、動画デモ or リアルタイムデモが必須です。

なぜ、これを行っていただくかというと、今回のような現実のデバイスを使って自分のプロダクトを作る場合「実際に動くものが一番伝わる」というのがあるためです。

たとえ冒頭でうまく伝えられなかったとしても、実際動くものを見せながら「これで、こういうことが少しでもより良くなります」「これがあることで使う人が楽しくなる」「煩わしかったものが、これで一歩ラクになる」などコメントをしていくのも良いでしょう。

相手には実際に思いがある人が手を動かしカタチにして伝えようとしていることで、信頼感や説得力が強化されます。

![image](https://i.gyazo.com/1bb55b5be1da1297de6e6e2ce9df4151.png)

リアルタイムデモは自然と実際動くものを見せながら説明することが多くなります。

![image](https://i.gyazo.com/456ee5a6f68335449f1a5c29819e7f80.png)

動画デモは、デモで動かす部分も説明する部分もすべて動画に入れてしまうオールインワン方式と、デモだけを収録して再生して口頭で説明を加えていくアフレコ方式があります。

オールインワン方式は一度作ってしまえば流すだけで楽なように見えますが、流している最中がどうしても単純なビデオ視聴しているようになり盛り下がりがちなので、結局、その場の雰囲気に合わせて調整する部分はトークでカバーしがちです。
また、音声合成やテロップ挿入など動画編集にかなりパワーを使うことになるので、そういった制作コストも考慮して進める必要があります。

アフレコ方式は、口頭の説明はリアルタイム性が高く、そのひとの思いが伝わります。リアルタイムデモの一歩手前といえます。デモ自体の失敗がないので説明に集中することができるのが大きなメリットです。

リアルタイムデモを是非トライしてほしいですが、設置済みのものであったり、持ち運びが難しいもの、見せるために複数人の助けが必要だったりと、デモに向いていないものはあるのも事実。

そのときは、アフレコ方式の動画デモもぜひ検討しましょう。

### 相手と自分の情報差を見極めて相手へ分かりやすく伝える段階を踏みましょう

![image](https://i.gyazo.com/dee5b9b0071c1ca511d90e115f8944f2.png)

アウトプットは、聞いてくれる相手への贈り物です。相手に対して唐突にならないように、ちゃんと段階を踏むことも大切です。唐突な独りよがりのアウトプットは、相手の理解を戸惑わせノイズとなります。

![image](https://i.gyazo.com/4d4da23e3f83a78ef1fda2d897c09925.png)

最初は、静止画でパッと内容が把握できるようしてから、動画による実際の動作を伝え、リアルタイムデモで、手元で動かし魅力的に伝える。こういったデモに入る前フリは大切にしましょう。

リアルタイムデモは成功すると盛り上がり、一気に内容が伝わります。しかし、ネットワークトラブルや不具合などで失敗すると大きく伝えたい情報が欠けることがリスクです。

そのため、まずは静止画や動画によって、丁寧に相手への印象を段階的にあげていくことで、スムーズな伝達を心掛けつつ、たとえ、うまく伝えられなかったときにも静止画や動画で伝わるという厚みあるアウトプットを目指しましょう。

![image](https://i.gyazo.com/ac8c09d50c4fdcc26fdc90b260550510.png)

もちろん、いきなりデモからはじめるという高等テクもあります。デモの成功に大きく後の進行が左右されますが、プレゼンテーションに自信がある方は、インパクトはあるので挑戦してもいいかもしれません。そのあたりは制限しないので、自由に組み立てていきましょう。

### リアルタイムデモ時のおススメ操作

![image](https://i.gyazo.com/1c4a9569022206fcd8910fad1b693744.png)

リアルタイムデモ時は一旦スライド共有を外して WEB カメラから見せるとよいです。そうすることで、大きい画面で操作を見せることができます。

また、背景設定も外しておいたほうがいいでしょう。Zoom では背景処理によって、見せるデバイスも背景に溶けてしまい見えにくくなる場合があります。

## 内容の組み立て・時間配分に気をつける

![image](https://i.gyazo.com/0cc17c2ff4f0218cb3f5b582de1db267.png)

登壇時間は 7 分です。

- 伝える内容
  - この作品はどんなものか（コンセプトや自分の想い）
  - どうつくりつづけたか
  - 制作デモ
    - 動画デモ or リアルタイムデモ必須

内容の組み立てに関しては、今回は、ある程度固定されているので、やりやすいとは思います。このあたりは授業ですので、あえて整えてあります。

ただし、時間配分には気をつけましょう。

とくに、リアルタイムデモは、ついつい見せ場を多めに見せたりという欲目が出たり（いいんですけどね！）、トラブルや作業のもたつきで時間計測が難しいので、注意して構成しましょう。

その点、動画でのデモは再生時間が固定なので便利ですね。時間内に伝えたいことが一定量しっかり伝わるのはメリットです。

## ともあれ、プレゼンテーションは練習することで磨かれる

![image](https://i.gyazo.com/00fbf352ed918bdaad8be8299271a9ba.png)

いろいろとお伝えしてきましたが、一旦自分の話したいことを詰め込んでみて、何度も練習することで、プレゼンテーションが磨かれます。ぜひやっていきましょう。

リアルタイムデモもやってみないと分からないところも多いですし、いくら全部伝えたくても収まらず、要点だけ伝えたり、削ったりすることもあるでしょう。練習することで、自分がつまづきやすい操作に気づいて対策することもできます。

事前に「これくらい時間がかかるけど、収まる」と感覚がつかめていると、当日は落ち着いてプレゼンテーションできることが多いです。練習していて当日だけミスすることは少ないです。

練習方法としては、よくあるやりかたとしては、タイマーを使って計測する方法があります。さらに Zoom での録画や動画キャプチャツールを使えば、再生時間がそのまま登壇時間として把握できますし、なにより自分の登壇を客観的にみることもできるのでおススメです。

ちなみに、動画キャプチャツールは Mac にも Windows にも標準でついています。

- [Macの画面録画は「QuickTime Player」使用方法の基本を解説│toaster team](https://toaster.how/media/video/quicktime)
- [Windowsの標準機能やパワポで画面を動画キャプチャー ～専用アプリはもういらない？ \- 高橋忍のにゃんともWindows \- 窓の杜](https://forest.watch.impress.co.jp/docs/serial/nyanwin/1247726.html)
  - ゲームバーでの録画がかなり手軽です

### もし、伝えたい内容が大きく残ってしまったら

![image](https://i.gyazo.com/59f50367cc4a65466795d9491335680b.png)

練習を繰り返して調整していく上で、要点は押さえられているものの、大きく伝えたいことが残ってしまうこともあるかもしれません。あるいは、途中の良い制作物が伝えられないこともあるかもしれません。

普段からアウトプットできていれば、そちらを note や Qiita でまとめて伝えられるかも模索してみましょう。

あらためて note や Qiita などにアウトプットするのもよいでしょう。そして、登壇中に「こういったものもあります、ぜひみてみてください」と伝えられれば、自分のプレゼンテーションにまつわるストーリーに奥行きが出ます。おススメです。

## 田中講師のプレゼンテーションを見てみましょう

このあたりで、わたくし田中講師の最近のプレゼンテーションを一緒に見てみましょう。

もちろん、今回の構成と IoTLT での構成は違うものなので、真似してくださいというものではありません。あくまで、参考によろしくお願いします。

![image](https://i.gyazo.com/f49e03014ad30ad6315067f804c3d81c.jpg)

[ビジュアルプログラミングIoTLT vol.9 アーカイブ 田中登壇部分](https://youtu.be/_6NbsS_av-4?t=3663)

- 静止画 → 動画 → リアルタイムプレゼン の流れ
- シンプルなページレイアウトで説明に熱量を乗せるやり方
- 伝え方の段階の踏み方
- メイン以外の伝えたい内容の外部リンクとしての伝え方
- などなど

あたりを補足しながら伝える予定です。（時間がありますように）

ちなみに、今回は練習せずに臨んでしまったので当初決めた時間を若干オーバーしてます。かっこよく制限時間に収められずくやしいですが、練習しないと私でもそうなるというところも含めて教訓として伝えます！

プレゼンテーションもプロトタイピングです。成功も失敗ありますが、自分で少しずつ登壇機会をうかがいながら、改善点やうまくいく方法を模索して、自分なりに磨いていきましょう。

## プレゼンテーションは自分を受け入れることでもある

![image](https://i.gyazo.com/5fc7d47b3f42a1b3a3e41e48641c6a77.png)

プロトタイピングの気持ちのコントロールが難しいところは、どこまでも「途中経過」というところです。つくりつづけるということは発想し進化しつづけるという面もありますが、裏を返せば、ずっと完成しないということでもあります。

自分の成果をリアルタイムにさらけ出すプレゼンテーションは、見せ方を考え切ってからツイートするのと比べて自己開示や自己内省の要素が強いため「ここまでしかできてないないのに伝えていいのか」「途中までしかできていないので恥ずかしい」といった気持ちが出てくることもあるでしょう。

![image](https://i.gyazo.com/7f4c2158acab923202b48b26b7f5b77f.png)

そんなときも、自分の「手を動かしたことによって進んだこと」「頑張ってここまで出来たこと」「つくることによってより解像度の上がった自分が目指すところ」に焦点を当てて、いまの現状を、自分にポジティブに受け入れてプレゼンテーションすることが大切です。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから「フィードバックを得るためのアンケート手法]」にすすみましょう。

# フィードバックを得るためのアンケート手法

![image](https://i.gyazo.com/1159ffd1fae17fe948b624657c3888b2.png)

次回の最終発表では、以下のように、生徒同士でフィードバックします。

- 発表後、フィードバックフォームから「良かった点」「気になった点、こうするといいなっていう点」フィードバックを書き込み
  - これは生徒全員が他の生徒全員に対して授業時間内のリミットで行います
  - 予定フォーム → URL 見えますか？
    - https://forms.gle/VrjbHhUuNANiv2Ln9
- 授業終了後、フィードバックを踏まえて第 8 回にブラッシュアップ
    - 生徒の皆さんが見れる予定スプレッドシート → URL 見えますか？
      - https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit?resourcekey#gid=913017201

こちらのアンケートは講師の方で作りましたが、このアンケートについてのいくつかのポイントと、フィードバックに退治するときの心構えをお伝えします。

## まず、Google フォームがおススメ

![image](https://i.gyazo.com/846221691a1c317ed31b396b58f5beb7.jpg)

無料で、分かりやすい操作画面で、きれいなフォームを作成できるツールで、今後も、展示や登壇などで自分のアウトプットにフィードバックが欲しいときに良き入り口となるので、是非使いこなしていきましょう。

[Google フォーム](https://www.google.com/intl/ja_jp/forms/about/) サイトからの特色の引用です。

- 回答をすばやく回収
  - レジャーの計画、イベント参加者の管理、ミニ投票、会報用のメールアドレスの収集、小テストの作成など、さまざまな用途に活用できます。
- デザインにもこだわりを
  - 写真やロゴを使用すると自動的にそれに合う色が選択されるほか、さまざまなテーマからふさわしい雰囲気のものを選ぶこともできます。
- 高度なアンケートを作成
  - 選択式、プルダウン形式、評価スケールなど、さまざまな形式の質問から選択できます。画像や YouTube 動画を追加したり、回答に応じて質問をスキップするように設定したりすることもできます。
- 外出中でも作成や回答が可能
  - フォームはパソコンにも携帯端末にも対応しているので、大小さまざまな画面で美しいフォームを作成できるほか、編集や回答も行えます。
- 整理して分析
  - アンケートの回答は自動的にフォームに整理して集計され、リアルタイムの回答状況やグラフを見ることもできます。さらに、すべてのデータをスプレッドシートに表示して詳しく分析することも可能です。
- などなど

## フィードバックを得るときに注意するポイント

![image](https://i.gyazo.com/90b3db6d4436ddf34310fb6627eef4bc.png)

今回のフォームでの項目については、アンケートでよくある「今回の私の登壇は良かったですか？」からの5段階評価を選ばせるといったものは避けています。

もちろん 100 人を越えるようなアンケートの場合は、そういった5段階評価で選ばせても、おおまかな反響は得ることができます。

ですが、こういったプロトタイピングしたものにおいては場に合わせる必要があります。ざっくりした反応よりも対話に近い形の文章の方がフィードバック内容をつかみやすいため、このように設定しています。

実際のところ、ただただ「56 人がよかったと答えました」とあって、だから自分のプロダクトは良い制作物ですね！とはならず、対応に困りますよね。

![image](https://i.gyazo.com/45d5364401d00a85dad14631fec08085.png)

フィードバック後に、自分が動きやすく具体的なアクションを起こせるようにアンケートを設計していきましょう。

また

- 良かったポイント
- 気になったポイント、こうするといいなっていうポイント

に分けている点にも仕掛けがあります。

おもに人がフィードバックを行うとき、良かったポイントというのは最初に書きやすく相手のフィードバックしたい気持ちが活性化しやすく良き入り口となります。

そこを入り口にして、自分のプロダクトに目を向けてもらった考えが深まったときに、うまくいけば、本当にコアなフィードバックをいただける「気になったポイント、こうするといいなっていうポイント」にも何か書いてくれるかもしれないという流れを作っています。

これは、オフラインで展示などでアンケートする場合でも活用しやすいです。まず、話しかけて良い点を聞いて盛り上げたあとに、より深いフィードバックを引き出すときに使うことができます。

今回のアンケート手法は、あくまでひとつの側面ではありますが、大事なのは制作と同じく、相手にどのように伝えて、どのような気持ちの流れがあって、お互いに良い形でフィードバックやりとりできるかということを、事前に想像を巡らせながらアンケートを作っていきましょう。

アンケートもプロトタイピングです。仕事でなら定型のアンケート手法が整備されているかもしれませんが、自分のプロダクトごとにフィードバックを得たいシチュエーションに応じて変わるので、試行錯誤していきましょう。

## 自己と他者のフィードバックをうまく消化して次のアクションを決めよう

![image](https://i.gyazo.com/02f4ff68bfae2ac76ba1a88362f65e78.png)

今回のフィードバックですが、ひとつ大事なポイントがあります。ほかの人から得たフィードバックは鵜呑みにしてただただやるのではなく、ちゃんと消化させて、次のアクションを決めましょう。

![image](https://i.gyazo.com/1113fa1bf801156b5117c302ce9202fc.png)

ここで大事になるのは、自分で自分に向けたフィードバックです。自己フィードバックは、自分が作った瞬間に生まれるもので、そのあとに来る、ほかの人からのフィードバックに対する、良き定規となります。

自分の「つくってみたら他のことも検討したい」「もっとこうしたい」といった発想は大切しつつ、フィードバックを消化して、「自分としてこういう考えでこう磨くんだ」という自分で判断しコントロールできている状態でポジティブにブラッシュアップをしていきましょう！

## フォーム投稿のウォームアップ

![image](https://i.gyazo.com/0452504c09ed10930fc9036ff8f1038c.png)

フォームからの投稿をテストしてみましょう。

- 発表後、フィードバックフォームから「良かった点」「気になった点、こうするといいなっていう点」フィードバックを書き込み
  - これは生徒全員が他の生徒全員に対して授業時間内のリミットで行います
  - 予定フォーム → URL 見えますか？
    - https://forms.gle/VrjbHhUuNANiv2Ln9
- 授業終了後、フィードバックを踏まえて第 8 回にブラッシュアップ
    - 生徒の皆さんが見れる予定スプレッドシート → URL 見えますか？
      - https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit?resourcekey#gid=913017201

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから README に戻りましょう。

# 第7回 制作物デモ発表 ／ プレゼンテーション

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第7回　2021年11月05日（金） 8限　21:00 ～ 22:30　遠隔授業
```

※書かれている時間は予想の所要時間です。前後する可能性があります。

- 10 分 はじめに
- 80 分 プレゼンテーション

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 第 7 回の心構え

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

第 7 回は、制作物デモ発表 ／ プレゼンテーション です。

第 6 回までに学んだ内容でリアルタイムデモ＋プレゼンテーションを行い生徒内でフィードバックを得ます。

- プレゼンテーションを意識して制作物を作り込んでいる
- フィードバックを受け取れるように伝えるプレゼンテーションをする

## 第 7 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- オンライン登壇しつつのリアルタイムデモを体験する
- 制作物デモ発表やプレゼンテーションを通して自分のプロダクトを伝える手法を把握する
- 自分のプロダクトについてツイートやプレゼンテーションをはじめ様々な方法があることを把握する

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- 制作物デモ発表やプレゼンテーションができる状態であること
- ほかの人へ共感しつつフィードバックするポジティブな気持ちがあること

## Zoom スポットライト機能のテスト＆みなさんの出力テスト

![image](https://i.gyazo.com/f01f37c2b95df6cc45b41c74282506f6.png)

講師側で今回の登壇者の人にスポットライトを当てたいので、テストさせてください。みなさんの出力テストもしておきましょう～。

- 各個人のテスト
  - カメラテスト
  - 資料の出力テスト
  - マイクテスト
- 講師のテスト
  - スピーカービューにしているか確認
  - ホスト側から誰かにスポットライトを当てれるか確認
  - 当てたらみんなが同じようにスポットライトが当たってるひとが見れているか確認

こういった各個人のテストは、他のオンライン登壇時もイベント開始直前にやっておきましょう。良いイベントであれば登壇者が30分くらい前に集まって、このような対応をします。

## 授業開始

では授業をはじめましょう！

左のメニューから「プレゼンテーション」をクリックしましょう。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

# プレゼンテーション

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## 今日の流れ

![image](https://i.gyazo.com/a487699b6132c7a8ee291008a43d5163.png)

- 最終課題として作ったものをプレゼンテーションします
  - 伝える内容
    - この作品はどんなものか（コンセプトや自分の想い）
    - どうつくりつづけたか
    - 制作デモ
      - 動画デモ or リアルタイムデモ必須
- プレゼンテーションの制限時間は 1 人あたり 7 分以内
- 発表中、フィードバックフォームから「良かった点」「気になった点、こうするといいなっていう点」フィードバックを書き込みます。
  - これは生徒全員が他の生徒全員に対して授業時間内のリミットで行います
  - フィードバックフォーム
    - https://forms.gle/VrjbHhUuNANiv2Ln9
- 授業終了後、フィードバックを踏まえて第 8 回にブラッシュアップ
    - 生徒の皆さんが見れる予定スプレッドシート → URL 見えますか？
      - https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit?resourcekey#gid=913017201

## いち発表中の動き

![image](https://i.gyazo.com/5499407f28785b7005a2cf3547252241.png)

おおよそ、いち発表はおおよそ 10 分以内で進行します。

発表する人は、まず発表を 7 分以内に行います。残り 3 分ほどはフィードバックを待ちつつ、質疑応答を行います。質疑応答は講師からもありますし、生徒からも OK です。

フィードバックする人は、発表者以外の生徒全員が必ず 1 回は行います。「良かった点」「気になった点、こうするといいなっていう点」フィードバックを書き込みます。貯めずに、随時フォームからフィードバックしましょう。

- 書き込むフィードバックフォーム
  - https://forms.gle/VrjbHhUuNANiv2Ln9

## 厳守事項

- 制作物には M5Stack を使用した IoT の仕組みにしましょう
  - 例：
    - M5Stack を操作画面（LINE BOT or LINE Notify or 何かしら自作のWebの仕組み ）で遠隔操作する
    - M5Stackで何かしらのセンサーや入力によって Web 上の何か（LINE BOT or LINE Notify or 何かしら自作のWebの仕組み ）を動かす
- 第 7 回
  - 制作デモを伴うプレゼンテーションを時間内に行いましょう
  - 各生徒は他の生徒全員にアンケートフォームから授業内にフィードバックを行いましょう
  - 提出場所のフォルダに第 7 回で発表した自分のスライドを提出しましょう
  - 提出場所のスプレッドシートに今回の自分の最終課題についてコメントを書きましょう

## 採点基準

![image](https://i.gyazo.com/cde6f43a81eff49bb72d784b695f9352.png)

こちらの 3 要素で採点します。 30 点。

- 発想力 10点
  - 自分の今までの知識や経験に基づいて自分なりに思いついているか（独自性）
  - 自由に発想ができているか（自在性）
- 創造力 10点
  - 発想を自分の技術と自分の考えをうまく組み合わせてカタチにできているか
  - 今の自分から得たものとともに新しい価値にチャレンジをしているか
- アウトプット力 10点
  - 制作物を通じて自分の考えをアウトプット出来ているか
  - 狙った他者（ターゲット）に伝わるように工夫できているか

## 提出場所

![image](https://i.gyazo.com/f31f0a37c64f84203adf5ebd7e86b647.png)

https://drive.google.com/drive/folders/1jrOE4hWfi3x_jQZz_Xn-FsVDfeAKtk9o

第 7 回終了までに、最終課題を発表した自分の ~~スプレッドシート~~ スライドをこちらにアップロードしましょう。Google スライド推奨。

![image](https://i.gyazo.com/ff6d87f56597f436f7a3e5a1ebef0c00.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=386298483

こちらのスプレッドシートに、今回の自分の最終課題についてコメントを記入しましょう。

  - どういう意図で最終課題をつくったか（必須）
  - どう伝わることを狙ってプレゼンテーションしたか（必須）
  - そのほか自分のアウトプットへの熱いメッセージあれば

## 授業終了後、フィードバックを踏まえて第 8 回までにブラッシュアップ

![image](https://i.gyazo.com/40ef516b042e6f09063b2f7bfa6cd752.png)

いろいろなフィードバックをもらいつつ、その中で制作物に関するフィードバックに注力しましょう。

https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit#gid=913017201

フィードバックフォームの下部に、自分へのフィードバックが自動分類されるような仕組みを作ってみました。試してみてくださいー。

![image](https://i.gyazo.com/8c62a0d4614c56c53cecdd12ac216a5d.png)

（うまく動かなかったら、元データでソートする）

## フィードバックする自分、フィードバックされる自分を両方体験しよう

![image](https://i.gyazo.com/eee1cd6380cfb9e302ef5b5527217eb4.png)

そろそろ、スタートです。今回は、アウトプットにフィードバックする自分、アウトプットしてフィードバックされる自分を体験して、今後もつくりつづけるときの世界観を両面から体感していきましょう。

なので、両方全力で。ポジティブに。

## でははじめましょう！

![image](https://i.gyazo.com/5e0248aefe50481855dfcffde2972bac.png)

## おつかれさまでした！

![image](https://i.gyazo.com/151fb74f6fca4222ac12a14fd5cb630b.png)

## フィードバックを確認してみましょう

さあ、いよいよフィードバックをみなさん確認してみましょう。

![image](https://i.gyazo.com/40ef516b042e6f09063b2f7bfa6cd752.png)

いろいろなフィードバックをもらいつつ、その中で制作物に関するフィードバックに注力しましょう。

https://docs.google.com/spreadsheets/d/16UdnoAU8ZrRKaD_XdkZfyl4KTUWVXBuJJwjGSo410Y0/edit#gid=913017201

フィードバックフォームの下部に、自分へのフィードバックが自動分類されるような仕組みを作ってみました。試してみてくださいー。

![image](https://i.gyazo.com/8c62a0d4614c56c53cecdd12ac216a5d.png)

（うまく動かなかったら、元データでソートする）

## リアルタイムデモは展示での説明にも通じます

（時間があれば話す）

![image](https://i.gyazo.com/dac7b65d42ccbc46c1f99b46f5951635.png)

リアルタイムに相手の反応を見ながらスムーズに分かりやすくデモをすることは、展示時のコミュニケーションへも活かすことができます。

## 次回の話

![image](https://i.gyazo.com/f01f37c2b95df6cc45b41c74282506f6.png)

いま一度、[第 8 回](../lecture05/99-final-task.html) の課題を見てみましょう。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから README にすすみましょう。

# 第8回 制作物デモ発表 ／ プレゼンテーション

![image](https://i.gyazo.com/ee01b5f25d0bed14e38b6ad0f4828a7d.png)

## この授業の概要

```
第8回　2021年11月12日（金） 8限　21:00 ～ 22:30　遠隔授業
```

※書かれている時間は予想の所要時間です。前後する可能性があります。

- 10 分 はじめに
- 60 分 プレゼンテーション
- 10 分 スライド提出・コメント記入
- 10 分 最終回の締め

## はじめに

![image](https://i.gyazo.com/cb9b9c279ea25ef482912ec9db7ff276.png)

- 途中退席
  - トイレなど急な用事で途中退席したいときは Zoom のコメントしつつで、いつでも行ってください。
  - それにより授業の方は止めませんが、なるべくこちらの資料で後追いができるようにしておりますので、抜けた間の把握はよろしくお願いします。
- コミュニケーションツールについて
  - Slack が中心となります。重要な情報は、デジキャンの掲示板も併用する予定ですが、基本的に Slack がメインとします。
  - Slack は1日1回以上は定期的にチェックください。
  - 質問や自分の制作物の進み具合など気軽に交流していきましょう！
- Zoom での授業について
  - ビデオについて
    - できるだけ、ビデオは ON でお願いします。
    - 手を動かしているときなど、雰囲気を見たいと思っています。
    - マシンスペックによってはキツいかもしれないので、そういう方は OFF でもOKです。
  - マイクについて
    - 通常はミュートでおねがいします。
    - ですが授業中に講師と会話をする場合があるので、マイクの設定もチェックしておいてください。
  - 画面共有
    - オンライン授業では、授業時に画面共有を使う機会が多いです。うまく行かないときの伝達や、疑問があるときの質問などなど。
- 授業の雰囲気を SNS に公開する場合があります
  - 公開してほしくない方は事前におっしゃってください。Slack の DM など。

### SNSアカウント

- 演習で LINE を利用する予定のため、LINEアカウントが必須です。
- 制作物はSNSへシェアを想定しているため、Twitter や Instagram などの公開アカウントが必須です。

### ツイート時の推奨ハッシュタグ

ツイート時は `#protoout #DHGS` をつけてお願いします。

- `#DHGS`
  - デジタルハリウッド大学院のハッシュタグなのでつけてみましょう。
    - [デジタルハリウッド大学院さん \(@DHGS\) / Twitter](https://twitter.com/dhgs)
- `#protoout`
  - プロトタイプしてアウトプットする意味で使います。ほかの人のアウトプットも見れるかも。

### その他の注意点（シラバスに記載）

- 演習形式で前後の関係性が連続しているため、欠席は不可です。
- 制作物を進めるにあたって外装や設置のために自分で物品購入する可能性があります。

## 分からないことあれば Slack で気軽に聞いてください

これから自分で作っていく時間が増えていくはずなので、つまづいているときには悩みすぎずSlack を活用して、聞いてくださいね～。改めてお伝えしておきます。

![image](https://i.gyazo.com/82ad117f19690778bd79c3df6bdaccfd.png)

## 第 8 回の心構え

![image](https://i.gyazo.com/2cb6bb2065f94760eb847eb5a9c5de21.png)

第 8 回は、フィードバック・ブラッシュアップ です。

- 第 7 回で得た自己や他者のフィードバックからのブラッシュアップを行いプレゼンテーションを行います。

## 第 8 回のゴール

![image](https://i.gyazo.com/37ccdda7457e2a55fe177b4fc8973767.png)

今回のゴールは、以下の通りです。

- 自己や他者のフィードバックからのブラッシュアップを行い、これからも継続してつくりつづける感覚をつかむ

## 今回はじめる前にできてると良いこと（理想形）

![image](https://i.gyazo.com/2426191c63343eb3f98402e2d3e238b1.png)

理想形ではあるので、現実に合わせて調整して進めていく予定です！

- フィードバックから制作しておりプレゼンテーションができる状態であること
- ほかの人へ共感しつつフィードバックするポジティブな気持ちがあること

## 授業開始

では授業をはじめましょう！

左のメニューから「プレゼンテーション」をクリックしましょう。

## 授業後について

![image](https://i.gyazo.com/9bd65355f8c821c9b4d032e7bcbdfae9.png)

- 今日のプレゼンテーションで第 8 回採点いたします！
- 資料の PDF 化で頑張ってみます。
  - Slack で報告予定です。

## デジキャンアンケートよろしくお願いします！

![image](https://i.gyazo.com/ae63e038ccb92474433c508557f40fda.png)

デジキャンのアンケートが事務局の方から出てますが、期日内で入力しましょう～。出席チェックと共に、私もみなさんのリアクションを気にしております。

## お疲れ様でした！

![image](https://i.gyazo.com/8c25c983712563658decb7babb379011.png)

これからもお互いつくりつづけていきましょう！# 第8回 フィードバックブラッシュアップ／ プレゼンテーション

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## 課題全体からの位置づけ

全体としては

```
- 最終課題　50％
  - 発想力・創造力・アウトプット力・継続制作力※ の要素で採点する予定です。
- 授業内の課題　50％
  - 機材をそろえて準備する課題 10％予定
  - 制作してアウトプットする課題 20％ * 2 予定
```

※以前は継続開発力としていましたが `継続制作力` としました。 

で採点を予定しています。

今回は最終課題です。

第 7 回では制作デモを伴うプレゼンテーションを行い、生徒同士でフィードバックを行います。

第 8 回では、そのフィードバックを元に自分なりに制作物のブラッシュアップを行ってプレゼンテーションを行っていただきます。

## 第 8 回の流れ

![image](https://i.gyazo.com/a487699b6132c7a8ee291008a43d5163.png)

- 第 7 回を踏まえてブラッシュアップした内容をプレゼンテーションします
  - 伝える内容
    - どんなフィードバックをピックアップしたか
    - そのフィードバックを自分なりにどう消化しアウトプットしたか
    - 今後の展望・目指すところ
- スライドを画面シェアしてプレゼンテーションします
- プレゼンテーションの制限時間は 1 人あたり 5 分以内
- 1 人が発表後、5 分質疑応答

## 1 人あたりの流れ

![image](https://i.gyazo.com/8a35fec70ecfb2e5dfac5eef3c1a4169.png)

プレゼンテーションの制限時間は 1 人あたり 5 分以内で、そのあとは質疑応答をします。講師・生徒 OK です。

## 厳守事項

- 制作物には M5Stack を使用した IoT の仕組みにしましょう
  - 例：
    - M5Stack を操作画面（LINE BOT or LINE Notify or 何かしら自作のWebの仕組み ）で遠隔操作する
    - M5Stackで何かしらのセンサーや入力によって Web 上の何か（LINE BOT or LINE Notify or 何かしら自作のWebの仕組み ）を動かす
- 第 8 回
  - 前回のフィードバックを元に、自分なりに制作物のブラッシュアップを行ってプレゼンテーションを時間内に行いましょう
  - 提出場所のフォルダに第 8 回で発表した自分のスライドを提出しましょう
  - 提出場所のスプレッドシートに今回の自分のブラッシュアップについてコメントを書きましょう

## 第 8 回の採点基準

![image](https://i.gyazo.com/2fef3f7c4c5c85f762b431a724ca3a51.png)

こちらの 2 要素で採点します。 20 点。

- アウトプット力 10点
  - 制作物を通じて自分の考えをアウトプット出来ているか
  - 狙った他者（ターゲット）に伝わるように工夫できているか
  - `New!` 第 7 回を踏まえてツイートなどでアウトプットしているか
- 継続制作力 10点
  - 自分や他の人からのフィードバックを受け入れてつくりつづけようとしているか
  - ただ、受け入れるだけでなく、自分なりに消化した上で、自分のプロダクトを磨いているか
  - 自分の目指す方向性を自分で理解しながらリアルタイムにプロダクトを考えてつくり続けているか

## 第 8 回 提出場所

![image](https://i.gyazo.com/9470e97bd0c0637b9451de5031d1c8af.png)

https://drive.google.com/drive/folders/1-qQM9du1tYWp1tsw825-xpabR5aLywDp

第 8 回終了までに、ブラッシュアップについて自分の発表したスライドをこちらにアップロードしましょう。

![image](https://i.gyazo.com/bade2c607337ece8011631469039d536.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=167621219

こちらのスプレッドシートに、今回の自分のブラッシュアップについてコメントを記入しましょう。
  - どのフィードバックを自分なりに消化してブラッシュアップしたか（必須）
  - 今後どのようにつくりつづけていくかの考え（必須）
  - そのほか自分のアウトプットへの熱いメッセージあれば

## でははじめましょう！

![image](https://i.gyazo.com/5e0248aefe50481855dfcffde2972bac.png)

## おつかれさまでした！

![image](https://i.gyazo.com/151fb74f6fca4222ac12a14fd5cb630b.png)

## 提出よろしくお願いします！

![image](https://i.gyazo.com/9470e97bd0c0637b9451de5031d1c8af.png)

https://drive.google.com/drive/folders/1-qQM9du1tYWp1tsw825-xpabR5aLywDp

第 8 回終了までに、ブラッシュアップについて自分の発表したスライドをこちらにアップロードしましょう。

![image](https://i.gyazo.com/bade2c607337ece8011631469039d536.png)

https://docs.google.com/spreadsheets/d/1W_IXR57dBmdn17ZQ4fJIVjkdXdt3nkCzr-5xSjY26KY/edit#gid=167621219

こちらのスプレッドシートに、今回の自分のブラッシュアップについてコメントを記入しましょう。
  - どのフィードバックを自分なりに消化してブラッシュアップしたか（必須）
  - 今後どのようにつくりつづけていくかの考え（必須）
  - そのほか自分のアウトプットへの熱いメッセージあれば

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから README にすすみましょう。# エンドトーク

![image](https://i.gyazo.com/2fe8f1e2d461451f6b5212996272c3ee.jpg)

## これからもアウトプットの前に試して作り馴染ませよう

![image](https://i.gyazo.com/aca539dd23aa929727641dd141a3cb12.png)

今回の M5Stack の習得のように、ある時みなさんが得た知識や経験が、自分のものとして馴染んで自在に使いこなせるようになるには時間がかかります。

なので、日々得たものを試して作ることを心掛けて自分に馴染ませていきましょう。そうすると、いざアウトプットをするときにも、起動コストが少なく、素早く扱うことができて、自分の作りたいものにうまく活用することができるはずです！

## これからも細かくアウトプットする自分を受け入れていきましょう

![image](https://i.gyazo.com/6e7124007af9434a2da11ed693ae61d9.png)

大きなアウトプットも大切！ですが、そんな大きさでは人生でそう何度もアウトプットできません。作るために大きなパワーも使いますし、かけたコストゆえに成功を意識しすぎることもあるでしょう。きっと、失敗を恐れるようになります。

人生でつくれる時間は限られています。

プロトタイピング。改めて、大切にしましょう。何かを進めるという粒度をできるだけ小さく意識し、つくっていく解像度を細かく。いつでもどこでもサッと取り組めるように。

そうすることで、小さくつなげて進んでいくことを積み重ねながら、楽しんで取り組んでいる自分を受け入れましょう。そうすれば、自己フィードバックも次第に自分に求めすぎず身の丈のものになっていき、きっと、ほかの人からのフィードバックへの共感も豊かになります。

軽快に、前向きに、自分のプロダクトをつくっていきましょう。この変化の多い世の中ですが、小さく動きつつ試しながら少しずつ良くしていければ、柔軟に対応することができるでしょう。

## これからも自己フィードバックとほかの人からのフィードバックで磨いていきましょう

![image](https://i.gyazo.com/674ff1b7fe8351fc860980610c347a11.png)

今回は、ツイートによる不特定多数寄りのフィードバック、生徒同士の作る人同士のフィードバック、フォームシステムを使ったフィードバック・プレゼンテーションからのフィードバックなど様々なフィードバック手法を体験できました。

自分でこうありたいという自己フィードバックは自分のプロダクトを深く鋭く掘り下げます。ほかの人からのフィードバックは自分では見えなかった視点やアイデアがあったり、受け取る側の素直な反応であったり、自分が伝えたい社会との接点です。

この2つをうまく掛け合わせることで、これからも自分のプロダクトや制作物を磨いていきましょう！

## これからもつくりつづけるサイクルをこれからも回していきましょう

![image](https://i.gyazo.com/d85c116e96b37c8f9d4617212762e6bc.png)

自分自身と対話しつつ発想して、発想をカタチにして創造したものをアウトプット。そして、フィードバックをつどつど受けて磨いてきました。

今回は、このつくりつづけるサイクルは数回だけ回しましたが、今後は自分なりに合ったやり方を取り入れつつ、つくりつづけていきましょう～。

# 質疑応答

![image](https://i.gyazo.com/aba8ccd625e7320883851b71ebd0caf2.png)

ここまでで質問があればどうぞ！

# 次にすすみましょう

左のナビゲーションから 第 8 回 README にすすみましょう。

## M5Stack 関連のナレッジ

ここでは、M5Stack で役に立つ TIPS やリンクをあつめます。

## ながめておくと良いところ

- [\#M5Stack \- Twitter検索 / Twitter](https://twitter.com/hashtag/M5Stack)
  - なんといってもこれを見てるとつくりたくなる
- [M5Stackさん \(@M5Stack\) / Twitter](https://twitter.com/M5Stack)
  - 本家の開発魂がものすごい

## コミュニティ

- [M5Stack User Group Japan \| Facebook](https://www.facebook.com/groups/154504605228235/)
  - 日々いろいろな人の制作風景が見れる
- [Arduinoファン \| Facebook](https://www.facebook.com/groups/1547944695219684)
  - Arduino 情報の中で M5Stack の投稿も多数。Arduino を使う様々が M5Stack にはまっていく様子が見れる。
- [ESP8266/ESP32環境向上委員会 \| Facebook](https://www.facebook.com/groups/927623023964478/)
  - M5Stack のベースにある ESP32 の情報がある。もちろん M5Stack の情報も多数。
- [IoTLT ~ IoT縛りの勉強会/LT会~ \| Facebook](https://www.facebook.com/groups/411744275663359)
  - さまざまな IoT の登壇が集まるコミュニティ。プロダクトプロトタイピング I 講師ののびすけ先生運営。


## 最近アツい

講師が見かけたもの。

2021/10/01 現在

- [「M5Stack Tough ESP32 IoT開発キット」を2021年9月30日より販売開始します｜株式会社スイッチサイエンスのプレスリリース](https://prtimes.jp/main/html/rd/p/000000051.000064534.html)
  - [M5Stack Tough ESP32 IoT開発キット \- スイッチサイエンス](https://www.switch-science.com/catalog/7483/?utm_source=prtimes&utm_medium=news&utm_campaign=m5stack_tough_kit)
- [\#ｽﾀｯｸﾁｬﾝ \- Twitter検索 / Twitter](https://twitter.com/hashtag/%EF%BD%BD%EF%BE%80%EF%BD%AF%EF%BD%B8%EF%BE%81%EF%BD%AC%EF%BE%9D?src=hashtag_click)
- [高須正和@NT深圳コミュニティ/TAKASU@NT ShenzhenさんはTwitterを使っています 「\#M5Stack Japanese Panel\! 日本語パネル、いいカメラで撮った写真です！ https://t\.co/BYtb4fYNxf」 / Twitter](https://twitter.com/tks/status/1442883517570961418)
  - ラインナップすごい

## TIPS

おもに事例とか作例


## 注目 Twitter アカウント

- [M5Stackさん \(@M5Stack\) / Twitter](https://twitter.com/M5Stack)
  - 本家
- [紅樹　タカオ💉💉さん \(@mongonta555\) / Twitter](https://twitter.com/mongonta555)
- [robo8080さん \(@robo8080\) / Twitter](https://twitter.com/robo8080)
- [ししかわ/Shinya Ishikawaさん \(@meganetaaan\) / Twitter](https://twitter.com/meganetaaan)
  - スタックチャンの作者、他にも MtStack 作例いろいろ
- [高須正和@NT深圳コミュニティ/TAKASU@NT Shenzhenさん \(@tks\) / Twitter](https://twitter.com/tks)
  - M5Stack の開発元とも仲が良く、いろいろな情報が集まる
- [たなかまさゆきさん \(@tnkmasayuki\) / Twitter](https://twitter.com/tnkmasayuki)
  -  https://lang-ship.com/blog/ の情報がものすごい
- [mgo\-tecさん \(@mgo\_tec\) / Twitter](https://twitter.com/mgo_tec)
  - M5Stack だけでなく Arduino の情報も豊富
- [tomorrow56@ガジェット分解\(モ2済\)さん \(@tomorrow56\) / Twitter](https://twitter.com/tomorrow56)
- [らびやんさん \(@lovyan03\) / Twitter](https://twitter.com/lovyan03)
  - 様々な作例が見れます。かつ IoT 系のディスプレイLCD高速描画の LovyanGFX の作者さん。

## 良く見る情報源

- [Lang\-ship \| ラングシップ](https://lang-ship.com/blog/)
- M5Stack 本家のリツイートだけながめるのもなかなかおススメ
  - [M5Stack（@M5Stack）さんの返信があるツイート / Twitter](https://twitter.com/M5Stack/with_replies)

## トラブルシューティング

- [ESP32 \( ESP\-WROOM\-32 , M5Stack \)自分的 トラブルシューティング まとめ \| mgo\-tec電子工作](https://www.mgo-tec.com/blog-entry-trouble-shooting-esp32-wroom.html)
- [M5Stack製品のトラブルシューティングと豆知識 \| ラズパイ好きの日記](https://raspberrypi.mongonta.com/m5stack-trobleshooting-tips/)
- [M5Stack\(旧Core\)で困った時の対処や注意事項](https://zenn.dev/mongonta/articles/25a49b39f51a8ae66d68)
- 

## 雑多なリンク集

ひとまず未分類で。

- [M5Stack/getting\_started\_ja\.md at master · m5stack/M5Stack](https://github.com/m5stack/M5Stack/blob/master/docs/getting_started_ja.md)
  - 2019 年の情報だけど、結構参考になります（インストールや最新のAPI情報は最新情報を追いましょう）
  - 「素晴らしい応用例」が素敵
- [m5\-docs](https://docs.m5stack.com/en/core/gray)
  - 本家のリファレンス
- [\[M5Stack\] ArduinoライブラリのAPIまとめ \| ラズパイの実](https://knt60345blog.com/m5stack-arduino-api/)
- [M5stack の LCD に日本語漢字フォントを表示したりスクロールしたり \| mgo\-tec電子工作](https://www.mgo-tec.com/blog-entry-m5stack-font-scrolle-esp32.html)

